2018-11-12 22:11:55.814198: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2018-11-12 22:11:59.758966: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Found device 0 with properties: 
name: TITAN V major: 7 minor: 0 memoryClockRate(GHz): 1.455
pciBusID: 0000:04:00.0
totalMemory: 11.78GiB freeMemory: 11.37GiB
2018-11-12 22:11:59.759019: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1485] Adding visible gpu devices: 0
2018-11-12 22:12:14.353645: I tensorflow/core/common_runtime/gpu/gpu_device.cc:966] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-11-12 22:12:14.353721: I tensorflow/core/common_runtime/gpu/gpu_device.cc:972]      0 
2018-11-12 22:12:14.353735: I tensorflow/core/common_runtime/gpu/gpu_device.cc:985] 0:   N 
2018-11-12 22:12:14.363283: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1098] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10982 MB memory) -> physical GPU (device: 0, name: TITAN V, pci bus id: 0000:04:00.0, compute capability: 7.0)
==================================================
Parameters:
batch_size : 50
data_type : Med
epoch : 300
lr : 0.03
model : ABCNN+LSTM
model_type : ABCNN1
word2vec : <preprocess.Word2Vec object at 0x7f8d0743e160>
==================================================
training data size: 750
training max len: 129
==================================================
================================
Tensor("regression/FC/BiasAdd:0", shape=(?, 1), dtype=float32)
==================================================
[Epoch 1]
[batch 1] cost: 11.834903 training pearson: -0.7529373609953633
[batch 2] cost: 11.01648 training pearson: -0.7242106746859894
[batch 3] cost: 9.280203 training pearson: -0.8081713730723163
[batch 4] cost: 9.326145 training pearson: -0.7718794375172231
[batch 5] cost: 8.857896 training pearson: -0.7843607571164447
[batch 6] cost: 9.402105 training pearson: -0.619732182322726
[batch 7] cost: 8.407701 training pearson: -0.8079465870930486
[batch 8] cost: 6.6144786 training pearson: -0.8659694115614927
[batch 9] cost: 8.235719 training pearson: -0.6340198081144158
[batch 10] cost: 6.5552936 training pearson: -0.8812289875771249
[batch 11] cost: 6.485281 training pearson: -0.6063716863326293
[batch 12] cost: 6.5218925 training pearson: -0.7594402577183867
[batch 13] cost: 5.1430583 training pearson: -0.6360440987003243
[batch 14] cost: 5.8161616 training pearson: -0.7207873604078914
[batch 15] cost: 5.054204 training pearson: -0.7396894594865507
epoch:  1 pearson: test_pearson:  -0.7182433687146873
============gbrt============
epoch:  1 pearson: ml_test_pearson:  0.6778501751682369
============xgb============
epoch:  1 pearson: ml_test_pearson:  0.6813256974589545
============rfr============
epoch:  1 pearson: ml_test_pearson:  0.624807689115481
===============模型average结果==================
epoch:  1 pearson: ml_test_pearson:  0.682108904275064
[Epoch 2]
[batch 1] cost: 4.2183867 training pearson: -0.7225988606553989
[batch 2] cost: 4.4448457 training pearson: -0.7847914148586105
[batch 3] cost: 4.362143 training pearson: -0.7058526198354104
[batch 4] cost: 3.4250805 training pearson: -0.8169641514160222
[batch 5] cost: 2.6567063 training pearson: -0.7055799400116033
[batch 6] cost: 3.4856536 training pearson: -0.8438312118856592
[batch 7] cost: 2.4591093 training pearson: -0.6903295790110427
[batch 8] cost: 2.639514 training pearson: -0.6723011359403442
[batch 9] cost: 2.8714838 training pearson: -0.779377989744113
[batch 10] cost: 2.4281776 training pearson: -0.7213643736937636
[batch 11] cost: 2.3375669 training pearson: -0.761485586748099
[batch 12] cost: 2.272358 training pearson: -0.8298879667923308
[batch 13] cost: 1.7929841 training pearson: -0.6175294336255475
[batch 14] cost: 2.36201 training pearson: -0.7116896419794747
[batch 15] cost: 2.2777615 training pearson: -0.6795880042864793
epoch:  2 pearson: test_pearson:  -0.718244551895809
============gbrt============
epoch:  2 pearson: ml_test_pearson:  0.6766983770833741
============xgb============
epoch:  2 pearson: ml_test_pearson:  0.653192648342539
============rfr============
epoch:  2 pearson: ml_test_pearson:  0.6188124082761725
===============模型average结果==================
epoch:  2 pearson: ml_test_pearson:  0.6755181746063985
[Epoch 3]
[batch 1] cost: 2.1642 training pearson: -0.8554525757107375
[batch 2] cost: 1.5329278 training pearson: -0.6983663836347003
[batch 3] cost: 1.4230145 training pearson: -0.8213187922254916
[batch 4] cost: 1.4897517 training pearson: -0.7118928564197008
[batch 5] cost: 1.655721 training pearson: -0.7921872792825574
[batch 6] cost: 1.4610515 training pearson: -0.6482723527614256
[batch 7] cost: 1.5498368 training pearson: -0.840328663301586
[batch 8] cost: 1.34135 training pearson: -0.7532245422494382
[batch 9] cost: 1.3024402 training pearson: -0.7453183918651032
[batch 10] cost: 1.4511707 training pearson: -0.6803733937433152
[batch 11] cost: 1.1469458 training pearson: -0.7283453010213801
[batch 12] cost: 1.4145327 training pearson: -0.7506837187751726
[batch 13] cost: 1.3896921 training pearson: -0.848899056850882
[batch 14] cost: 1.8004112 training pearson: -0.7203171177543436
[batch 15] cost: 1.3813329 training pearson: -0.6999722436921204
epoch:  3 pearson: test_pearson:  -0.7181094035869733
============gbrt============
epoch:  3 pearson: ml_test_pearson:  0.6633711503695834
============xgb============
epoch:  3 pearson: ml_test_pearson:  0.6734119139273634
============rfr============
epoch:  3 pearson: ml_test_pearson:  0.6253547912121433
===============模型average结果==================
epoch:  3 pearson: ml_test_pearson:  0.6744209889132474
[Epoch 4]
[batch 1] cost: 1.1297531 training pearson: -0.7130257107544141
[batch 2] cost: 1.0597137 training pearson: 0.6539904751043019
[batch 3] cost: 1.9493115 training pearson: 0.8818890758576038
[batch 4] cost: 1.1997887 training pearson: 0.5769978613495482
[batch 5] cost: 1.379571 training pearson: 0.7546520670473813
[batch 6] cost: 1.6972069 training pearson: 0.802061900536484
[batch 7] cost: 1.4493866 training pearson: 0.7149510175580115
[batch 8] cost: 1.6803789 training pearson: 0.7716548374956853
[batch 9] cost: 1.9080952 training pearson: 0.7273577624502611
[batch 10] cost: 1.499941 training pearson: 0.7196681709508962
[batch 11] cost: 1.5015464 training pearson: 0.8443628929943745
[batch 12] cost: 1.1031593 training pearson: 0.7045404373026617
[batch 13] cost: 1.7532573 training pearson: 0.7156163411099838
[batch 14] cost: 0.4584733 training pearson: 0.5940056994430425
[batch 15] cost: 1.4409415 training pearson: 0.828479506825268
epoch:  4 pearson: test_pearson:  0.7182505757392357
============gbrt============
epoch:  4 pearson: ml_test_pearson:  0.6727690440070696
============xgb============
epoch:  4 pearson: ml_test_pearson:  0.6812512136354127
============rfr============
epoch:  4 pearson: ml_test_pearson:  0.5970453131262777
===============模型average结果==================
epoch:  4 pearson: ml_test_pearson:  0.6683105256397779
[Epoch 5]
[batch 1] cost: 0.8385129 training pearson: 0.5470633359594819
[batch 2] cost: 0.96160036 training pearson: 0.7120242262353077
[batch 3] cost: 1.1377807 training pearson: 0.7678217320095848
[batch 4] cost: 1.4473605 training pearson: 0.7252466303541343
[batch 5] cost: 1.0246316 training pearson: 0.7626153566520758
[batch 6] cost: 1.7805187 training pearson: 0.7634643601318232
[batch 7] cost: 2.0670507 training pearson: 0.8109555494166839
[batch 8] cost: 0.96380126 training pearson: 0.5812140042643932
[batch 9] cost: 1.3610917 training pearson: 0.8035794299152234
[batch 10] cost: 1.5954837 training pearson: 0.8267724127986676
[batch 11] cost: 1.9085572 training pearson: 0.8522334726432672
[batch 12] cost: 1.8298881 training pearson: 0.6867735650929622
[batch 13] cost: 1.4378061 training pearson: 0.7603704858815376
[batch 14] cost: 1.4533767 training pearson: 0.7104471182680087
[batch 15] cost: 1.2308624 training pearson: 0.7343405534534773
epoch:  5 pearson: test_pearson:  0.7182588787402683
============gbrt============
epoch:  5 pearson: ml_test_pearson:  0.6677410833489206
============xgb============
epoch:  5 pearson: ml_test_pearson:  0.6776050387809154
============rfr============
epoch:  5 pearson: ml_test_pearson:  0.6213791769568132
===============模型average结果==================
epoch:  5 pearson: ml_test_pearson:  0.6762505799529582
[Epoch 6]
[batch 1] cost: 1.0824913 training pearson: 0.7044278894230478
[batch 2] cost: 1.2806462 training pearson: 0.7856720388684145
[batch 3] cost: 1.8449566 training pearson: 0.7792945340583094
[batch 4] cost: 1.8420597 training pearson: 0.8828663263467759
[batch 5] cost: 1.5775169 training pearson: 0.7959360907864674
[batch 6] cost: 1.3467096 training pearson: 0.5774820568578776
[batch 7] cost: 1.0949626 training pearson: 0.6913639947521417
[batch 8] cost: 1.634399 training pearson: 0.7545544467805383
[batch 9] cost: 0.8098352 training pearson: 0.4925079311740423
[batch 10] cost: 1.3618594 training pearson: 0.820347075239872
[batch 11] cost: 1.8877616 training pearson: 0.7653812943821793
[batch 12] cost: 1.3734021 training pearson: 0.8335920986928348
[batch 13] cost: 1.303941 training pearson: 0.7118406212443746
[batch 14] cost: 1.263095 training pearson: 0.70455458026387
[batch 15] cost: 1.089737 training pearson: 0.808181284221491
epoch:  6 pearson: test_pearson:  0.7183713022376648
============gbrt============
epoch:  6 pearson: ml_test_pearson:  0.6819181094454771
============xgb============
epoch:  6 pearson: ml_test_pearson:  0.6936936526638519
============rfr============
epoch:  6 pearson: ml_test_pearson:  0.6500204150192759
===============模型average结果==================
epoch:  6 pearson: ml_test_pearson:  0.6962844249011297
[Epoch 7]
[batch 1] cost: 1.0268407 training pearson: 0.7345293688753799
[batch 2] cost: 1.1462992 training pearson: 0.758881970841357
[batch 3] cost: 1.7539089 training pearson: 0.8421172804119421
[batch 4] cost: 2.0094333 training pearson: 0.7836571120720902
[batch 5] cost: 1.365802 training pearson: 0.6966208595999829
[batch 6] cost: 1.7241507 training pearson: 0.8353101967049299
[batch 7] cost: 0.9488995 training pearson: 0.5472515771376592
[batch 8] cost: 1.5179372 training pearson: 0.6637864658084432
[batch 9] cost: 1.6308658 training pearson: 0.8059881699443019
[batch 10] cost: 0.8852124 training pearson: 0.6287593775497295
[batch 11] cost: 1.7344284 training pearson: 0.8060867515665541
[batch 12] cost: 1.4104316 training pearson: 0.7577778854920422
[batch 13] cost: 1.2053559 training pearson: 0.729329548696711
[batch 14] cost: 1.3503739 training pearson: 0.7089573218223604
[batch 15] cost: 1.0640428 training pearson: 0.712992152711552
epoch:  7 pearson: test_pearson:  0.7182820597856119
============gbrt============
epoch:  7 pearson: ml_test_pearson:  0.6719865817057122
============xgb============
epoch:  7 pearson: ml_test_pearson:  0.6775438648544606
============rfr============
epoch:  7 pearson: ml_test_pearson:  0.6196548179138976
===============模型average结果==================
epoch:  7 pearson: ml_test_pearson:  0.6782995867684012
[Epoch 8]
[batch 1] cost: 1.208051 training pearson: 0.5811872811816313
[batch 2] cost: 1.1424965 training pearson: 0.7144197782656717
[batch 3] cost: 1.4277784 training pearson: 0.7712477561237074
[batch 4] cost: 1.6981251 training pearson: 0.8458817022453647
[batch 5] cost: 1.230458 training pearson: 0.6856480200307254
[batch 6] cost: 1.3039159 training pearson: 0.7916455577413422
[batch 7] cost: 0.88462067 training pearson: 0.7348252374520313
[batch 8] cost: 1.6042403 training pearson: 0.7645020017856031
[batch 9] cost: 1.5623028 training pearson: 0.7735048066568058
[batch 10] cost: 1.58072 training pearson: 0.7683971403312803
[batch 11] cost: 0.9920687 training pearson: 0.5993662209457832
[batch 12] cost: 1.6275641 training pearson: 0.7418598453028659
[batch 13] cost: 1.9536442 training pearson: 0.7145680338334799
[batch 14] cost: 1.2968858 training pearson: 0.7893162323162799
[batch 15] cost: 1.2635838 training pearson: 0.7971645236844644
epoch:  8 pearson: test_pearson:  0.7183480476354112
============gbrt============
epoch:  8 pearson: ml_test_pearson:  0.6989724011769216
============xgb============
epoch:  8 pearson: ml_test_pearson:  0.6997677300142578
============rfr============
epoch:  8 pearson: ml_test_pearson:  0.6520081906419276
===============模型average结果==================
epoch:  8 pearson: ml_test_pearson:  0.7066829294211904
[Epoch 9]
[batch 1] cost: 1.6113348 training pearson: 0.8254304461376851
[batch 2] cost: 1.5177237 training pearson: 0.6866265380766141
[batch 3] cost: 1.8732464 training pearson: 0.8089764183375213
[batch 4] cost: 2.5929718 training pearson: 0.7880984344816215
[batch 5] cost: 1.2190512 training pearson: 0.8349227573597746
[batch 6] cost: 0.98436 training pearson: 0.6492219208913235
[batch 7] cost: 1.3773215 training pearson: 0.6718193282378154
[batch 8] cost: 0.9015084 training pearson: 0.6851907424960524
[batch 9] cost: 0.91477036 training pearson: 0.6729861855823579
[batch 10] cost: 1.0374454 training pearson: 0.7887191880660602
[batch 11] cost: 0.98085284 training pearson: 0.7134467904954139
[batch 12] cost: 1.3847876 training pearson: 0.7947108162721922
[batch 13] cost: 1.8796463 training pearson: 0.8224058498794616
[batch 14] cost: 1.062819 training pearson: 0.655714664155363
[batch 15] cost: 1.3622814 training pearson: 0.6882360706700299
epoch:  9 pearson: test_pearson:  0.7184848326042971
============gbrt============
epoch:  9 pearson: ml_test_pearson:  0.6775694019011715
============xgb============
epoch:  9 pearson: ml_test_pearson:  0.67471075216255
============rfr============
epoch:  9 pearson: ml_test_pearson:  0.6369693768605267
===============模型average结果==================
epoch:  9 pearson: ml_test_pearson:  0.6794083726780237
[Epoch 10]
[batch 1] cost: 1.6407738 training pearson: 0.8040279078857652
[batch 2] cost: 1.183244 training pearson: 0.8138166395349359
[batch 3] cost: 1.3214756 training pearson: 0.8517998548981608
[batch 4] cost: 1.3837824 training pearson: 0.6480998239637141
[batch 5] cost: 1.9231656 training pearson: 0.7527709552953716
[batch 6] cost: 1.2916523 training pearson: 0.7376726830923596
[batch 7] cost: 1.4901724 training pearson: 0.7966971987548411
[batch 8] cost: 1.3409448 training pearson: 0.7709601025086034
[batch 9] cost: 1.2022166 training pearson: 0.7124108804246713
[batch 10] cost: 1.5914185 training pearson: 0.7941516597563103
[batch 11] cost: 1.5334278 training pearson: 0.6567123382562979
[batch 12] cost: 1.3043174 training pearson: 0.7530818204266754
[batch 13] cost: 1.3236045 training pearson: 0.7761665417737624
[batch 14] cost: 1.0081149 training pearson: 0.5470020351619033
[batch 15] cost: 1.1018624 training pearson: 0.7441832044802792
epoch:  10 pearson: test_pearson:  0.7170409162434176
============gbrt============
epoch:  10 pearson: ml_test_pearson:  0.6687491223140324
============xgb============
epoch:  10 pearson: ml_test_pearson:  0.6781684984409412
============rfr============
epoch:  10 pearson: ml_test_pearson:  0.6409974376562789
===============模型average结果==================
epoch:  10 pearson: ml_test_pearson:  0.6817688407394522
[Epoch 11]
[batch 1] cost: 1.7147381 training pearson: 0.7844914151937303
[batch 2] cost: 2.23419 training pearson: 0.7650404688227972
[batch 3] cost: 1.3910016 training pearson: 0.8222786001011247
[batch 4] cost: 1.4778885 training pearson: 0.7583234511598564
[batch 5] cost: 1.2066604 training pearson: 0.767673143901017
[batch 6] cost: 0.9303548 training pearson: 0.5399531043359591
[batch 7] cost: 1.2153492 training pearson: 0.7307933680831734
[batch 8] cost: 1.7451184 training pearson: 0.7640894690349099
[batch 9] cost: 1.2033192 training pearson: 0.7777451080529956
[batch 10] cost: 1.3439112 training pearson: 0.7859724477802769
[batch 11] cost: 1.2938329 training pearson: 0.5813193444301691
[batch 12] cost: 1.6180576 training pearson: 0.8143522479611217
[batch 13] cost: 1.5842227 training pearson: 0.8467626806579068
[batch 14] cost: 1.1728098 training pearson: 0.7618940424863692
[batch 15] cost: 0.46485466 training pearson: 0.5233829510777195
epoch:  11 pearson: test_pearson:  0.7170420657468527
============gbrt============
epoch:  11 pearson: ml_test_pearson:  0.6808862600144633
============xgb============
epoch:  11 pearson: ml_test_pearson:  0.6809161326093908
============rfr============
epoch:  11 pearson: ml_test_pearson:  0.6781120690675986
===============模型average结果==================
epoch:  11 pearson: ml_test_pearson:  0.7002010491271693
[Epoch 12]
[batch 1] cost: 1.6255435 training pearson: 0.7939357439177404
[batch 2] cost: 0.98542124 training pearson: 0.7400728809191197
[batch 3] cost: 1.3086536 training pearson: 0.7216111842385365
[batch 4] cost: 1.5945586 training pearson: 0.668576166398424
[batch 5] cost: 0.7158565 training pearson: 0.6614435636029572
[batch 6] cost: 1.57483 training pearson: 0.6510226633836372
[batch 7] cost: 1.3916472 training pearson: 0.6661710452795425
[batch 8] cost: 1.0631614 training pearson: 0.7036309488697595
[batch 9] cost: 0.8663961 training pearson: 0.6243105246157037
[batch 10] cost: 2.0667083 training pearson: 0.783401190000643
[batch 11] cost: 1.0947661 training pearson: 0.7307723076178625
[batch 12] cost: 1.594859 training pearson: 0.781448830067461
[batch 13] cost: 1.9028691 training pearson: 0.8834802337090347
[batch 14] cost: 1.2703767 training pearson: 0.8648371102678396
[batch 15] cost: 1.4932681 training pearson: 0.7595074307611034
epoch:  12 pearson: test_pearson:  0.7081155940345317
============gbrt============
epoch:  12 pearson: ml_test_pearson:  0.6680206244362448
============xgb============
epoch:  12 pearson: ml_test_pearson:  0.6432134705959248
============rfr============
epoch:  12 pearson: ml_test_pearson:  0.6289697755343711
===============模型average结果==================
epoch:  12 pearson: ml_test_pearson:  0.6664227350353357
[Epoch 13]
[batch 1] cost: 1.0501616 training pearson: 0.7054435602747727
[batch 2] cost: 1.0744323 training pearson: 0.7359004027000706
[batch 3] cost: 1.3681903 training pearson: 0.7529831464341638
[batch 4] cost: 1.2150441 training pearson: 0.7390600328660779
[batch 5] cost: 1.2747436 training pearson: 0.7266661341626723
[batch 6] cost: 1.5521735 training pearson: 0.7416490096866488
[batch 7] cost: 1.685008 training pearson: 0.6932625813991183
[batch 8] cost: 1.6271778 training pearson: 0.7593405013766766
[batch 9] cost: 1.4080817 training pearson: 0.7771172937172273
[batch 10] cost: 1.6552484 training pearson: 0.6979460112044229
[batch 11] cost: 1.1993918 training pearson: 0.5773089613545361
[batch 12] cost: 1.6618763 training pearson: 0.49895953130994486
[batch 13] cost: 1.3723614 training pearson: 0.4220502162179042
[batch 14] cost: 1.3383768 training pearson: 0.550926603025853
[batch 15] cost: 0.9248799 training pearson: 0.22966138078110496
epoch:  13 pearson: test_pearson:  0.6213791073186716
============gbrt============
epoch:  13 pearson: ml_test_pearson:  0.6666463443907915
============xgb============
epoch:  13 pearson: ml_test_pearson:  0.6704490096252619
============rfr============
epoch:  13 pearson: ml_test_pearson:  0.6498755405482565
===============模型average结果==================
epoch:  13 pearson: ml_test_pearson:  0.6773956385135999
[Epoch 14]
[batch 1] cost: 1.7314813 training pearson: 0.6930219174623035
[batch 2] cost: 1.21749 training pearson: 0.7037855332124167
[batch 3] cost: 1.2787329 training pearson: 0.7127811521290901
[batch 4] cost: 1.0602525 training pearson: 0.7330747878501691
[batch 5] cost: 1.3385388 training pearson: 0.6159582387304341
[batch 6] cost: 1.6398822 training pearson: 0.5210311583571501
[batch 7] cost: 1.2015618 training pearson: 0.5202506558033315
[batch 8] cost: 1.1750429 training pearson: 0.39313969808800764
[batch 9] cost: 1.2623707 training pearson: 0.8222640045940738
[batch 10] cost: 0.9452518 training pearson: 0.6330109362684678
[batch 11] cost: 1.9567012 training pearson: 0.7226238983129738
[batch 12] cost: 1.4270887 training pearson: 0.7678423078910768
[batch 13] cost: 1.9390054 training pearson: 0.8025127120391173
[batch 14] cost: 0.77889556 training pearson: 0.4346093754594435
[batch 15] cost: 1.0651425 training pearson: 0.5613365077448071
epoch:  14 pearson: test_pearson:  0.7203672609618947
============gbrt============
epoch:  14 pearson: ml_test_pearson:  0.6863011712163672
============xgb============
epoch:  14 pearson: ml_test_pearson:  0.7091725181520743
============rfr============
epoch:  14 pearson: ml_test_pearson:  0.6458663723800177
===============模型average结果==================
epoch:  14 pearson: ml_test_pearson:  0.6926893227189274
[Epoch 15]
[batch 1] cost: 1.0927448 training pearson: 0.7740457203441659
[batch 2] cost: 1.4660922 training pearson: 0.7989306562815524
[batch 3] cost: 1.3613375 training pearson: 0.7564472270946881
[batch 4] cost: 1.0646467 training pearson: 0.7226823220286918
[batch 5] cost: 1.4396582 training pearson: 0.6913633844172807
[batch 6] cost: 1.3446616 training pearson: 0.7423422276515259
[batch 7] cost: 0.8577446 training pearson: 0.7363019316626119
[batch 8] cost: 1.3257185 training pearson: 0.7622836835086445
[batch 9] cost: 1.3188183 training pearson: 0.7064095593113054
[batch 10] cost: 2.4913955 training pearson: 0.8811547168177092
[batch 11] cost: 0.92770654 training pearson: 0.7469522327687135
[batch 12] cost: 1.6560714 training pearson: 0.8036309247464304
[batch 13] cost: 0.40483165 training pearson: 0.53639852737042
[batch 14] cost: 2.0915627 training pearson: 0.7289892408659808
[batch 15] cost: 1.6257792 training pearson: 0.764878722936452
epoch:  15 pearson: test_pearson:  0.7185597905135102
============gbrt============
epoch:  15 pearson: ml_test_pearson:  0.6694493680723721
============xgb============
epoch:  15 pearson: ml_test_pearson:  0.6803254082679976
============rfr============
epoch:  15 pearson: ml_test_pearson:  0.629955562661253
===============模型average结果==================
epoch:  15 pearson: ml_test_pearson:  0.6718139145929732
[Epoch 16]
[batch 1] cost: 0.965352 training pearson: 0.6056500522284126
[batch 2] cost: 1.1418654 training pearson: 0.6802810843589571
[batch 3] cost: 1.9959064 training pearson: 0.8058143661462521
[batch 4] cost: 1.1711117 training pearson: 0.6424110611947633
[batch 5] cost: 1.7426987 training pearson: 0.7991498252189237
[batch 6] cost: 1.3144314 training pearson: 0.7138766171765794
[batch 7] cost: 1.1725973 training pearson: 0.6807906625405515
[batch 8] cost: 0.8635462 training pearson: 0.7101498566871931
[batch 9] cost: 1.3298154 training pearson: 0.7246480996822239
[batch 10] cost: 1.2714688 training pearson: 0.8422905838123573
[batch 11] cost: 1.6080828 training pearson: 0.7076609865993314
[batch 12] cost: 1.2376714 training pearson: 0.7045306432701631
[batch 13] cost: 1.5064813 training pearson: 0.8675781781873373
[batch 14] cost: 1.1995147 training pearson: 0.7378094035357371
[batch 15] cost: 1.8543602 training pearson: 0.41136441748612373
epoch:  16 pearson: test_pearson:  0.7184752309189761
============gbrt============
epoch:  16 pearson: ml_test_pearson:  0.6908556372585273
============xgb============
epoch:  16 pearson: ml_test_pearson:  0.7116694717679972
============rfr============
epoch:  16 pearson: ml_test_pearson:  0.6431858096917222
===============模型average结果==================
epoch:  16 pearson: ml_test_pearson:  0.692121011920364
[Epoch 17]
[batch 1] cost: 0.99425447 training pearson: 0.5251439714258479
[batch 2] cost: 1.5222788 training pearson: 0.7909387494521549
[batch 3] cost: 0.8533217 training pearson: 0.5472298261276691
[batch 4] cost: 1.5846742 training pearson: 0.7621957620828135
[batch 5] cost: 1.5119764 training pearson: 0.7608310230338955
[batch 6] cost: 0.8025259 training pearson: 0.7125524175708396
[batch 7] cost: 1.6697458 training pearson: 0.7856433731602764
[batch 8] cost: 1.8476043 training pearson: 0.8492805342088282
[batch 9] cost: 1.4761223 training pearson: 0.8233862322894884
[batch 10] cost: 2.3098211 training pearson: 0.7558314853684345
[batch 11] cost: 1.1830459 training pearson: 0.8162098075105989
[batch 12] cost: 0.95756334 training pearson: 0.5613567165697199
[batch 13] cost: 1.2739118 training pearson: 0.7855513719242859
[batch 14] cost: 1.5326205 training pearson: 0.8193042115085304
[batch 15] cost: 0.8700293 training pearson: 0.6776513750831873
epoch:  17 pearson: test_pearson:  0.7176139828914624
============gbrt============
epoch:  17 pearson: ml_test_pearson:  0.666755033419754
============xgb============
epoch:  17 pearson: ml_test_pearson:  0.6845494592950779
============rfr============
epoch:  17 pearson: ml_test_pearson:  0.6339626322169084
===============模型average结果==================
epoch:  17 pearson: ml_test_pearson:  0.6744992330013523
[Epoch 18]
[batch 1] cost: 1.1034397 training pearson: 0.7363909720084365
[batch 2] cost: 1.2343236 training pearson: 0.43938868989594865
[batch 3] cost: 0.7713685 training pearson: 0.7221840874745142
[batch 4] cost: 1.4944438 training pearson: 0.8722947391447767
[batch 5] cost: 1.29927 training pearson: 0.7563731355394859
[batch 6] cost: 0.99890554 training pearson: 0.7930658065253374
[batch 7] cost: 1.4681811 training pearson: 0.6896894240531074
[batch 8] cost: 1.4644355 training pearson: 0.7748373870363574
[batch 9] cost: 0.97987074 training pearson: 0.6934332299560652
[batch 10] cost: 1.6651373 training pearson: 0.7657110376535342
[batch 11] cost: 0.91153383 training pearson: 0.5423180363325331
[batch 12] cost: 1.5706198 training pearson: 0.7662984968083776
[batch 13] cost: 1.1632295 training pearson: 0.7851889756239915
[batch 14] cost: 1.2775382 training pearson: 0.6706012043840588
[batch 15] cost: 2.878809 training pearson: 0.8572594232292734
epoch:  18 pearson: test_pearson:  0.7182637653507726
============gbrt============
epoch:  18 pearson: ml_test_pearson:  0.6734298048974569
============xgb============
epoch:  18 pearson: ml_test_pearson:  0.6805591215799438
============rfr============
epoch:  18 pearson: ml_test_pearson:  0.6414332970570472
===============模型average结果==================
epoch:  18 pearson: ml_test_pearson:  0.6824935923288457
[Epoch 19]
[batch 1] cost: 0.9425867 training pearson: 0.7946933385579276
[batch 2] cost: 1.1483475 training pearson: 0.5101586598553541
[batch 3] cost: 1.4012117 training pearson: 0.774874804112363
[batch 4] cost: 1.0207368 training pearson: 0.6434368836280849
[batch 5] cost: 1.9241388 training pearson: 0.7495033956586404
[batch 6] cost: 1.3772545 training pearson: 0.7567661218221496
[batch 7] cost: 1.1350641 training pearson: 0.7737441943607581
[batch 8] cost: 1.6339194 training pearson: 0.698488050519246
[batch 9] cost: 1.2034202 training pearson: 0.8224996189613007
[batch 10] cost: 1.0187607 training pearson: 0.6586732342613638
[batch 11] cost: 1.7871616 training pearson: 0.8299250725868567
[batch 12] cost: 1.6299863 training pearson: 0.8351225195230092
[batch 13] cost: 1.2814932 training pearson: 0.8747734346654583
[batch 14] cost: 0.9787913 training pearson: 0.3880969195324485
[batch 15] cost: 1.7200276 training pearson: 0.7524998493449019
epoch:  19 pearson: test_pearson:  0.7186813536229971
============gbrt============
epoch:  19 pearson: ml_test_pearson:  0.6642538437616888
============xgb============
epoch:  19 pearson: ml_test_pearson:  0.6595726962982779
============rfr============
epoch:  19 pearson: ml_test_pearson:  0.6443370124843113
===============模型average结果==================
epoch:  19 pearson: ml_test_pearson:  0.67604802474909
[Epoch 20]
[batch 1] cost: 1.089489 training pearson: 0.7307064847202775
[batch 2] cost: 1.4190297 training pearson: 0.7574072235684172
[batch 3] cost: 0.833977 training pearson: 0.4024870256618695
[batch 4] cost: 0.8788008 training pearson: 0.6322604863759533
[batch 5] cost: 1.3921704 training pearson: 0.7033231663145265
[batch 6] cost: 1.3584813 training pearson: 0.8507503707382771
[batch 7] cost: 2.0415154 training pearson: 0.8354024648145226
[batch 8] cost: 1.2716169 training pearson: 0.8277069753271076
[batch 9] cost: 1.2072978 training pearson: 0.5349088893109666
[batch 10] cost: 1.39016 training pearson: 0.869458981158227
[batch 11] cost: 1.9092355 training pearson: 0.7598377122606716
[batch 12] cost: 0.83998847 training pearson: 0.6102958917057054
[batch 13] cost: 1.4403975 training pearson: 0.799616728634179
[batch 14] cost: 1.3821383 training pearson: 0.6574317265866771
[batch 15] cost: 1.7071815 training pearson: 0.8107295042967116
epoch:  20 pearson: test_pearson:  0.7163450540427602
============gbrt============
epoch:  20 pearson: ml_test_pearson:  0.6774278135648782
============xgb============
epoch:  20 pearson: ml_test_pearson:  0.6666196316365609
============rfr============
epoch:  20 pearson: ml_test_pearson:  0.6604326983860829
===============模型average结果==================
epoch:  20 pearson: ml_test_pearson:  0.6933998299162923
[Epoch 21]
[batch 1] cost: 1.0008323 training pearson: 0.6165071157209653
[batch 2] cost: 1.6865774 training pearson: 0.8413047438576574
[batch 3] cost: 1.1106204 training pearson: 0.46571279984716807
[batch 4] cost: 1.1724366 training pearson: 0.587419298112773
[batch 5] cost: 1.0444064 training pearson: 0.5487764287450598
[batch 6] cost: 1.9656253 training pearson: 0.8367567005354163
[batch 7] cost: 1.5686535 training pearson: 0.856461347306041
[batch 8] cost: 1.1361682 training pearson: 0.789887853705445
[batch 9] cost: 0.8818236 training pearson: 0.6135462808019946
[batch 10] cost: 0.68575835 training pearson: 0.5024152903527852
[batch 11] cost: 1.3964654 training pearson: 0.7884952657540794
[batch 12] cost: 1.6671335 training pearson: 0.7217678342362424
[batch 13] cost: 1.5708739 training pearson: 0.7908610423039862
[batch 14] cost: 1.3307658 training pearson: 0.785933227178713
[batch 15] cost: 1.873169 training pearson: 0.8072418264592639
epoch:  21 pearson: test_pearson:  0.7164082171243236
============gbrt============
epoch:  21 pearson: ml_test_pearson:  0.680433326162555
============xgb============
epoch:  21 pearson: ml_test_pearson:  0.6647492123268919
============rfr============
epoch:  21 pearson: ml_test_pearson:  0.6451895161514173
===============模型average结果==================
epoch:  21 pearson: ml_test_pearson:  0.6824345153756972
[Epoch 22]
[batch 1] cost: 1.4009881 training pearson: 0.6975504366618684
[batch 2] cost: 1.6551585 training pearson: 0.7448517867048277
[batch 3] cost: 1.32335 training pearson: 0.733874549933971
[batch 4] cost: 0.9899186 training pearson: 0.6640506133958759
[batch 5] cost: 1.024044 training pearson: 0.8060799339380449
[batch 6] cost: 0.76763886 training pearson: 0.646401330561157
[batch 7] cost: 1.4508553 training pearson: 0.8370189048747809
[batch 8] cost: 1.6723981 training pearson: 0.8198069771140087
[batch 9] cost: 1.5008099 training pearson: 0.8638346403051744
[batch 10] cost: 1.841764 training pearson: 0.7840832452229061
[batch 11] cost: 1.6218076 training pearson: 0.7873533337887358
[batch 12] cost: 1.1192555 training pearson: 0.5768726454515503
[batch 13] cost: 1.2347335 training pearson: 0.6247979712413868
[batch 14] cost: 1.3249898 training pearson: 0.8105560287504325
[batch 15] cost: 1.0325105 training pearson: 0.6638361461955543
epoch:  22 pearson: test_pearson:  0.7024453387508117
============gbrt============
epoch:  22 pearson: ml_test_pearson:  0.6831974174730011
============xgb============
epoch:  22 pearson: ml_test_pearson:  0.6626906910721602
============rfr============
epoch:  22 pearson: ml_test_pearson:  0.6772544381559711
===============模型average结果==================
epoch:  22 pearson: ml_test_pearson:  0.6924670779703754
[Epoch 23]
[batch 1] cost: 1.5392871 training pearson: 0.7504199234992945
[batch 2] cost: 1.2597651 training pearson: 0.7533327533748317
[batch 3] cost: 1.3758808 training pearson: 0.7578953003331694
[batch 4] cost: 1.5298022 training pearson: 0.815581230472427
[batch 5] cost: 1.4347295 training pearson: 0.7434805771214461
[batch 6] cost: 1.6427872 training pearson: 0.778718745141336
[batch 7] cost: 1.5237753 training pearson: 0.7264504518813799
[batch 8] cost: 0.8786139 training pearson: 0.6928704413850529
[batch 9] cost: 1.1716338 training pearson: 0.6863049495742962
[batch 10] cost: 0.91276354 training pearson: 0.6493647721968494
[batch 11] cost: 1.4366897 training pearson: 0.8060131984617229
[batch 12] cost: 1.3344665 training pearson: 0.7999348187348039
[batch 13] cost: 0.58443564 training pearson: 0.6006106379971535
[batch 14] cost: 1.4782101 training pearson: 0.7287664165064113
[batch 15] cost: 1.8236157 training pearson: 0.8255884387645014
epoch:  23 pearson: test_pearson:  0.7143971611264228
============gbrt============
epoch:  23 pearson: ml_test_pearson:  0.6785208547506679
============xgb============
epoch:  23 pearson: ml_test_pearson:  0.671487083709125
============rfr============
epoch:  23 pearson: ml_test_pearson:  0.6701951315926838
===============模型average结果==================
epoch:  23 pearson: ml_test_pearson:  0.6910464897205101
[Epoch 24]
[batch 1] cost: 0.7841184 training pearson: 0.6891838847730736
[batch 2] cost: 1.6847299 training pearson: 0.8138459424151457
[batch 3] cost: 0.8980696 training pearson: 0.6977045325542784
[batch 4] cost: 0.8877574 training pearson: 0.7372376899171217
[batch 5] cost: 1.4375772 training pearson: 0.7309806381720164
[batch 6] cost: 1.0536623 training pearson: 0.734205029400085
[batch 7] cost: 1.2448401 training pearson: 0.7462041425243039
[batch 8] cost: 1.2925688 training pearson: 0.6707696468357643
[batch 9] cost: 1.5425693 training pearson: 0.7315433703101396
[batch 10] cost: 1.1869876 training pearson: 0.8413729679414896
[batch 11] cost: 1.1443156 training pearson: 0.6939532083947632
[batch 12] cost: 1.5336581 training pearson: 0.7975954041612853
[batch 13] cost: 2.0227203 training pearson: 0.765696568359232
[batch 14] cost: 1.9025993 training pearson: 0.8196691115446957
[batch 15] cost: 1.2200401 training pearson: 0.7217385166920031
epoch:  24 pearson: test_pearson:  0.7101504023217869
============gbrt============
epoch:  24 pearson: ml_test_pearson:  0.676986059462273
============xgb============
epoch:  24 pearson: ml_test_pearson:  0.6562331362422003
============rfr============
epoch:  24 pearson: ml_test_pearson:  0.6363665819618762
===============模型average结果==================
epoch:  24 pearson: ml_test_pearson:  0.6749335240570608
[Epoch 25]
[batch 1] cost: 1.3177636 training pearson: 0.7089076166777147
[batch 2] cost: 1.4658197 training pearson: 0.7822112095110444
[batch 3] cost: 0.90439796 training pearson: 0.6254466535134813
[batch 4] cost: 1.6148938 training pearson: 0.8082290190764209
[batch 5] cost: 1.0806484 training pearson: 0.7399553123796234
[batch 6] cost: 1.6772113 training pearson: 0.6461017959885219
[batch 7] cost: 1.6426953 training pearson: 0.8335907226432827
[batch 8] cost: 0.6541519 training pearson: 0.5731112943601934
[batch 9] cost: 1.2958673 training pearson: 0.763740480401062
[batch 10] cost: 1.3162006 training pearson: 0.8758042462087211
[batch 11] cost: 1.1653098 training pearson: 0.7592447102336901
[batch 12] cost: 2.2190828 training pearson: 0.8469578637465287
[batch 13] cost: 1.4975971 training pearson: 0.8115450862815664
[batch 14] cost: 0.8887154 training pearson: 0.6990681507213692
[batch 15] cost: 1.0811459 training pearson: 0.6108827749155709
epoch:  25 pearson: test_pearson:  0.7187292016395957
============gbrt============
epoch:  25 pearson: ml_test_pearson:  0.6942714514540153
============xgb============
epoch:  25 pearson: ml_test_pearson:  0.6810977774147422
============rfr============
epoch:  25 pearson: ml_test_pearson:  0.6538289689365238
===============模型average结果==================
epoch:  25 pearson: ml_test_pearson:  0.691434583202864
[Epoch 26]
[batch 1] cost: 1.5230724 training pearson: 0.81737537483126
[batch 2] cost: 1.5632269 training pearson: 0.8186547569679441
[batch 3] cost: 1.5169287 training pearson: 0.7606677919147131
[batch 4] cost: 1.7696748 training pearson: 0.7769316203218952
[batch 5] cost: 0.92431456 training pearson: 0.7897251878629333
[batch 6] cost: 0.7498346 training pearson: 0.40828750744125636
[batch 7] cost: 1.2520605 training pearson: 0.8157131561334513
[batch 8] cost: 1.566003 training pearson: 0.7724640545954684
[batch 9] cost: 1.4205713 training pearson: 0.7632353257522082
[batch 10] cost: 1.20963 training pearson: 0.8180476880236726
[batch 11] cost: 1.2998723 training pearson: 0.7395476210318842
[batch 12] cost: 1.6479993 training pearson: 0.853955318813142
[batch 13] cost: 1.3698212 training pearson: 0.6398169509799216
[batch 14] cost: 0.988976 training pearson: 0.6455843097703344
[batch 15] cost: 0.9535962 training pearson: 0.7524001412672356
epoch:  26 pearson: test_pearson:  0.7184484313238023
============gbrt============
epoch:  26 pearson: ml_test_pearson:  0.6740449075583314
============xgb============
epoch:  26 pearson: ml_test_pearson:  0.6601455455586205
============rfr============
epoch:  26 pearson: ml_test_pearson:  0.6770785772478052
===============模型average结果==================
epoch:  26 pearson: ml_test_pearson:  0.6919417061960448
[Epoch 27]
[batch 1] cost: 1.455736 training pearson: 0.6429534742729962
[batch 2] cost: 2.1472745 training pearson: 0.8537645690124148
[batch 3] cost: 0.95492154 training pearson: 0.7857833459082756
[batch 4] cost: 1.1086773 training pearson: 0.6699921627813208
[batch 5] cost: 0.701671 training pearson: 0.5494078497924684
[batch 6] cost: 1.902367 training pearson: 0.861474322576773
[batch 7] cost: 0.8397026 training pearson: 0.7578180396656881
[batch 8] cost: 1.4716343 training pearson: 0.7442115855009046
[batch 9] cost: 1.3088248 training pearson: 0.7511550871959856
[batch 10] cost: 1.4674509 training pearson: 0.7990221729884878
[batch 11] cost: 1.8541092 training pearson: 0.8187778124568883
[batch 12] cost: 1.2489655 training pearson: 0.8097383835209371
[batch 13] cost: 1.2048217 training pearson: 0.6785248604365886
[batch 14] cost: 1.0574129 training pearson: 0.5677243948207331
[batch 15] cost: 0.97666353 training pearson: 0.6466100732490989
epoch:  27 pearson: test_pearson:  0.7211701551859048
============gbrt============
epoch:  27 pearson: ml_test_pearson:  0.6681172150582027
============xgb============
epoch:  27 pearson: ml_test_pearson:  0.6768008796662485
============rfr============
epoch:  27 pearson: ml_test_pearson:  0.6496108151941512
===============模型average结果==================
epoch:  27 pearson: ml_test_pearson:  0.6813152698982765
[Epoch 28]
[batch 1] cost: 1.8894553 training pearson: 0.7597146878443882
[batch 2] cost: 0.96225595 training pearson: 0.5197136455595468
[batch 3] cost: 1.1944562 training pearson: 0.7630883563520102
[batch 4] cost: 1.5457819 training pearson: 0.6599799200174801
[batch 5] cost: 1.4576889 training pearson: 0.8642421807848238
[batch 6] cost: 0.97087646 training pearson: 0.7501743172340837
[batch 7] cost: 1.2537887 training pearson: 0.6267915593833085
[batch 8] cost: 0.96169287 training pearson: 0.7641169322656188
[batch 9] cost: 1.7871622 training pearson: 0.8070399759980168
[batch 10] cost: 1.1104847 training pearson: 0.7774177135476491
[batch 11] cost: 1.1790984 training pearson: 0.8000533020417862
[batch 12] cost: 1.38513 training pearson: 0.7796567585760255
[batch 13] cost: 1.4905771 training pearson: 0.7981200333014623
[batch 14] cost: 1.3657179 training pearson: 0.8050790521504315
[batch 15] cost: 1.0855995 training pearson: 0.7505506393137295
epoch:  28 pearson: test_pearson:  0.720998339429341
============gbrt============
epoch:  28 pearson: ml_test_pearson:  0.6737327878141169
============xgb============
epoch:  28 pearson: ml_test_pearson:  0.6651385008268536
============rfr============
epoch:  28 pearson: ml_test_pearson:  0.6475726947090383
===============模型average结果==================
epoch:  28 pearson: ml_test_pearson:  0.6793656442637813
[Epoch 29]
[batch 1] cost: 1.7962472 training pearson: 0.7600451365343711
[batch 2] cost: 1.0471547 training pearson: 0.6740702426302528
[batch 3] cost: 1.2938107 training pearson: 0.8300874613918713
[batch 4] cost: 0.98177934 training pearson: 0.7747419821030486
[batch 5] cost: 1.6457425 training pearson: 0.8350960309767448
[batch 6] cost: 0.6731365 training pearson: 0.6083070075331091
[batch 7] cost: 1.553871 training pearson: 0.7085717871058754
[batch 8] cost: 1.4853436 training pearson: 0.8355814259541858
[batch 9] cost: 1.4029385 training pearson: 0.7216925693799261
[batch 10] cost: 1.0673432 training pearson: 0.7753006870586934
[batch 11] cost: 0.9155338 training pearson: 0.712916340237345
[batch 12] cost: 1.6421772 training pearson: 0.805850141426464
[batch 13] cost: 1.6666127 training pearson: 0.723457042479612
[batch 14] cost: 1.3034918 training pearson: 0.7957478859045166
[batch 15] cost: 1.1237187 training pearson: 0.7793905505141374
epoch:  29 pearson: test_pearson:  0.7175211104006266
============gbrt============
epoch:  29 pearson: ml_test_pearson:  0.6902112104531755
============xgb============
epoch:  29 pearson: ml_test_pearson:  0.6661023168711081
============rfr============
epoch:  29 pearson: ml_test_pearson:  0.6687382150143707
===============模型average结果==================
epoch:  29 pearson: ml_test_pearson:  0.6919126805645456
[Epoch 30]
[batch 1] cost: 1.6680228 training pearson: 0.8103053422005677
[batch 2] cost: 1.3584644 training pearson: 0.8114755888047509
[batch 3] cost: 1.3057247 training pearson: 0.8257417788418722
[batch 4] cost: 1.7558943 training pearson: 0.764066578569842
[batch 5] cost: 1.6371858 training pearson: 0.6968331081012061
[batch 6] cost: 1.04735 training pearson: 0.628182224591682
[batch 7] cost: 1.6522744 training pearson: 0.7916900065380367
[batch 8] cost: 1.2198918 training pearson: 0.8046688891087422
[batch 9] cost: 1.0015672 training pearson: 0.6186488602816709
[batch 10] cost: 1.1853311 training pearson: 0.7956106585811203
[batch 11] cost: 1.1487937 training pearson: 0.811841015652707
[batch 12] cost: 1.1756352 training pearson: 0.762351714027098
[batch 13] cost: 1.2190684 training pearson: 0.6618021899103265
[batch 14] cost: 1.1956292 training pearson: 0.7246217079962052
[batch 15] cost: 0.97999954 training pearson: 0.6669091885965437
epoch:  30 pearson: test_pearson:  0.7177953572380854
============gbrt============
epoch:  30 pearson: ml_test_pearson:  0.674618046109064
============xgb============
epoch:  30 pearson: ml_test_pearson:  0.656502387454813
============rfr============
epoch:  30 pearson: ml_test_pearson:  0.6342237170731779
===============模型average结果==================
epoch:  30 pearson: ml_test_pearson:  0.6706999954028425
[Epoch 31]
[batch 1] cost: 1.3083884 training pearson: 0.6520599486706988
[batch 2] cost: 1.352046 training pearson: 0.8046149241742625
[batch 3] cost: 1.1818645 training pearson: 0.7750065234891738
[batch 4] cost: 1.3784003 training pearson: 0.7366734056818265
[batch 5] cost: 1.4918509 training pearson: 0.7843777770643392
[batch 6] cost: 1.8999883 training pearson: 0.826099670951173
[batch 7] cost: 0.5958722 training pearson: 0.5780550771700771
[batch 8] cost: 1.1173239 training pearson: 0.7493778690084958
[batch 9] cost: 1.7396519 training pearson: 0.8652060400729332
[batch 10] cost: 1.5223001 training pearson: 0.814091137022062
[batch 11] cost: 1.122089 training pearson: 0.6506161149881602
[batch 12] cost: 0.66072106 training pearson: 0.5207983361932371
[batch 13] cost: 1.2208686 training pearson: 0.8170493159588479
[batch 14] cost: 1.6438197 training pearson: 0.7713317498463362
[batch 15] cost: 1.2382212 training pearson: 0.748949765500546
epoch:  31 pearson: test_pearson:  0.7193649525327794
============gbrt============
epoch:  31 pearson: ml_test_pearson:  0.6833460078815873
============xgb============
epoch:  31 pearson: ml_test_pearson:  0.6901072780717465
============rfr============
epoch:  31 pearson: ml_test_pearson:  0.6407512205983722
===============模型average结果==================
epoch:  31 pearson: ml_test_pearson:  0.6854052312304844
[Epoch 32]
[batch 1] cost: 1.5764618 training pearson: 0.7526191754428913
[batch 2] cost: 1.0787277 training pearson: 0.8029415099049914
[batch 3] cost: 1.137145 training pearson: 0.7190459970546629
[batch 4] cost: 1.0186168 training pearson: 0.600218606098099
[batch 5] cost: 0.95631427 training pearson: 0.6723516137381633
[batch 6] cost: 0.86154634 training pearson: 0.6854249848872961
[batch 7] cost: 1.9568936 training pearson: 0.7726398120244955
[batch 8] cost: 1.4750394 training pearson: 0.7684205670109688
[batch 9] cost: 1.3508176 training pearson: 0.870163475733326
[batch 10] cost: 1.1957666 training pearson: 0.7724201633774179
[batch 11] cost: 1.1233063 training pearson: 0.811889984083557
[batch 12] cost: 0.77828264 training pearson: 0.7122247492544758
[batch 13] cost: 1.7251883 training pearson: 0.8137197817400476
[batch 14] cost: 1.4758544 training pearson: 0.6941397294055166
[batch 15] cost: 1.6562445 training pearson: 0.7950157870136922
epoch:  32 pearson: test_pearson:  0.7196586628106854
============gbrt============
epoch:  32 pearson: ml_test_pearson:  0.6875039391638972
============xgb============
epoch:  32 pearson: ml_test_pearson:  0.6719765896448817
============rfr============
epoch:  32 pearson: ml_test_pearson:  0.6455151205208067
===============模型average结果==================
epoch:  32 pearson: ml_test_pearson:  0.6853009998703161
[Epoch 33]
[batch 1] cost: 1.738878 training pearson: 0.7953570387203704
[batch 2] cost: 1.170766 training pearson: 0.7801287086846099
[batch 3] cost: 2.0047424 training pearson: 0.778033988906051
[batch 4] cost: 0.7366442 training pearson: 0.6533595633226177
[batch 5] cost: 1.646707 training pearson: 0.7335320218914066
[batch 6] cost: 0.8814357 training pearson: 0.6360892412109942
[batch 7] cost: 1.3134159 training pearson: 0.7808412349988679
[batch 8] cost: 0.92979264 training pearson: 0.7695763450635786
[batch 9] cost: 1.3749222 training pearson: 0.821839254054556
[batch 10] cost: 1.351215 training pearson: 0.8339207495114805
[batch 11] cost: 1.3156629 training pearson: 0.6059146159562864
[batch 12] cost: 1.5516014 training pearson: 0.8061896885079854
[batch 13] cost: 1.3826265 training pearson: 0.7784245779195373
[batch 14] cost: 0.75370836 training pearson: 0.49889505062317635
[batch 15] cost: 1.1760463 training pearson: 0.7338821883431764
epoch:  33 pearson: test_pearson:  0.7198506779808049
============gbrt============
epoch:  33 pearson: ml_test_pearson:  0.6916053354450622
============xgb============
epoch:  33 pearson: ml_test_pearson:  0.6794061071124018
============rfr============
epoch:  33 pearson: ml_test_pearson:  0.6641420111183558
===============模型average结果==================
epoch:  33 pearson: ml_test_pearson:  0.6918192432872604
[Epoch 34]
[batch 1] cost: 0.9299689 training pearson: 0.6919780075421509
[batch 2] cost: 0.9763873 training pearson: 0.6673266135413544
[batch 3] cost: 1.9338299 training pearson: 0.7779504775817745
[batch 4] cost: 1.9244913 training pearson: 0.6928016281973867
[batch 5] cost: 1.6480606 training pearson: 0.7999711482092111
[batch 6] cost: 1.4228592 training pearson: 0.7592053460494544
[batch 7] cost: 0.7850073 training pearson: 0.6344833678601236
[batch 8] cost: 0.97712034 training pearson: 0.7258116931534522
[batch 9] cost: 1.6248927 training pearson: 0.7464367277284599
[batch 10] cost: 1.2998811 training pearson: 0.8099796461782028
[batch 11] cost: 0.87892896 training pearson: 0.7820897587903727
[batch 12] cost: 0.97127134 training pearson: 0.6944556211386674
[batch 13] cost: 1.1483159 training pearson: 0.791403768226168
[batch 14] cost: 1.3419648 training pearson: 0.8032936645672081
[batch 15] cost: 1.3651417 training pearson: 0.7838277317399379
epoch:  34 pearson: test_pearson:  0.7198665697880854
============gbrt============
epoch:  34 pearson: ml_test_pearson:  0.6791962721262802
============xgb============
epoch:  34 pearson: ml_test_pearson:  0.6810725878189954
============rfr============
epoch:  34 pearson: ml_test_pearson:  0.6811348369463504
===============模型average结果==================
epoch:  34 pearson: ml_test_pearson:  0.694835724320719
[Epoch 35]
[batch 1] cost: 0.6806275 training pearson: 0.45502199206539196
[batch 2] cost: 1.6754272 training pearson: 0.775220804532363
[batch 3] cost: 1.6377568 training pearson: 0.810789301205731
[batch 4] cost: 1.0423719 training pearson: 0.6315844268557106
[batch 5] cost: 1.1087338 training pearson: 0.7051967190223015
[batch 6] cost: 1.8422301 training pearson: 0.7259670737230454
[batch 7] cost: 1.0026375 training pearson: 0.8461348711232185
[batch 8] cost: 1.5052137 training pearson: 0.80674642694083
[batch 9] cost: 1.0093423 training pearson: 0.7899831877489314
[batch 10] cost: 1.6956277 training pearson: 0.8421656950580811
[batch 11] cost: 1.0860448 training pearson: 0.7839361701577349
[batch 12] cost: 1.173021 training pearson: 0.801966532899592
[batch 13] cost: 1.2573467 training pearson: 0.7482991006438932
[batch 14] cost: 1.3797591 training pearson: 0.7338973288116669
[batch 15] cost: 1.1015499 training pearson: 0.7200398027209601
epoch:  35 pearson: test_pearson:  0.7209656613784101
============gbrt============
epoch:  35 pearson: ml_test_pearson:  0.6700456895303973
============xgb============
epoch:  35 pearson: ml_test_pearson:  0.6853373774611544
============rfr============
epoch:  35 pearson: ml_test_pearson:  0.6487835765635391
===============模型average结果==================
epoch:  35 pearson: ml_test_pearson:  0.6809153592505196
[Epoch 36]
[batch 1] cost: 0.98299056 training pearson: 0.8380348343899034
[batch 2] cost: 1.412929 training pearson: 0.6885298953088983
[batch 3] cost: 1.7288088 training pearson: 0.7660645008239477
[batch 4] cost: 1.6405175 training pearson: 0.726210032484816
[batch 5] cost: 1.3520393 training pearson: 0.7955265349314179
[batch 6] cost: 1.4198948 training pearson: 0.7283194163755358
[batch 7] cost: 1.5302787 training pearson: 0.7624755997489797
[batch 8] cost: 1.5816236 training pearson: 0.8358551892391911
[batch 9] cost: 1.0191909 training pearson: 0.817780650754204
[batch 10] cost: 0.89118737 training pearson: 0.6885401356774908
[batch 11] cost: 1.2755656 training pearson: 0.7416597667650392
[batch 12] cost: 0.96710134 training pearson: 0.7505137471028103
[batch 13] cost: 1.3000178 training pearson: 0.7647534539252634
[batch 14] cost: 0.95676047 training pearson: 0.6147140011577339
[batch 15] cost: 1.1471404 training pearson: 0.827258254536249
epoch:  36 pearson: test_pearson:  0.722570584819304
============gbrt============
epoch:  36 pearson: ml_test_pearson:  0.6813096198858507
============xgb============
epoch:  36 pearson: ml_test_pearson:  0.6814610227345539
============rfr============
epoch:  36 pearson: ml_test_pearson:  0.6837216896025224
===============模型average结果==================
epoch:  36 pearson: ml_test_pearson:  0.7026943499907957
[Epoch 37]
[batch 1] cost: 1.5634857 training pearson: 0.7573405416359538
[batch 2] cost: 1.1300012 training pearson: 0.7216012996779896
[batch 3] cost: 1.7193348 training pearson: 0.7400307808635256
[batch 4] cost: 1.0922807 training pearson: 0.6539948387044139
[batch 5] cost: 1.4767542 training pearson: 0.7890533614791355
[batch 6] cost: 1.1777977 training pearson: 0.8025463993369223
[batch 7] cost: 0.74245375 training pearson: 0.6811854419163548
[batch 8] cost: 0.99069184 training pearson: 0.6627310174201235
[batch 9] cost: 0.73272294 training pearson: 0.6172271732348164
[batch 10] cost: 1.3319736 training pearson: 0.8027419553231118
[batch 11] cost: 1.7396404 training pearson: 0.7615009941056587
[batch 12] cost: 1.2436259 training pearson: 0.7844228513358911
[batch 13] cost: 1.4325184 training pearson: 0.7224230361302705
[batch 14] cost: 1.3907466 training pearson: 0.8279891019964956
[batch 15] cost: 1.2164268 training pearson: 0.8651602742860738
epoch:  37 pearson: test_pearson:  0.7207063937469551
============gbrt============
epoch:  37 pearson: ml_test_pearson:  0.6806697542889444
============xgb============
epoch:  37 pearson: ml_test_pearson:  0.6816267627102511
============rfr============
epoch:  37 pearson: ml_test_pearson:  0.6372251589154503
===============模型average结果==================
epoch:  37 pearson: ml_test_pearson:  0.6801634350711708
[Epoch 38]
[batch 1] cost: 0.9359667 training pearson: 0.7444793216734691
[batch 2] cost: 1.2554742 training pearson: 0.7795103190900878
[batch 3] cost: 1.3758862 training pearson: 0.8429808393781869
[batch 4] cost: 1.6163543 training pearson: 0.7837610863670699
[batch 5] cost: 1.5719622 training pearson: 0.7490503781549288
[batch 6] cost: 1.2189405 training pearson: 0.7529187425888932
[batch 7] cost: 0.9255071 training pearson: 0.5876761205593879
[batch 8] cost: 1.2964877 training pearson: 0.6391873242301408
[batch 9] cost: 0.92593706 training pearson: 0.6099905670138246
[batch 10] cost: 1.1077254 training pearson: 0.6890392340487131
[batch 11] cost: 1.7673856 training pearson: 0.8168547389070088
[batch 12] cost: 0.9789743 training pearson: 0.7041776745679424
[batch 13] cost: 1.3880788 training pearson: 0.8144687655520733
[batch 14] cost: 1.6039078 training pearson: 0.8226618917949213
[batch 15] cost: 0.95514184 training pearson: 0.7418175624997073
epoch:  38 pearson: test_pearson:  0.7202568899853173
============gbrt============
epoch:  38 pearson: ml_test_pearson:  0.6863205339350378
============xgb============
epoch:  38 pearson: ml_test_pearson:  0.6749693238024936
============rfr============
epoch:  38 pearson: ml_test_pearson:  0.6593939203612806
===============模型average结果==================
epoch:  38 pearson: ml_test_pearson:  0.689887719267564
[Epoch 39]
[batch 1] cost: 1.1733463 training pearson: 0.710969297058947
[batch 2] cost: 0.74277234 training pearson: 0.5933340365901179
[batch 3] cost: 1.446585 training pearson: 0.7533780865857987
[batch 4] cost: 1.6250479 training pearson: 0.8702291877494914
[batch 5] cost: 1.3331777 training pearson: 0.823732645126474
[batch 6] cost: 1.163799 training pearson: 0.7662943919066699
[batch 7] cost: 0.9295294 training pearson: 0.6740564293879174
[batch 8] cost: 1.507486 training pearson: 0.7607731916274901
[batch 9] cost: 0.6323405 training pearson: 0.6939329995168272
[batch 10] cost: 1.4449269 training pearson: 0.7517431605928296
[batch 11] cost: 1.3784522 training pearson: 0.7085349152098509
[batch 12] cost: 1.4107825 training pearson: 0.8005842278834223
[batch 13] cost: 1.240666 training pearson: 0.8297394084100632
[batch 14] cost: 1.434519 training pearson: 0.7422363419261159
[batch 15] cost: 1.3659234 training pearson: 0.7315206327788211
epoch:  39 pearson: test_pearson:  0.7176567511125608
============gbrt============
epoch:  39 pearson: ml_test_pearson:  0.6814229431140829
============xgb============
epoch:  39 pearson: ml_test_pearson:  0.6511032166053807
============rfr============
epoch:  39 pearson: ml_test_pearson:  0.6107603209983291
===============模型average结果==================
epoch:  39 pearson: ml_test_pearson:  0.6630406092407409
[Epoch 40]
[batch 1] cost: 1.78362 training pearson: 0.7242475974052092
[batch 2] cost: 0.8752543 training pearson: 0.8061657682750096
[batch 3] cost: 0.86626863 training pearson: 0.6747866243883882
[batch 4] cost: 0.9836958 training pearson: 0.755951828050839
[batch 5] cost: 1.1851938 training pearson: 0.6602381722909731
[batch 6] cost: 1.716667 training pearson: 0.7298300019057915
[batch 7] cost: 1.581344 training pearson: 0.8941213651020208
[batch 8] cost: 1.3135449 training pearson: 0.7660356666403076
[batch 9] cost: 1.4613242 training pearson: 0.7661088705107468
[batch 10] cost: 1.1926596 training pearson: 0.8457631332117322
[batch 11] cost: 0.93819463 training pearson: 0.76863532231193
[batch 12] cost: 1.2699687 training pearson: 0.801705161697473
[batch 13] cost: 1.0117116 training pearson: 0.7950536692492988
[batch 14] cost: 1.268545 training pearson: 0.8090404108246387
[batch 15] cost: 1.2723451 training pearson: 0.5851089442191154
epoch:  40 pearson: test_pearson:  0.7120045471973275
============gbrt============
epoch:  40 pearson: ml_test_pearson:  0.6609939519550992
============xgb============
epoch:  40 pearson: ml_test_pearson:  0.6137392719312293
============rfr============
epoch:  40 pearson: ml_test_pearson:  0.6360004489940022
===============模型average结果==================
epoch:  40 pearson: ml_test_pearson:  0.6563518674233171
[Epoch 41]
[batch 1] cost: 1.3607428 training pearson: 0.8686891244674649
[batch 2] cost: 1.2725705 training pearson: 0.6950607354526699
[batch 3] cost: 1.413558 training pearson: 0.7494191314849632
[batch 4] cost: 1.5565556 training pearson: 0.7481575640570686
[batch 5] cost: 0.88757116 training pearson: 0.6759445131920782
[batch 6] cost: 1.6672896 training pearson: 0.798649484864866
[batch 7] cost: 1.059132 training pearson: 0.7617317070417613
[batch 8] cost: 0.91112727 training pearson: 0.7529540546207745
[batch 9] cost: 0.91100603 training pearson: 0.6958935231664612
[batch 10] cost: 1.1325772 training pearson: 0.8297494665514789
[batch 11] cost: 1.0254369 training pearson: 0.5721273567376138
[batch 12] cost: 1.5531939 training pearson: 0.7387196563816166
[batch 13] cost: 1.122946 training pearson: 0.8116952630992695
[batch 14] cost: 1.3666605 training pearson: 0.7585493882036879
[batch 15] cost: 1.3324062 training pearson: 0.7392375566201671
epoch:  41 pearson: test_pearson:  0.703505869443467
============gbrt============
epoch:  41 pearson: ml_test_pearson:  0.6642134382234508
============xgb============
epoch:  41 pearson: ml_test_pearson:  0.6479711457986155
============rfr============
epoch:  41 pearson: ml_test_pearson:  0.6254359655195029
===============模型average结果==================
epoch:  41 pearson: ml_test_pearson:  0.6675159915268208
[Epoch 42]
[batch 1] cost: 1.3716594 training pearson: 0.8447651657268856
[batch 2] cost: 1.2418301 training pearson: 0.7013904422275511
[batch 3] cost: 1.5223919 training pearson: 0.7295063300587423
[batch 4] cost: 1.3119977 training pearson: 0.7172685801238843
[batch 5] cost: 1.5325229 training pearson: 0.8684322219275168
[batch 6] cost: 0.79801196 training pearson: 0.714560370719938
[batch 7] cost: 1.3638415 training pearson: 0.6822658926542776
[batch 8] cost: 1.1883273 training pearson: 0.7721544514755309
[batch 9] cost: 0.69967735 training pearson: 0.6316724510614631
[batch 10] cost: 1.0192668 training pearson: 0.6130781937757078
[batch 11] cost: 1.1836817 training pearson: 0.7944235995924528
[batch 12] cost: 1.2295938 training pearson: 0.7443517455281042
[batch 13] cost: 1.524788 training pearson: 0.6824796069155337
[batch 14] cost: 1.5587332 training pearson: 0.8096529261524259
[batch 15] cost: 1.1550723 training pearson: 0.8047471210077802
epoch:  42 pearson: test_pearson:  0.7209990200541333
============gbrt============
epoch:  42 pearson: ml_test_pearson:  0.6835718160065319
============xgb============
epoch:  42 pearson: ml_test_pearson:  0.706620925679768
============rfr============
epoch:  42 pearson: ml_test_pearson:  0.647587967452597
===============模型average结果==================
epoch:  42 pearson: ml_test_pearson:  0.6900321829050466
[Epoch 43]
[batch 1] cost: 1.0424533 training pearson: 0.6934063157547198
[batch 2] cost: 1.5548553 training pearson: 0.8164221746721182
[batch 3] cost: 1.3805687 training pearson: 0.6108024253036699
[batch 4] cost: 0.97087675 training pearson: 0.7003266553246718
[batch 5] cost: 1.3244841 training pearson: 0.7325083809547801
[batch 6] cost: 1.2356719 training pearson: 0.7808694393756623
[batch 7] cost: 0.8531009 training pearson: 0.7356242872840538
[batch 8] cost: 1.3906908 training pearson: 0.7156373432419255
[batch 9] cost: 1.3858267 training pearson: 0.7739213545975169
[batch 10] cost: 1.6224173 training pearson: 0.764886729444715
[batch 11] cost: 1.6695977 training pearson: 0.758779017978934
[batch 12] cost: 0.7869884 training pearson: 0.7106077933069603
[batch 13] cost: 1.3470902 training pearson: 0.7639434377810428
[batch 14] cost: 1.2693061 training pearson: 0.8230591219810922
[batch 15] cost: 0.8200094 training pearson: 0.7737239695911483
epoch:  43 pearson: test_pearson:  0.7202129126981982
============gbrt============
epoch:  43 pearson: ml_test_pearson:  0.6877025199713841
============xgb============
epoch:  43 pearson: ml_test_pearson:  0.6918252622665593
============rfr============
epoch:  43 pearson: ml_test_pearson:  0.6639104117005882
===============模型average结果==================
epoch:  43 pearson: ml_test_pearson:  0.6964769191222921
[Epoch 44]
[batch 1] cost: 1.0587034 training pearson: 0.6937700245237859
[batch 2] cost: 0.6658023 training pearson: 0.6504644003688512
[batch 3] cost: 1.254559 training pearson: 0.801031890217639
[batch 4] cost: 1.292346 training pearson: 0.5860464367753689
[batch 5] cost: 1.4903977 training pearson: 0.8319463211076901
[batch 6] cost: 1.3695575 training pearson: 0.6804255129958068
[batch 7] cost: 1.688404 training pearson: 0.8284689239469232
[batch 8] cost: 1.6654645 training pearson: 0.735304931892714
[batch 9] cost: 1.0418779 training pearson: 0.7408899760702968
[batch 10] cost: 2.0170205 training pearson: 0.825038917585528
[batch 11] cost: 0.5486881 training pearson: 0.7787780909371723
[batch 12] cost: 1.161723 training pearson: 0.8218269670713823
[batch 13] cost: 0.9863936 training pearson: 0.7341901467389107
[batch 14] cost: 1.0327315 training pearson: 0.6710347293233612
[batch 15] cost: 1.309622 training pearson: 0.7939834381392243
epoch:  44 pearson: test_pearson:  0.7196419206818675
============gbrt============
epoch:  44 pearson: ml_test_pearson:  0.6872186467643326
============xgb============
epoch:  44 pearson: ml_test_pearson:  0.6837736330096823
============rfr============
epoch:  44 pearson: ml_test_pearson:  0.692985472440348
===============模型average结果==================
epoch:  44 pearson: ml_test_pearson:  0.7050306748080988
[Epoch 45]
[batch 1] cost: 0.6606636 training pearson: 0.5722803299421144
[batch 2] cost: 1.3734092 training pearson: 0.7829311192419984
[batch 3] cost: 1.6704255 training pearson: 0.7374032833741828
[batch 4] cost: 1.691168 training pearson: 0.8248797882823188
[batch 5] cost: 1.3925257 training pearson: 0.8237411991391148
[batch 6] cost: 1.1574172 training pearson: 0.6589885268761334
[batch 7] cost: 0.83915466 training pearson: 0.7535792998794564
[batch 8] cost: 1.2472287 training pearson: 0.7688780394071228
[batch 9] cost: 0.98435766 training pearson: 0.7960341412934805
[batch 10] cost: 1.2623672 training pearson: 0.7299201505859091
[batch 11] cost: 1.4531729 training pearson: 0.7695428670697736
[batch 12] cost: 0.772179 training pearson: 0.7314508661835311
[batch 13] cost: 1.177304 training pearson: 0.7279416003415978
[batch 14] cost: 1.4436281 training pearson: 0.7872600386902634
[batch 15] cost: 1.3919864 training pearson: 0.588712990450161
epoch:  45 pearson: test_pearson:  0.719702675425715
============gbrt============
epoch:  45 pearson: ml_test_pearson:  0.6732858375655998
============xgb============
epoch:  45 pearson: ml_test_pearson:  0.6884702117073436
============rfr============
epoch:  45 pearson: ml_test_pearson:  0.6578611639814848
===============模型average结果==================
epoch:  45 pearson: ml_test_pearson:  0.6875624187142095
[Epoch 46]
[batch 1] cost: 1.4901085 training pearson: 0.8732057743481819
[batch 2] cost: 1.8602139 training pearson: 0.7470874438854204
[batch 3] cost: 1.187758 training pearson: 0.848494834444338
[batch 4] cost: 1.4064349 training pearson: 0.8068765460089239
[batch 5] cost: 1.027702 training pearson: 0.6921921620101571
[batch 6] cost: 1.1677097 training pearson: 0.7934476578791643
[batch 7] cost: 1.4991869 training pearson: 0.8381615352156279
[batch 8] cost: 1.0384995 training pearson: 0.6187192797566895
[batch 9] cost: 0.90047723 training pearson: 0.6930504198871676
[batch 10] cost: 0.9455336 training pearson: 0.7303193695782199
[batch 11] cost: 1.5999255 training pearson: 0.7523390381999183
[batch 12] cost: 1.351378 training pearson: 0.684115719089984
[batch 13] cost: 0.880477 training pearson: 0.5604037410220831
[batch 14] cost: 0.65792966 training pearson: 0.6629134120974582
[batch 15] cost: 1.4131906 training pearson: 0.7414449864026651
epoch:  46 pearson: test_pearson:  0.7197207752421803
============gbrt============
epoch:  46 pearson: ml_test_pearson:  0.6719730591690957
============xgb============
epoch:  46 pearson: ml_test_pearson:  0.68489062607189
============rfr============
epoch:  46 pearson: ml_test_pearson:  0.659586276831105
===============模型average结果==================
epoch:  46 pearson: ml_test_pearson:  0.6849032728327711
[Epoch 47]
[batch 1] cost: 1.4242427 training pearson: 0.77126764333239
[batch 2] cost: 1.6869185 training pearson: 0.6943886803212573
[batch 3] cost: 1.400619 training pearson: 0.7367016822031995
[batch 4] cost: 1.5109694 training pearson: 0.8294073387522249
[batch 5] cost: 1.0139952 training pearson: 0.568290116487198
[batch 6] cost: 1.4379011 training pearson: 0.788678680698207
[batch 7] cost: 1.0260593 training pearson: 0.7802347816261692
[batch 8] cost: 1.3213029 training pearson: 0.7964861183149626
[batch 9] cost: 1.1757828 training pearson: 0.7114189405771789
[batch 10] cost: 1.0889663 training pearson: 0.7320038020622703
[batch 11] cost: 0.89275956 training pearson: 0.6497356678804297
[batch 12] cost: 1.0342809 training pearson: 0.7542801719770451
[batch 13] cost: 0.9852107 training pearson: 0.7065422204247754
[batch 14] cost: 1.1289006 training pearson: 0.7572726280798996
[batch 15] cost: 1.2668566 training pearson: 0.8643557634962286
epoch:  47 pearson: test_pearson:  0.7197417484915902
============gbrt============
epoch:  47 pearson: ml_test_pearson:  0.6764596002943397
============xgb============
epoch:  47 pearson: ml_test_pearson:  0.684887833488773
============rfr============
epoch:  47 pearson: ml_test_pearson:  0.6666282740030602
===============模型average结果==================
epoch:  47 pearson: ml_test_pearson:  0.69122533543449
[Epoch 48]
[batch 1] cost: 1.5681645 training pearson: 0.7331702382198165
[batch 2] cost: 1.1310186 training pearson: 0.7683013289617735
[batch 3] cost: 1.1737838 training pearson: 0.7754484310147891
[batch 4] cost: 1.3457985 training pearson: 0.7770912824619788
[batch 5] cost: 0.92143065 training pearson: 0.7118495595103558
[batch 6] cost: 1.0128012 training pearson: 0.8303487048791683
[batch 7] cost: 0.7342575 training pearson: 0.6681463305296238
[batch 8] cost: 1.6504413 training pearson: 0.8162299191322889
[batch 9] cost: 1.3946915 training pearson: 0.6003233908373714
[batch 10] cost: 1.2094817 training pearson: 0.704253147907387
[batch 11] cost: 1.0551137 training pearson: 0.7668368452856871
[batch 12] cost: 1.1224355 training pearson: 0.7254805159314213
[batch 13] cost: 1.4440044 training pearson: 0.7864468558096641
[batch 14] cost: 1.3447155 training pearson: 0.8383565622838678
[batch 15] cost: 1.1518748 training pearson: 0.7013780839512456
epoch:  48 pearson: test_pearson:  0.719805522446707
============gbrt============
epoch:  48 pearson: ml_test_pearson:  0.6821654928779021
============xgb============
epoch:  48 pearson: ml_test_pearson:  0.6859955426008745
============rfr============
epoch:  48 pearson: ml_test_pearson:  0.6820218146879922
===============模型average结果==================
epoch:  48 pearson: ml_test_pearson:  0.6987162163724009
[Epoch 49]
[batch 1] cost: 1.242089 training pearson: 0.8066264791637578
[batch 2] cost: 1.2451811 training pearson: 0.8501122073172184
[batch 3] cost: 1.1201036 training pearson: 0.7257751525763236
[batch 4] cost: 1.2666212 training pearson: 0.700786504086451
[batch 5] cost: 1.63055 training pearson: 0.8469983321742282
[batch 6] cost: 1.2468591 training pearson: 0.8020937226380103
[batch 7] cost: 0.7672316 training pearson: 0.6025214225294343
[batch 8] cost: 1.5542111 training pearson: 0.5902908358964373
[batch 9] cost: 1.3185962 training pearson: 0.7045178636199129
[batch 10] cost: 1.0475793 training pearson: 0.7984278496116325
[batch 11] cost: 1.2996988 training pearson: 0.8322317202839349
[batch 12] cost: 0.6736026 training pearson: 0.746258467862686
[batch 13] cost: 1.338023 training pearson: 0.6616397506760616
[batch 14] cost: 1.2452035 training pearson: 0.7910513216610271
[batch 15] cost: 1.1817759 training pearson: 0.7277263915451201
epoch:  49 pearson: test_pearson:  0.7198269720815531
============gbrt============
epoch:  49 pearson: ml_test_pearson:  0.6918972882575607
============xgb============
epoch:  49 pearson: ml_test_pearson:  0.6920189250935269
============rfr============
epoch:  49 pearson: ml_test_pearson:  0.6633298140887889
===============模型average结果==================
epoch:  49 pearson: ml_test_pearson:  0.6992593412204665
[Epoch 50]
[batch 1] cost: 1.2572587 training pearson: 0.7597251738801157
[batch 2] cost: 1.2562023 training pearson: 0.7814490259651657
[batch 3] cost: 1.9299649 training pearson: 0.8371711606406986
[batch 4] cost: 1.2385163 training pearson: 0.7373318131802752
[batch 5] cost: 1.0733802 training pearson: 0.8026892892376731
[batch 6] cost: 1.6367066 training pearson: 0.7803979914366701
[batch 7] cost: 0.70204866 training pearson: 0.7418099433102748
[batch 8] cost: 1.5268496 training pearson: 0.7629304000325152
[batch 9] cost: 1.3227295 training pearson: 0.7309570734649169
[batch 10] cost: 1.0508279 training pearson: 0.7451656331730423
[batch 11] cost: 0.97930264 training pearson: 0.7074533589805196
[batch 12] cost: 1.0580376 training pearson: 0.7914618210541297
[batch 13] cost: 1.0501326 training pearson: 0.593777127554873
[batch 14] cost: 0.9800612 training pearson: 0.7647819406331099
[batch 15] cost: 1.0947433 training pearson: 0.6919709708642822
epoch:  50 pearson: test_pearson:  0.7198270070260663
============gbrt============
epoch:  50 pearson: ml_test_pearson:  0.6804437280992709
============xgb============
epoch:  50 pearson: ml_test_pearson:  0.6821065761860594
============rfr============
epoch:  50 pearson: ml_test_pearson:  0.6510178914267788
===============模型average结果==================
epoch:  50 pearson: ml_test_pearson:  0.6852605495638552
[Epoch 51]
[batch 1] cost: 1.2590647 training pearson: 0.692556542465319
[batch 2] cost: 0.9608176 training pearson: 0.7527598301735281
[batch 3] cost: 0.99044317 training pearson: 0.7634359410481178
[batch 4] cost: 1.2323096 training pearson: 0.812082982447063
[batch 5] cost: 0.53189075 training pearson: 0.4811561088400765
[batch 6] cost: 1.3312538 training pearson: 0.7937709253001648
[batch 7] cost: 1.850243 training pearson: 0.7421647005607872
[batch 8] cost: 1.2470633 training pearson: 0.8019922972616401
[batch 9] cost: 1.0843478 training pearson: 0.6619848437386452
[batch 10] cost: 0.94586027 training pearson: 0.7231649209040429
[batch 11] cost: 1.0066692 training pearson: 0.705316188612577
[batch 12] cost: 1.4182838 training pearson: 0.7903759383831378
[batch 13] cost: 1.2469879 training pearson: 0.8174193523108403
[batch 14] cost: 1.1834522 training pearson: 0.8089312064071126
[batch 15] cost: 1.8129574 training pearson: 0.7340381733581526
epoch:  51 pearson: test_pearson:  0.719943465542063
============gbrt============
epoch:  51 pearson: ml_test_pearson:  0.6721052729961825
============xgb============
epoch:  51 pearson: ml_test_pearson:  0.6838114585139681
============rfr============
epoch:  51 pearson: ml_test_pearson:  0.667759061437862
===============模型average结果==================
epoch:  51 pearson: ml_test_pearson:  0.6893872743417375
[Epoch 52]
[batch 1] cost: 0.8258953 training pearson: 0.6630523407805109
[batch 2] cost: 1.1104218 training pearson: 0.7906617867676214
[batch 3] cost: 1.2690588 training pearson: 0.793319256341071
[batch 4] cost: 1.360062 training pearson: 0.7689626560057782
[batch 5] cost: 1.053399 training pearson: 0.7858239667838327
[batch 6] cost: 1.6922144 training pearson: 0.7654101099115558
[batch 7] cost: 1.572072 training pearson: 0.7415700096580528
[batch 8] cost: 1.2618506 training pearson: 0.6938147570606468
[batch 9] cost: 1.0961418 training pearson: 0.6530464083399052
[batch 10] cost: 1.4423294 training pearson: 0.7089565734903741
[batch 11] cost: 1.2222313 training pearson: 0.7991901878812989
[batch 12] cost: 0.9315203 training pearson: 0.7568107917199071
[batch 13] cost: 1.0450901 training pearson: 0.6659889138527131
[batch 14] cost: 1.2209306 training pearson: 0.841750065985892
[batch 15] cost: 1.0553774 training pearson: 0.7327138183608787
epoch:  52 pearson: test_pearson:  0.7198730978336056
============gbrt============
epoch:  52 pearson: ml_test_pearson:  0.6818171746215869
============xgb============
epoch:  52 pearson: ml_test_pearson:  0.6936219268643029
============rfr============
epoch:  52 pearson: ml_test_pearson:  0.6555952488326408
===============模型average结果==================
epoch:  52 pearson: ml_test_pearson:  0.6912460505935377
[Epoch 53]
[batch 1] cost: 1.8014737 training pearson: 0.7989293490300238
[batch 2] cost: 1.369163 training pearson: 0.7168907649078561
[batch 3] cost: 1.0584236 training pearson: 0.7164213423043065
[batch 4] cost: 1.5817806 training pearson: 0.8582862285569809
[batch 5] cost: 0.9932493 training pearson: 0.7328291040249226
[batch 6] cost: 1.1605594 training pearson: 0.6976268557759872
[batch 7] cost: 1.2502489 training pearson: 0.7099492751935949
[batch 8] cost: 1.1336453 training pearson: 0.6864969039206983
[batch 9] cost: 1.0198722 training pearson: 0.7286503460247465
[batch 10] cost: 0.8819944 training pearson: 0.7856340027279345
[batch 11] cost: 1.4063339 training pearson: 0.6189182957192182
[batch 12] cost: 0.96415955 training pearson: 0.7092799058950525
[batch 13] cost: 0.79665816 training pearson: 0.791495449816857
[batch 14] cost: 1.2446575 training pearson: 0.8000108710467015
[batch 15] cost: 1.1814603 training pearson: 0.8352878344345891
epoch:  53 pearson: test_pearson:  0.7198995459818849
============gbrt============
epoch:  53 pearson: ml_test_pearson:  0.6866764954724172
============xgb============
epoch:  53 pearson: ml_test_pearson:  0.6945092263855749
============rfr============
epoch:  53 pearson: ml_test_pearson:  0.6825103085121917
===============模型average结果==================
epoch:  53 pearson: ml_test_pearson:  0.7038493170650649
[Epoch 54]
[batch 1] cost: 1.0831807 training pearson: 0.8272811313718168
[batch 2] cost: 0.8908783 training pearson: 0.7693129048585832
[batch 3] cost: 1.3844265 training pearson: 0.5918353462327184
[batch 4] cost: 1.0491835 training pearson: 0.7847998940699633
[batch 5] cost: 1.2462592 training pearson: 0.7721342957694898
[batch 6] cost: 1.1334696 training pearson: 0.787428061804855
[batch 7] cost: 1.5116234 training pearson: 0.6966119873653163
[batch 8] cost: 1.2181582 training pearson: 0.7685443951099932
[batch 9] cost: 1.4137021 training pearson: 0.7680501510314744
[batch 10] cost: 1.0786378 training pearson: 0.7873129900316111
[batch 11] cost: 1.0551492 training pearson: 0.7578762743195205
[batch 12] cost: 2.1059766 training pearson: 0.8160193102011114
[batch 13] cost: 1.2050807 training pearson: 0.635605838768527
[batch 14] cost: 1.1077465 training pearson: 0.6939693458203356
[batch 15] cost: 0.45039794 training pearson: 0.5957576438545059
epoch:  54 pearson: test_pearson:  0.7197093836513399
============gbrt============
epoch:  54 pearson: ml_test_pearson:  0.6860863842973263
============xgb============
epoch:  54 pearson: ml_test_pearson:  0.7023867721665714
============rfr============
epoch:  54 pearson: ml_test_pearson:  0.6560443814535952
===============模型average结果==================
epoch:  54 pearson: ml_test_pearson:  0.6959107239631075
[Epoch 55]
[batch 1] cost: 1.2804674 training pearson: 0.7028822475542451
[batch 2] cost: 0.9311201 training pearson: 0.6123996345100345
[batch 3] cost: 1.1486458 training pearson: 0.8112421085312579
[batch 4] cost: 1.0996395 training pearson: 0.7000988414805592
[batch 5] cost: 1.1191127 training pearson: 0.7821087599398298
[batch 6] cost: 1.2732805 training pearson: 0.7073744007972169
[batch 7] cost: 1.2236259 training pearson: 0.78202763530152
[batch 8] cost: 1.1692743 training pearson: 0.7502809113932868
[batch 9] cost: 1.1522455 training pearson: 0.8174051716291986
[batch 10] cost: 1.688532 training pearson: 0.7280181593606109
[batch 11] cost: 1.0683502 training pearson: 0.7742506102354059
[batch 12] cost: 0.79114443 training pearson: 0.5699804189738257
[batch 13] cost: 1.5340351 training pearson: 0.8139694734269436
[batch 14] cost: 1.5274822 training pearson: 0.8253920639092841
[batch 15] cost: 0.7640588 training pearson: 0.7527285690505254
epoch:  55 pearson: test_pearson:  0.7196265258716065
============gbrt============
epoch:  55 pearson: ml_test_pearson:  0.6863652478255432
============xgb============
epoch:  55 pearson: ml_test_pearson:  0.6974284024284404
============rfr============
epoch:  55 pearson: ml_test_pearson:  0.6411019773037124
===============模型average结果==================
epoch:  55 pearson: ml_test_pearson:  0.6866438925618513
[Epoch 56]
[batch 1] cost: 1.5447787 training pearson: 0.8216526858611896
[batch 2] cost: 1.5645236 training pearson: 0.6811636012130202
[batch 3] cost: 1.1679523 training pearson: 0.7900049684420233
[batch 4] cost: 1.3819722 training pearson: 0.8045881124950002
[batch 5] cost: 0.7780108 training pearson: 0.49939725738227925
[batch 6] cost: 1.3616127 training pearson: 0.7724772768674928
[batch 7] cost: 0.9119407 training pearson: 0.6335522721338538
[batch 8] cost: 1.4692189 training pearson: 0.8398366082252787
[batch 9] cost: 0.80867815 training pearson: 0.6965178940951965
[batch 10] cost: 1.1756566 training pearson: 0.7661161713878835
[batch 11] cost: 0.9827149 training pearson: 0.7204367467252852
[batch 12] cost: 1.1828581 training pearson: 0.8127008224327719
[batch 13] cost: 1.2323238 training pearson: 0.8126465807212896
[batch 14] cost: 1.2301065 training pearson: 0.8192962873931291
[batch 15] cost: 0.8529262 training pearson: 0.771311055380313
epoch:  56 pearson: test_pearson:  0.7197260282599276
============gbrt============
epoch:  56 pearson: ml_test_pearson:  0.6808068751431167
============xgb============
epoch:  56 pearson: ml_test_pearson:  0.6886997563444578
============rfr============
epoch:  56 pearson: ml_test_pearson:  0.6521123619543183
===============模型average结果==================
epoch:  56 pearson: ml_test_pearson:  0.6860735331981275
[Epoch 57]
[batch 1] cost: 0.95202667 training pearson: 0.712956647049205
[batch 2] cost: 1.2808981 training pearson: 0.8054207923408921
[batch 3] cost: 1.0042484 training pearson: 0.8512059676794991
[batch 4] cost: 0.96196574 training pearson: 0.5683547947042148
[batch 5] cost: 1.0421357 training pearson: 0.735680422930386
[batch 6] cost: 1.1497749 training pearson: 0.8520267430979915
[batch 7] cost: 1.2550154 training pearson: 0.7080105985513138
[batch 8] cost: 1.1983376 training pearson: 0.7222439074670073
[batch 9] cost: 1.1311152 training pearson: 0.7917097080527464
[batch 10] cost: 0.99564195 training pearson: 0.5127937812826824
[batch 11] cost: 1.5924579 training pearson: 0.7898216829294232
[batch 12] cost: 0.8152829 training pearson: 0.6875619015637255
[batch 13] cost: 1.1070914 training pearson: 0.7582681732187379
[batch 14] cost: 1.5560898 training pearson: 0.8581922711535875
[batch 15] cost: 1.5327967 training pearson: 0.7185077845248155
epoch:  57 pearson: test_pearson:  0.7197869206919029
============gbrt============
epoch:  57 pearson: ml_test_pearson:  0.6832680615440287
============xgb============
epoch:  57 pearson: ml_test_pearson:  0.6921696415227583
============rfr============
epoch:  57 pearson: ml_test_pearson:  0.6412863948430272
===============模型average结果==================
epoch:  57 pearson: ml_test_pearson:  0.6832102954452454
[Epoch 58]
[batch 1] cost: 1.4512569 training pearson: 0.8077627132377542
[batch 2] cost: 1.2176727 training pearson: 0.8153280649708124
[batch 3] cost: 0.9420613 training pearson: 0.6647636396127703
[batch 4] cost: 1.0347171 training pearson: 0.7038733832038648
[batch 5] cost: 0.9705473 training pearson: 0.7554302175767119
[batch 6] cost: 1.6136959 training pearson: 0.7338283101166067
[batch 7] cost: 0.8630606 training pearson: 0.6827602181422091
[batch 8] cost: 1.4500952 training pearson: 0.7521301257589191
[batch 9] cost: 0.8052536 training pearson: 0.626918535329825
[batch 10] cost: 1.4372079 training pearson: 0.7474063093861756
[batch 11] cost: 1.0447562 training pearson: 0.6786019409819831
[batch 12] cost: 0.98185486 training pearson: 0.7469070501382898
[batch 13] cost: 1.0869159 training pearson: 0.8008413409258107
[batch 14] cost: 1.1865824 training pearson: 0.7980823865975085
[batch 15] cost: 1.466436 training pearson: 0.8164152846250978
epoch:  58 pearson: test_pearson:  0.719752760733587
============gbrt============
epoch:  58 pearson: ml_test_pearson:  0.6900624572040334
============xgb============
epoch:  58 pearson: ml_test_pearson:  0.6793381118709495
============rfr============
epoch:  58 pearson: ml_test_pearson:  0.6545941196624216
===============模型average结果==================
epoch:  58 pearson: ml_test_pearson:  0.6867067016792098
[Epoch 59]
[batch 1] cost: 1.1948876 training pearson: 0.7054173397099107
[batch 2] cost: 1.3999497 training pearson: 0.7580355632519388
[batch 3] cost: 1.2735507 training pearson: 0.8468311128505303
[batch 4] cost: 0.8689815 training pearson: 0.8012056241705555
[batch 5] cost: 0.94094396 training pearson: 0.7012560467252447
[batch 6] cost: 0.93015146 training pearson: 0.7874580599004606
[batch 7] cost: 0.892529 training pearson: 0.8117073211801477
[batch 8] cost: 1.3579035 training pearson: 0.6404771605244588
[batch 9] cost: 2.014676 training pearson: 0.7383250618705435
[batch 10] cost: 1.3208373 training pearson: 0.7509771136907131
[batch 11] cost: 0.92043746 training pearson: 0.6722816548211843
[batch 12] cost: 1.0558593 training pearson: 0.7702329880467529
[batch 13] cost: 1.2956613 training pearson: 0.7629790023768207
[batch 14] cost: 0.55924535 training pearson: 0.6037249881969615
[batch 15] cost: 1.390102 training pearson: 0.8261348481150342
epoch:  59 pearson: test_pearson:  0.7195682308718782
============gbrt============
epoch:  59 pearson: ml_test_pearson:  0.6885497827335623
============xgb============
epoch:  59 pearson: ml_test_pearson:  0.6993064943800994
============rfr============
epoch:  59 pearson: ml_test_pearson:  0.6690324091360137
===============模型average结果==================
epoch:  59 pearson: ml_test_pearson:  0.696613391687786
[Epoch 60]
[batch 1] cost: 0.909877 training pearson: 0.8382366756275792
[batch 2] cost: 1.2564337 training pearson: 0.7337016908795997
[batch 3] cost: 0.9578255 training pearson: 0.6154210620250954
[batch 4] cost: 1.4174857 training pearson: 0.6971552547628168
[batch 5] cost: 0.9663362 training pearson: 0.8147190899274976
[batch 6] cost: 1.0512723 training pearson: 0.6722886185354092
[batch 7] cost: 1.251631 training pearson: 0.7935374683268425
[batch 8] cost: 1.224272 training pearson: 0.6851601402753104
[batch 9] cost: 1.017478 training pearson: 0.7481103367252017
[batch 10] cost: 1.4373028 training pearson: 0.8945264496233502
[batch 11] cost: 1.1866432 training pearson: 0.7014708305036266
[batch 12] cost: 1.0499051 training pearson: 0.7363084663693285
[batch 13] cost: 1.1321605 training pearson: 0.7807768125262229
[batch 14] cost: 1.5442252 training pearson: 0.6854678281218957
[batch 15] cost: 0.93157804 training pearson: 0.8183726816688522
epoch:  60 pearson: test_pearson:  0.7195589341589512
============gbrt============
epoch:  60 pearson: ml_test_pearson:  0.6995395682042848
============xgb============
epoch:  60 pearson: ml_test_pearson:  0.6941443851895939
============rfr============
epoch:  60 pearson: ml_test_pearson:  0.6641408583456008
===============模型average结果==================
epoch:  60 pearson: ml_test_pearson:  0.6991794386245764
[Epoch 61]
[batch 1] cost: 1.2065288 training pearson: 0.5804687925491597
[batch 2] cost: 1.3323181 training pearson: 0.8029449340742759
[batch 3] cost: 0.78254014 training pearson: 0.7544873383709535
[batch 4] cost: 0.8057347 training pearson: 0.7341655219113278
[batch 5] cost: 1.2348839 training pearson: 0.7471922709913573
[batch 6] cost: 1.0493536 training pearson: 0.7497767470386784
[batch 7] cost: 1.8924576 training pearson: 0.8115846671528578
[batch 8] cost: 1.3309088 training pearson: 0.7769498961378387
[batch 9] cost: 1.5069232 training pearson: 0.8479007733297582
[batch 10] cost: 0.724824 training pearson: 0.5735220259789571
[batch 11] cost: 1.080046 training pearson: 0.7783409924723144
[batch 12] cost: 1.293322 training pearson: 0.8324881968059656
[batch 13] cost: 0.45721114 training pearson: 0.5966045541844284
[batch 14] cost: 0.8181563 training pearson: 0.7518673196985505
[batch 15] cost: 1.7852874 training pearson: 0.6142814207620875
epoch:  61 pearson: test_pearson:  0.7195540920541935
============gbrt============
epoch:  61 pearson: ml_test_pearson:  0.6855854871494068
============xgb============
epoch:  61 pearson: ml_test_pearson:  0.6995949477851438
============rfr============
epoch:  61 pearson: ml_test_pearson:  0.6321103964079539
===============模型average结果==================
epoch:  61 pearson: ml_test_pearson:  0.6824789778707233
[Epoch 62]
[batch 1] cost: 1.8192608 training pearson: 0.7572600969150803
[batch 2] cost: 0.8529297 training pearson: 0.651429109050429
[batch 3] cost: 0.9301188 training pearson: 0.7190610055189199
[batch 4] cost: 0.8467949 training pearson: 0.676615247866145
[batch 5] cost: 0.77512175 training pearson: 0.7421624676829358
[batch 6] cost: 1.253175 training pearson: 0.8355769644881147
[batch 7] cost: 1.063469 training pearson: 0.7430678877452079
[batch 8] cost: 1.396303 training pearson: 0.7602494643961463
[batch 9] cost: 0.8399494 training pearson: 0.7488495253528257
[batch 10] cost: 1.2228929 training pearson: 0.7248617928095612
[batch 11] cost: 1.3050961 training pearson: 0.7592879951344825
[batch 12] cost: 0.9587973 training pearson: 0.7347280414856192
[batch 13] cost: 1.2621107 training pearson: 0.8283212886263746
[batch 14] cost: 1.513751 training pearson: 0.8086170585145018
[batch 15] cost: 1.1909845 training pearson: 0.7047692663403775
epoch:  62 pearson: test_pearson:  0.7195097706571789
============gbrt============
epoch:  62 pearson: ml_test_pearson:  0.6802557965597859
============xgb============
epoch:  62 pearson: ml_test_pearson:  0.685503830041466
============rfr============
epoch:  62 pearson: ml_test_pearson:  0.6628163315690452
===============模型average结果==================
epoch:  62 pearson: ml_test_pearson:  0.6934953092126321
[Epoch 63]
[batch 1] cost: 0.77323157 training pearson: 0.6650183172670366
[batch 2] cost: 1.1614603 training pearson: 0.8303965355798213
[batch 3] cost: 1.0236539 training pearson: 0.7239093803927216
[batch 4] cost: 0.7399342 training pearson: 0.70567663979635
[batch 5] cost: 1.3401613 training pearson: 0.7867529160510148
[batch 6] cost: 1.0605539 training pearson: 0.7298399709601608
[batch 7] cost: 0.86291796 training pearson: 0.6195483700412399
[batch 8] cost: 1.5055099 training pearson: 0.8401678524700201
[batch 9] cost: 1.1774033 training pearson: 0.8106662530235551
[batch 10] cost: 1.6219614 training pearson: 0.8477923321683637
[batch 11] cost: 0.96238196 training pearson: 0.7869288540669734
[batch 12] cost: 1.1785997 training pearson: 0.6924728839092898
[batch 13] cost: 1.1427072 training pearson: 0.6771704997237452
[batch 14] cost: 1.2967762 training pearson: 0.5977746965744127
[batch 15] cost: 1.2486277 training pearson: 0.7705360509977474
epoch:  63 pearson: test_pearson:  0.7194367318032115
============gbrt============
epoch:  63 pearson: ml_test_pearson:  0.6864349591393514
============xgb============
epoch:  63 pearson: ml_test_pearson:  0.6950154372279482
============rfr============
epoch:  63 pearson: ml_test_pearson:  0.6751513641781941
===============模型average结果==================
epoch:  63 pearson: ml_test_pearson:  0.702761634996509
[Epoch 64]
[batch 1] cost: 1.0008566 training pearson: 0.628723623333677
[batch 2] cost: 0.89058167 training pearson: 0.7865754265077832
[batch 3] cost: 1.3614936 training pearson: 0.8098966422267886
[batch 4] cost: 0.94715226 training pearson: 0.8090424864683684
[batch 5] cost: 0.94948125 training pearson: 0.7772291035071986
[batch 6] cost: 1.1270449 training pearson: 0.6485474977143735
[batch 7] cost: 1.0315906 training pearson: 0.8759400871157736
[batch 8] cost: 0.98112226 training pearson: 0.7321499621602714
[batch 9] cost: 1.3724884 training pearson: 0.7430252656266799
[batch 10] cost: 1.1005259 training pearson: 0.7519827273559797
[batch 11] cost: 0.9474988 training pearson: 0.6501455445339205
[batch 12] cost: 1.3277973 training pearson: 0.7954051131012742
[batch 13] cost: 1.7029624 training pearson: 0.8254576170475824
[batch 14] cost: 1.2804744 training pearson: 0.7877984701388236
[batch 15] cost: 0.996828 training pearson: 0.49026254014190046
epoch:  64 pearson: test_pearson:  0.7194531868635298
============gbrt============
epoch:  64 pearson: ml_test_pearson:  0.6924180252060883
============xgb============
epoch:  64 pearson: ml_test_pearson:  0.7028391354815116
============rfr============
epoch:  64 pearson: ml_test_pearson:  0.6804992907096806
===============模型average结果==================
epoch:  64 pearson: ml_test_pearson:  0.706192108383867
[Epoch 65]
[batch 1] cost: 1.3396045 training pearson: 0.6905830801241265
[batch 2] cost: 0.81755674 training pearson: 0.584570996703282
[batch 3] cost: 1.3610455 training pearson: 0.8803350570583492
[batch 4] cost: 0.70689285 training pearson: 0.5378159190800051
[batch 5] cost: 0.93203354 training pearson: 0.7609527470808484
[batch 6] cost: 0.963143 training pearson: 0.644490999587352
[batch 7] cost: 0.94433206 training pearson: 0.7758069699763567
[batch 8] cost: 1.4200332 training pearson: 0.7957784816694052
[batch 9] cost: 0.9749756 training pearson: 0.7970842772040281
[batch 10] cost: 1.3417125 training pearson: 0.7623370608346735
[batch 11] cost: 1.2579652 training pearson: 0.7243595610874933
[batch 12] cost: 1.3687623 training pearson: 0.8312723247287495
[batch 13] cost: 1.0584598 training pearson: 0.744165694328962
[batch 14] cost: 1.2337713 training pearson: 0.7278497482201339
[batch 15] cost: 1.2382491 training pearson: 0.7319182522877197
epoch:  65 pearson: test_pearson:  0.7194027586569172
============gbrt============
epoch:  65 pearson: ml_test_pearson:  0.6901658857373901
============xgb============
epoch:  65 pearson: ml_test_pearson:  0.6985619747728148
============rfr============
epoch:  65 pearson: ml_test_pearson:  0.6701438019942197
===============模型average结果==================
epoch:  65 pearson: ml_test_pearson:  0.7015140768945574
[Epoch 66]
[batch 1] cost: 1.3141763 training pearson: 0.7947532837338058
[batch 2] cost: 1.0059958 training pearson: 0.7831558948657067
[batch 3] cost: 1.1685828 training pearson: 0.7711179266528828
[batch 4] cost: 1.0906099 training pearson: 0.6670133679647642
[batch 5] cost: 1.1727529 training pearson: 0.8185153084694062
[batch 6] cost: 1.3515979 training pearson: 0.8331629622560573
[batch 7] cost: 0.79290795 training pearson: 0.7443087533848066
[batch 8] cost: 0.63656944 training pearson: 0.44229196491425776
[batch 9] cost: 1.0864602 training pearson: 0.7901060351161237
[batch 10] cost: 1.1921805 training pearson: 0.6407738732226493
[batch 11] cost: 1.3391731 training pearson: 0.808611939930875
[batch 12] cost: 1.3195387 training pearson: 0.7801795339608613
[batch 13] cost: 1.1168346 training pearson: 0.7664589750146339
[batch 14] cost: 0.93969953 training pearson: 0.7476225275547798
[batch 15] cost: 1.3580304 training pearson: 0.6989422094237527
epoch:  66 pearson: test_pearson:  0.7193792948399929
============gbrt============
epoch:  66 pearson: ml_test_pearson:  0.6925223351538285
============xgb============
epoch:  66 pearson: ml_test_pearson:  0.704582949666198
============rfr============
epoch:  66 pearson: ml_test_pearson:  0.6750462088991058
===============模型average结果==================
epoch:  66 pearson: ml_test_pearson:  0.7036848694281884
[Epoch 67]
[batch 1] cost: 1.03628 training pearson: 0.6823578148397536
[batch 2] cost: 1.2427456 training pearson: 0.8532380970583273
[batch 3] cost: 0.99021393 training pearson: 0.8191352724898754
[batch 4] cost: 1.326218 training pearson: 0.7461749204011293
[batch 5] cost: 0.73603195 training pearson: 0.6954025595598473
[batch 6] cost: 1.1296924 training pearson: 0.7161464530186812
[batch 7] cost: 1.1630732 training pearson: 0.65136994960131
[batch 8] cost: 1.2763051 training pearson: 0.7169884037489133
[batch 9] cost: 0.529051 training pearson: 0.6599506489438666
[batch 10] cost: 1.2554518 training pearson: 0.7947075034168124
[batch 11] cost: 1.1839068 training pearson: 0.7440491604942149
[batch 12] cost: 1.4928094 training pearson: 0.8100571141561994
[batch 13] cost: 1.3230939 training pearson: 0.8376026112340967
[batch 14] cost: 1.0835224 training pearson: 0.6665141200895013
[batch 15] cost: 1.0481894 training pearson: 0.6106786702931806
epoch:  67 pearson: test_pearson:  0.7194135445235985
============gbrt============
epoch:  67 pearson: ml_test_pearson:  0.690446765573471
============xgb============
epoch:  67 pearson: ml_test_pearson:  0.7033334301540639
============rfr============
epoch:  67 pearson: ml_test_pearson:  0.6855514409974247
===============模型average结果==================
epoch:  67 pearson: ml_test_pearson:  0.7096578177045935
[Epoch 68]
[batch 1] cost: 1.1953892 training pearson: 0.6682652713990058
[batch 2] cost: 0.94182396 training pearson: 0.7683623872664429
[batch 3] cost: 0.89324015 training pearson: 0.7297561689309654
[batch 4] cost: 1.2193203 training pearson: 0.7143520653576687
[batch 5] cost: 0.71515703 training pearson: 0.6663028488190491
[batch 6] cost: 1.0844053 training pearson: 0.7573374971243062
[batch 7] cost: 0.88463926 training pearson: 0.7839494800267633
[batch 8] cost: 1.3700402 training pearson: 0.8681380109191589
[batch 9] cost: 1.6772403 training pearson: 0.7389658141291175
[batch 10] cost: 1.2453045 training pearson: 0.8624942332993879
[batch 11] cost: 1.2500893 training pearson: 0.7182589463272708
[batch 12] cost: 1.3727543 training pearson: 0.8274298625066071
[batch 13] cost: 0.8867952 training pearson: 0.5421014177265544
[batch 14] cost: 0.9318073 training pearson: 0.6661523337103858
[batch 15] cost: 1.0656145 training pearson: 0.7234219698178935
epoch:  68 pearson: test_pearson:  0.7195301396824323
============gbrt============
epoch:  68 pearson: ml_test_pearson:  0.6936175546258747
============xgb============
epoch:  68 pearson: ml_test_pearson:  0.7002078676891631
============rfr============
epoch:  68 pearson: ml_test_pearson:  0.6798918005889704
===============模型average结果==================
epoch:  68 pearson: ml_test_pearson:  0.7063555422523435
[Epoch 69]
[batch 1] cost: 0.653187 training pearson: 0.5597351490426353
[batch 2] cost: 1.6479384 training pearson: 0.8500957878646858
[batch 3] cost: 1.4082316 training pearson: 0.8321559112544072
[batch 4] cost: 1.2275767 training pearson: 0.8250931949651581
[batch 5] cost: 1.3741039 training pearson: 0.6979702267250709
[batch 6] cost: 0.85891306 training pearson: 0.6684086452560262
[batch 7] cost: 0.98784775 training pearson: 0.8229577041362038
[batch 8] cost: 1.2904288 training pearson: 0.8292769195062923
[batch 9] cost: 1.2533535 training pearson: 0.7486124139251917
[batch 10] cost: 0.6498053 training pearson: 0.5376335348827921
[batch 11] cost: 1.0241216 training pearson: 0.8235262256287529
[batch 12] cost: 0.93504393 training pearson: 0.8158263624499167
[batch 13] cost: 1.1996955 training pearson: 0.658917873241083
[batch 14] cost: 0.7326655 training pearson: 0.4806881867698286
[batch 15] cost: 1.4021504 training pearson: 0.7163477354322303
epoch:  69 pearson: test_pearson:  0.7194892013068939
============gbrt============
epoch:  69 pearson: ml_test_pearson:  0.686684516216905
============xgb============
epoch:  69 pearson: ml_test_pearson:  0.6843863968515745
============rfr============
epoch:  69 pearson: ml_test_pearson:  0.6651503381732075
===============模型average结果==================
epoch:  69 pearson: ml_test_pearson:  0.6932329785931921
[Epoch 70]
[batch 1] cost: 1.2253438 training pearson: 0.7667046543593579
[batch 2] cost: 0.96164435 training pearson: 0.7183041374898514
[batch 3] cost: 1.005668 training pearson: 0.6173942327540943
[batch 4] cost: 0.751765 training pearson: 0.6057690958139811
[batch 5] cost: 0.716944 training pearson: 0.754365397718216
[batch 6] cost: 0.9854006 training pearson: 0.7400929081666057
[batch 7] cost: 0.53856194 training pearson: 0.4603099019821532
[batch 8] cost: 1.1652226 training pearson: 0.8110890244581976
[batch 9] cost: 1.140271 training pearson: 0.7180696217141631
[batch 10] cost: 1.2519684 training pearson: 0.7800059252651129
[batch 11] cost: 1.2868494 training pearson: 0.7937967657111841
[batch 12] cost: 1.4085361 training pearson: 0.8374096386023844
[batch 13] cost: 1.1085825 training pearson: 0.8331807683504223
[batch 14] cost: 1.7468246 training pearson: 0.7096112425524913
[batch 15] cost: 1.3063333 training pearson: 0.8174748133340669
epoch:  70 pearson: test_pearson:  0.719472798491965
============gbrt============
epoch:  70 pearson: ml_test_pearson:  0.687829011802619
============xgb============
epoch:  70 pearson: ml_test_pearson:  0.6797462771265699
============rfr============
epoch:  70 pearson: ml_test_pearson:  0.6222370211466643
===============模型average结果==================
epoch:  70 pearson: ml_test_pearson:  0.6751724022408467
[Epoch 71]
[batch 1] cost: 1.3221297 training pearson: 0.8277454937317545
[batch 2] cost: 0.93870544 training pearson: 0.5752599846281229
[batch 3] cost: 0.9201126 training pearson: 0.8149845100584403
[batch 4] cost: 1.528681 training pearson: 0.7829335485919979
[batch 5] cost: 0.88655937 training pearson: 0.7512173646973719
[batch 6] cost: 1.0864927 training pearson: 0.6739335480048125
[batch 7] cost: 1.0385785 training pearson: 0.7570865852223324
[batch 8] cost: 1.1457099 training pearson: 0.8068946499785785
[batch 9] cost: 1.2772954 training pearson: 0.7961342595351317
[batch 10] cost: 0.9952539 training pearson: 0.7708119832589679
[batch 11] cost: 0.9696674 training pearson: 0.7681993556343134
[batch 12] cost: 0.958035 training pearson: 0.7490893346968615
[batch 13] cost: 1.2066462 training pearson: 0.7158832898811223
[batch 14] cost: 1.0999322 training pearson: 0.7278947515480924
[batch 15] cost: 1.1530755 training pearson: 0.6751248333475658
epoch:  71 pearson: test_pearson:  0.7193593553906312
============gbrt============
epoch:  71 pearson: ml_test_pearson:  0.6898707043475426
============xgb============
epoch:  71 pearson: ml_test_pearson:  0.6813224167834734
============rfr============
epoch:  71 pearson: ml_test_pearson:  0.6799613205188003
===============模型average结果==================
epoch:  71 pearson: ml_test_pearson:  0.7008302027156036
[Epoch 72]
[batch 1] cost: 0.98278534 training pearson: 0.7711503760799757
[batch 2] cost: 0.90726423 training pearson: 0.7142050400829998
[batch 3] cost: 0.939971 training pearson: 0.8201520794706674
[batch 4] cost: 1.4481789 training pearson: 0.8729541819106329
[batch 5] cost: 0.788491 training pearson: 0.6450394632170734
[batch 6] cost: 1.0425963 training pearson: 0.7214045257517288
[batch 7] cost: 1.0225704 training pearson: 0.6840978503044777
[batch 8] cost: 1.1818118 training pearson: 0.6973472894198172
[batch 9] cost: 1.5826275 training pearson: 0.743321184869047
[batch 10] cost: 1.1625373 training pearson: 0.64499728163282
[batch 11] cost: 1.1571076 training pearson: 0.7727332041418981
[batch 12] cost: 0.8475089 training pearson: 0.7678215890329848
[batch 13] cost: 1.5355484 training pearson: 0.8060818648342127
[batch 14] cost: 1.0995178 training pearson: 0.7602195073978303
[batch 15] cost: 0.7548408 training pearson: 0.6737317944902081
epoch:  72 pearson: test_pearson:  0.719340600225295
============gbrt============
epoch:  72 pearson: ml_test_pearson:  0.7094798076632746
============xgb============
epoch:  72 pearson: ml_test_pearson:  0.6863729382935738
============rfr============
epoch:  72 pearson: ml_test_pearson:  0.6541012364199953
===============模型average结果==================
epoch:  72 pearson: ml_test_pearson:  0.7013078531482901
[Epoch 73]
[batch 1] cost: 1.5640177 training pearson: 0.8244551333018905
[batch 2] cost: 1.1178181 training pearson: 0.6567145481864477
[batch 3] cost: 0.89807343 training pearson: 0.7202761638071988
[batch 4] cost: 1.4861335 training pearson: 0.7046477234451353
[batch 5] cost: 1.3745543 training pearson: 0.7828989703359581
[batch 6] cost: 1.0409923 training pearson: 0.7803250430422531
[batch 7] cost: 1.3063245 training pearson: 0.7288133875618272
[batch 8] cost: 1.312883 training pearson: 0.7315951383635887
[batch 9] cost: 0.785028 training pearson: 0.7189607813627017
[batch 10] cost: 0.7262159 training pearson: 0.6299300294568704
[batch 11] cost: 1.134211 training pearson: 0.7887613943484532
[batch 12] cost: 0.87746805 training pearson: 0.7140844616290272
[batch 13] cost: 0.8525418 training pearson: 0.793662264353382
[batch 14] cost: 0.9629245 training pearson: 0.7790076437779625
[batch 15] cost: 0.91947097 training pearson: 0.7981179646908227
epoch:  73 pearson: test_pearson:  0.7193682706967304
============gbrt============
epoch:  73 pearson: ml_test_pearson:  0.706162356041755
============xgb============
epoch:  73 pearson: ml_test_pearson:  0.6711897997743788
============rfr============
epoch:  73 pearson: ml_test_pearson:  0.6576708020851081
===============模型average结果==================
epoch:  73 pearson: ml_test_pearson:  0.6973992571364113
[Epoch 74]
[batch 1] cost: 0.8530919 training pearson: 0.6774434070247684
[batch 2] cost: 1.5919659 training pearson: 0.7292406381881725
[batch 3] cost: 1.6901157 training pearson: 0.8451350987731604
[batch 4] cost: 0.8631122 training pearson: 0.6747045297935309
[batch 5] cost: 1.0402828 training pearson: 0.7273614229899289
[batch 6] cost: 0.6778418 training pearson: 0.7478844388281214
[batch 7] cost: 0.8582911 training pearson: 0.6502930896925214
[batch 8] cost: 1.2891041 training pearson: 0.7720014894872288
[batch 9] cost: 1.2305925 training pearson: 0.8128947518125464
[batch 10] cost: 0.5715916 training pearson: 0.7067409695214096
[batch 11] cost: 1.126171 training pearson: 0.8028465387457763
[batch 12] cost: 1.216879 training pearson: 0.7321358212782695
[batch 13] cost: 0.89461684 training pearson: 0.7895043460355897
[batch 14] cost: 1.2924014 training pearson: 0.7103692933204724
[batch 15] cost: 1.1333561 training pearson: 0.7636966218239917
epoch:  74 pearson: test_pearson:  0.7193642281459212
============gbrt============
epoch:  74 pearson: ml_test_pearson:  0.7023629283384849
============xgb============
epoch:  74 pearson: ml_test_pearson:  0.6808127025222903
============rfr============
epoch:  74 pearson: ml_test_pearson:  0.6722010448160236
===============模型average结果==================
epoch:  74 pearson: ml_test_pearson:  0.7005116323085212
[Epoch 75]
[batch 1] cost: 1.2257686 training pearson: 0.8279971559501683
[batch 2] cost: 0.8837567 training pearson: 0.5928391610817021
[batch 3] cost: 0.93105906 training pearson: 0.6568513321126186
[batch 4] cost: 0.61223215 training pearson: 0.8552614758029631
[batch 5] cost: 0.7948258 training pearson: 0.49742365773552943
[batch 6] cost: 1.1679493 training pearson: 0.8055185402795486
[batch 7] cost: 1.3303304 training pearson: 0.7444965828481268
[batch 8] cost: 0.82901746 training pearson: 0.7586577626669934
[batch 9] cost: 1.1015137 training pearson: 0.6868817594844002
[batch 10] cost: 0.9406957 training pearson: 0.6987166695077859
[batch 11] cost: 1.6812018 training pearson: 0.8311151002152943
[batch 12] cost: 1.2159425 training pearson: 0.6172047480205669
[batch 13] cost: 0.9129036 training pearson: 0.7597644512080652
[batch 14] cost: 1.214071 training pearson: 0.7655153236760865
[batch 15] cost: 1.3496858 training pearson: 0.8326334087751979
epoch:  75 pearson: test_pearson:  0.719314380265777
============gbrt============
epoch:  75 pearson: ml_test_pearson:  0.7067375175057624
============xgb============
epoch:  75 pearson: ml_test_pearson:  0.6781165136294857
============rfr============
epoch:  75 pearson: ml_test_pearson:  0.6742440843675024
===============模型average结果==================
epoch:  75 pearson: ml_test_pearson:  0.7048345645341365
[Epoch 76]
[batch 1] cost: 1.5222205 training pearson: 0.8277758491447033
[batch 2] cost: 0.7874307 training pearson: 0.7998184954363772
[batch 3] cost: 1.110148 training pearson: 0.7570661510581324
[batch 4] cost: 1.2743312 training pearson: 0.7370858249970407
[batch 5] cost: 1.319205 training pearson: 0.6825687863599031
[batch 6] cost: 1.131598 training pearson: 0.8057597300836591
[batch 7] cost: 1.0081258 training pearson: 0.856572819963581
[batch 8] cost: 1.1577893 training pearson: 0.700394289739174
[batch 9] cost: 1.2526026 training pearson: 0.789011425284558
[batch 10] cost: 0.6626143 training pearson: 0.6246230261761724
[batch 11] cost: 1.0063558 training pearson: 0.5412540763930102
[batch 12] cost: 1.1285037 training pearson: 0.7408566708356128
[batch 13] cost: 0.87454623 training pearson: 0.7608084037739555
[batch 14] cost: 0.8779683 training pearson: 0.6792100392812469
[batch 15] cost: 1.0415444 training pearson: 0.7783024572183752
epoch:  76 pearson: test_pearson:  0.7192520091942025
============gbrt============
epoch:  76 pearson: ml_test_pearson:  0.701927532413165
============xgb============
epoch:  76 pearson: ml_test_pearson:  0.6715014528300466
============rfr============
epoch:  76 pearson: ml_test_pearson:  0.6656748023139031
===============模型average结果==================
epoch:  76 pearson: ml_test_pearson:  0.696930759235645
[Epoch 77]
[batch 1] cost: 0.9808646 training pearson: 0.7509419477700231
[batch 2] cost: 1.1857694 training pearson: 0.8058803495082685
[batch 3] cost: 0.9632199 training pearson: 0.63907885254413
[batch 4] cost: 1.3725048 training pearson: 0.8042215198299424
[batch 5] cost: 0.8851514 training pearson: 0.7763283995386664
[batch 6] cost: 1.215344 training pearson: 0.7600531232887416
[batch 7] cost: 0.7526732 training pearson: 0.7702506308049325
[batch 8] cost: 0.97742516 training pearson: 0.7649066693402425
[batch 9] cost: 0.82006776 training pearson: 0.559573794518918
[batch 10] cost: 1.1419612 training pearson: 0.8312964912242585
[batch 11] cost: 0.9449616 training pearson: 0.728730190394408
[batch 12] cost: 1.4654374 training pearson: 0.8529510955129321
[batch 13] cost: 1.154863 training pearson: 0.7260782195467095
[batch 14] cost: 1.1682324 training pearson: 0.7659705580528747
[batch 15] cost: 1.1274658 training pearson: 0.6835767619194455
epoch:  77 pearson: test_pearson:  0.7193142726442384
============gbrt============
epoch:  77 pearson: ml_test_pearson:  0.7207134002961683
============xgb============
epoch:  77 pearson: ml_test_pearson:  0.6890437003880493
============rfr============
epoch:  77 pearson: ml_test_pearson:  0.6775775262337381
===============模型average结果==================
epoch:  77 pearson: ml_test_pearson:  0.7136614251053854
[Epoch 78]
[batch 1] cost: 0.72650635 training pearson: 0.6006707912632563
[batch 2] cost: 1.0571249 training pearson: 0.8001597465652583
[batch 3] cost: 0.9796559 training pearson: 0.7912742719957664
[batch 4] cost: 1.1068118 training pearson: 0.7461631436812184
[batch 5] cost: 1.0338254 training pearson: 0.8170715685927284
[batch 6] cost: 1.4332467 training pearson: 0.7966836732181887
[batch 7] cost: 0.872973 training pearson: 0.711510761342841
[batch 8] cost: 1.202298 training pearson: 0.6976932464215398
[batch 9] cost: 1.2248373 training pearson: 0.7851682288180204
[batch 10] cost: 1.1863178 training pearson: 0.8140894060208584
[batch 11] cost: 1.059923 training pearson: 0.837447962079687
[batch 12] cost: 1.1351291 training pearson: 0.7880002975755325
[batch 13] cost: 1.022609 training pearson: 0.668592445157348
[batch 14] cost: 0.90154696 training pearson: 0.4579570082053212
[batch 15] cost: 1.0250156 training pearson: 0.7127769243987283
epoch:  78 pearson: test_pearson:  0.7191726457513137
============gbrt============
epoch:  78 pearson: ml_test_pearson:  0.7061387303916115
============xgb============
epoch:  78 pearson: ml_test_pearson:  0.6878313682822008
============rfr============
epoch:  78 pearson: ml_test_pearson:  0.6816513666701386
===============模型average结果==================
epoch:  78 pearson: ml_test_pearson:  0.7097216650582238
[Epoch 79]
[batch 1] cost: 1.3465613 training pearson: 0.763662773335951
[batch 2] cost: 0.7408339 training pearson: 0.8341217317784477
[batch 3] cost: 1.0681624 training pearson: 0.7080869213334368
[batch 4] cost: 1.0173006 training pearson: 0.6832226180854314
[batch 5] cost: 1.0322788 training pearson: 0.7850008748368122
[batch 6] cost: 0.56831247 training pearson: 0.5579941354521144
[batch 7] cost: 0.7108759 training pearson: 0.6475282675027532
[batch 8] cost: 1.3272547 training pearson: 0.6188225807660281
[batch 9] cost: 0.943434 training pearson: 0.8287005916165612
[batch 10] cost: 1.1747974 training pearson: 0.7163921700272606
[batch 11] cost: 1.0397711 training pearson: 0.8561005438089434
[batch 12] cost: 0.9985855 training pearson: 0.6914825964782894
[batch 13] cost: 1.1958596 training pearson: 0.7678860030201485
[batch 14] cost: 1.2584634 training pearson: 0.8495106658418538
[batch 15] cost: 1.5224876 training pearson: 0.7419819186342248
epoch:  79 pearson: test_pearson:  0.7192311517819642
============gbrt============
epoch:  79 pearson: ml_test_pearson:  0.713409539040099
============xgb============
epoch:  79 pearson: ml_test_pearson:  0.6928168587071996
============rfr============
epoch:  79 pearson: ml_test_pearson:  0.7026712407839714
===============模型average结果==================
epoch:  79 pearson: ml_test_pearson:  0.7223348191043799
[Epoch 80]
[batch 1] cost: 1.9179856 training pearson: 0.7712532538243406
[batch 2] cost: 0.95436674 training pearson: 0.6918284494792745
[batch 3] cost: 1.2726387 training pearson: 0.6843082318779196
[batch 4] cost: 0.8761575 training pearson: 0.6712222581050691
[batch 5] cost: 0.80166227 training pearson: 0.6899575622228103
[batch 6] cost: 0.8122731 training pearson: 0.6961342821990093
[batch 7] cost: 0.9370656 training pearson: 0.7758359342812173
[batch 8] cost: 1.3131149 training pearson: 0.8213931420503547
[batch 9] cost: 0.92170495 training pearson: 0.771438404638498
[batch 10] cost: 0.98355985 training pearson: 0.7667879151685103
[batch 11] cost: 0.9078453 training pearson: 0.8237133055612638
[batch 12] cost: 0.87660277 training pearson: 0.7620495596973692
[batch 13] cost: 1.2498301 training pearson: 0.7420506784689401
[batch 14] cost: 0.9096124 training pearson: 0.7155119203496775
[batch 15] cost: 1.0969709 training pearson: 0.8173063478328858
epoch:  80 pearson: test_pearson:  0.7191556617339399
============gbrt============
epoch:  80 pearson: ml_test_pearson:  0.7137169389858383
============xgb============
epoch:  80 pearson: ml_test_pearson:  0.6831608749958843
============rfr============
epoch:  80 pearson: ml_test_pearson:  0.6877310480587732
===============模型average结果==================
epoch:  80 pearson: ml_test_pearson:  0.7124339322027401
[Epoch 81]
[batch 1] cost: 0.9901326 training pearson: 0.8173893446840281
[batch 2] cost: 1.0509088 training pearson: 0.6272243253469776
[batch 3] cost: 1.1406157 training pearson: 0.8008970600196772
[batch 4] cost: 1.1062462 training pearson: 0.8380354005532197
[batch 5] cost: 1.0743196 training pearson: 0.7640598359028626
[batch 6] cost: 1.6192974 training pearson: 0.8068768183177953
[batch 7] cost: 0.5300133 training pearson: 0.6515542817216077
[batch 8] cost: 0.9165769 training pearson: 0.742263280645974
[batch 9] cost: 0.7858017 training pearson: 0.8104553053701606
[batch 10] cost: 0.70004106 training pearson: 0.63981582513521
[batch 11] cost: 1.3205347 training pearson: 0.6909823070405213
[batch 12] cost: 0.94613093 training pearson: 0.6490357841169403
[batch 13] cost: 1.2952036 training pearson: 0.7362520325702991
[batch 14] cost: 1.0912614 training pearson: 0.7626374868024772
[batch 15] cost: 1.2408588 training pearson: 0.7862595565932459
epoch:  81 pearson: test_pearson:  0.719181325672767
============gbrt============
epoch:  81 pearson: ml_test_pearson:  0.7112853652019895
============xgb============
epoch:  81 pearson: ml_test_pearson:  0.6890361428255222
============rfr============
epoch:  81 pearson: ml_test_pearson:  0.685126227321909
===============模型average结果==================
epoch:  81 pearson: ml_test_pearson:  0.7132901939124857
[Epoch 82]
[batch 1] cost: 1.6156037 training pearson: 0.7850926743693394
[batch 2] cost: 0.83050036 training pearson: 0.7763595772677067
[batch 3] cost: 1.0099764 training pearson: 0.732416558723825
[batch 4] cost: 1.1482747 training pearson: 0.48328654656605724
[batch 5] cost: 1.0998112 training pearson: 0.7848568149362855
[batch 6] cost: 1.0182527 training pearson: 0.8189302947859879
[batch 7] cost: 0.50761724 training pearson: 0.7969703868748785
[batch 8] cost: 1.2398279 training pearson: 0.724003100014815
[batch 9] cost: 1.1264999 training pearson: 0.8272991330437969
[batch 10] cost: 0.8168256 training pearson: 0.7828112250053634
[batch 11] cost: 0.90195394 training pearson: 0.769401343030205
[batch 12] cost: 1.4257601 training pearson: 0.730658393570315
[batch 13] cost: 0.9312314 training pearson: 0.7199801343105416
[batch 14] cost: 1.0641431 training pearson: 0.7465656202327839
[batch 15] cost: 0.92943853 training pearson: 0.7235603260819762
epoch:  82 pearson: test_pearson:  0.7190014376501903
============gbrt============
epoch:  82 pearson: ml_test_pearson:  0.7063153067321789
============xgb============
epoch:  82 pearson: ml_test_pearson:  0.695825085366273
============rfr============
epoch:  82 pearson: ml_test_pearson:  0.6709297844182145
===============模型average结果==================
epoch:  82 pearson: ml_test_pearson:  0.7090765758260444
[Epoch 83]
[batch 1] cost: 1.5295029 training pearson: 0.7975899184196756
[batch 2] cost: 1.0578638 training pearson: 0.7723727985417573
[batch 3] cost: 0.76590973 training pearson: 0.4590306512227701
[batch 4] cost: 0.96782106 training pearson: 0.6641604212265088
[batch 5] cost: 1.6669208 training pearson: 0.7804571042634822
[batch 6] cost: 1.1009554 training pearson: 0.6841924616347677
[batch 7] cost: 1.0695012 training pearson: 0.811709058167742
[batch 8] cost: 1.1592398 training pearson: 0.814293946465336
[batch 9] cost: 0.9417384 training pearson: 0.8265950959835949
[batch 10] cost: 0.7348218 training pearson: 0.6741399952467904
[batch 11] cost: 0.9557579 training pearson: 0.7149399507623478
[batch 12] cost: 0.8868026 training pearson: 0.6670835652498516
[batch 13] cost: 0.84979796 training pearson: 0.7417206738991486
[batch 14] cost: 0.9697677 training pearson: 0.7578415096309001
[batch 15] cost: 0.9540851 training pearson: 0.798336510675106
epoch:  83 pearson: test_pearson:  0.7190642312504226
============gbrt============
epoch:  83 pearson: ml_test_pearson:  0.7073462572035772
============xgb============
epoch:  83 pearson: ml_test_pearson:  0.687510191169895
============rfr============
epoch:  83 pearson: ml_test_pearson:  0.6739600759181424
===============模型average结果==================
epoch:  83 pearson: ml_test_pearson:  0.7080338650413616
[Epoch 84]
[batch 1] cost: 1.0695624 training pearson: 0.7584607488224431
[batch 2] cost: 1.3147278 training pearson: 0.8287825214446681
[batch 3] cost: 1.4506149 training pearson: 0.7738054029287653
[batch 4] cost: 1.0304751 training pearson: 0.7567574480731052
[batch 5] cost: 0.88776135 training pearson: 0.8054163049731184
[batch 6] cost: 1.0809975 training pearson: 0.734854031839799
[batch 7] cost: 0.7189337 training pearson: 0.8239390072880749
[batch 8] cost: 0.5357411 training pearson: 0.7069789917735038
[batch 9] cost: 0.93308973 training pearson: 0.7685400448587396
[batch 10] cost: 1.055025 training pearson: 0.786017853792254
[batch 11] cost: 0.807669 training pearson: 0.5504384928996817
[batch 12] cost: 0.946286 training pearson: 0.7363013919222704
[batch 13] cost: 1.5303687 training pearson: 0.8299122005444589
[batch 14] cost: 1.3829116 training pearson: 0.6394274740492996
[batch 15] cost: 0.8294072 training pearson: 0.6809749870128035
epoch:  84 pearson: test_pearson:  0.7189455253337812
============gbrt============
epoch:  84 pearson: ml_test_pearson:  0.704150548739339
============xgb============
epoch:  84 pearson: ml_test_pearson:  0.6820157580563628
============rfr============
epoch:  84 pearson: ml_test_pearson:  0.697094292172873
===============模型average结果==================
epoch:  84 pearson: ml_test_pearson:  0.7141159640118403
[Epoch 85]
[batch 1] cost: 1.1613222 training pearson: 0.7253706164459761
[batch 2] cost: 1.0893365 training pearson: 0.830297792604232
[batch 3] cost: 1.0994376 training pearson: 0.68908510882149
[batch 4] cost: 1.0143974 training pearson: 0.7974794445695916
[batch 5] cost: 0.86291975 training pearson: 0.6558035997023893
[batch 6] cost: 1.121707 training pearson: 0.7621476149317522
[batch 7] cost: 1.132515 training pearson: 0.7983115302337119
[batch 8] cost: 0.8959024 training pearson: 0.6563488085975533
[batch 9] cost: 0.92743284 training pearson: 0.813884322289485
[batch 10] cost: 0.91106355 training pearson: 0.737001509459249
[batch 11] cost: 0.6514761 training pearson: 0.6936573657121751
[batch 12] cost: 0.9580931 training pearson: 0.7154716609987564
[batch 13] cost: 1.3669766 training pearson: 0.711784928999203
[batch 14] cost: 1.2004647 training pearson: 0.7672466060863942
[batch 15] cost: 1.0503109 training pearson: 0.816968642575083
epoch:  85 pearson: test_pearson:  0.7189032257066468
============gbrt============
epoch:  85 pearson: ml_test_pearson:  0.7163459078355823
============xgb============
epoch:  85 pearson: ml_test_pearson:  0.6832032050815401
============rfr============
epoch:  85 pearson: ml_test_pearson:  0.6865268438827502
===============模型average结果==================
epoch:  85 pearson: ml_test_pearson:  0.7130495427899527
[Epoch 86]
[batch 1] cost: 0.98657304 training pearson: 0.8097766241159646
[batch 2] cost: 1.2712778 training pearson: 0.7374472848296328
[batch 3] cost: 0.9360449 training pearson: 0.6789510294295238
[batch 4] cost: 1.6773697 training pearson: 0.690038474773168
[batch 5] cost: 1.1030196 training pearson: 0.6750617179792952
[batch 6] cost: 1.3718557 training pearson: 0.8130227268414879
[batch 7] cost: 0.98469996 training pearson: 0.7775456846170142
[batch 8] cost: 0.8429448 training pearson: 0.7148034476498832
[batch 9] cost: 0.9082182 training pearson: 0.7781308659776182
[batch 10] cost: 0.8692494 training pearson: 0.8034746786649097
[batch 11] cost: 0.99403745 training pearson: 0.6752066312135051
[batch 12] cost: 0.6663069 training pearson: 0.7556756652494449
[batch 13] cost: 1.0038233 training pearson: 0.8389215170803821
[batch 14] cost: 0.7472684 training pearson: 0.6154130550477702
[batch 15] cost: 1.046071 training pearson: 0.7489509562148629
epoch:  86 pearson: test_pearson:  0.7188749719898592
============gbrt============
epoch:  86 pearson: ml_test_pearson:  0.7123103548192383
============xgb============
epoch:  86 pearson: ml_test_pearson:  0.6734114606479854
============rfr============
epoch:  86 pearson: ml_test_pearson:  0.6915503281661279
===============模型average结果==================
epoch:  86 pearson: ml_test_pearson:  0.7137352580823445
[Epoch 87]
[batch 1] cost: 1.57128 training pearson: 0.8384753497517509
[batch 2] cost: 1.1966664 training pearson: 0.823624165373029
[batch 3] cost: 0.926811 training pearson: 0.6340786294899263
[batch 4] cost: 0.7654022 training pearson: 0.7420560451364615
[batch 5] cost: 1.0095325 training pearson: 0.7349591858233324
[batch 6] cost: 0.8175609 training pearson: 0.8634555708679877
[batch 7] cost: 1.26927 training pearson: 0.6009191250565383
[batch 8] cost: 0.90932184 training pearson: 0.7938384579708089
[batch 9] cost: 0.53357947 training pearson: 0.6685173857290604
[batch 10] cost: 0.91610444 training pearson: 0.5852529147335107
[batch 11] cost: 1.372018 training pearson: 0.7574877913501207
[batch 12] cost: 1.2285858 training pearson: 0.8104059043573676
[batch 13] cost: 1.012876 training pearson: 0.7029324680310735
[batch 14] cost: 0.9476316 training pearson: 0.8425552357522682
[batch 15] cost: 0.82178205 training pearson: 0.8157849088463175
epoch:  87 pearson: test_pearson:  0.7188918764031719
============gbrt============
epoch:  87 pearson: ml_test_pearson:  0.7165571156206328
============xgb============
epoch:  87 pearson: ml_test_pearson:  0.6814076482429282
============rfr============
epoch:  87 pearson: ml_test_pearson:  0.6925396942687735
===============模型average结果==================
epoch:  87 pearson: ml_test_pearson:  0.7155901172411459
[Epoch 88]
[batch 1] cost: 0.74913347 training pearson: 0.6940243321433079
[batch 2] cost: 0.7470433 training pearson: 0.5031727549468659
[batch 3] cost: 1.0175129 training pearson: 0.7823851840127207
[batch 4] cost: 0.912637 training pearson: 0.7720843637770743
[batch 5] cost: 1.3172148 training pearson: 0.7916397800886004
[batch 6] cost: 0.83063185 training pearson: 0.7094597486871901
[batch 7] cost: 1.1789157 training pearson: 0.6974830961312463
[batch 8] cost: 0.85226 training pearson: 0.7925582302918275
[batch 9] cost: 0.97439337 training pearson: 0.8018411370833098
[batch 10] cost: 1.1082653 training pearson: 0.7607410515065722
[batch 11] cost: 1.303094 training pearson: 0.7888967170225278
[batch 12] cost: 1.0650735 training pearson: 0.7227740141093704
[batch 13] cost: 1.2043743 training pearson: 0.7676310446250104
[batch 14] cost: 0.9215917 training pearson: 0.8164485699516592
[batch 15] cost: 1.0411544 training pearson: 0.66038422830256
epoch:  88 pearson: test_pearson:  0.718802175439295
============gbrt============
epoch:  88 pearson: ml_test_pearson:  0.7186379364628166
============xgb============
epoch:  88 pearson: ml_test_pearson:  0.691710361505327
============rfr============
epoch:  88 pearson: ml_test_pearson:  0.6958397381555154
===============模型average结果==================
epoch:  88 pearson: ml_test_pearson:  0.7211166496232969
[Epoch 89]
[batch 1] cost: 0.75503 training pearson: 0.5913536573757819
[batch 2] cost: 0.9278932 training pearson: 0.6919464924365821
[batch 3] cost: 1.3447071 training pearson: 0.7597476085093687
[batch 4] cost: 1.2205945 training pearson: 0.8219760704785426
[batch 5] cost: 1.092394 training pearson: 0.7764405969947187
[batch 6] cost: 1.0998576 training pearson: 0.7344599634706911
[batch 7] cost: 0.8726453 training pearson: 0.8176610031649046
[batch 8] cost: 1.0723872 training pearson: 0.765764064978791
[batch 9] cost: 1.2840202 training pearson: 0.7866978288467142
[batch 10] cost: 1.0001211 training pearson: 0.7649966943357388
[batch 11] cost: 1.0789979 training pearson: 0.7176489077953884
[batch 12] cost: 0.9260647 training pearson: 0.6577305792329592
[batch 13] cost: 0.9064519 training pearson: 0.690549888012784
[batch 14] cost: 0.863834 training pearson: 0.7815056077458107
[batch 15] cost: 0.7219703 training pearson: 0.7629197144538461
epoch:  89 pearson: test_pearson:  0.7188357332985421
============gbrt============
epoch:  89 pearson: ml_test_pearson:  0.7028107273372641
============xgb============
epoch:  89 pearson: ml_test_pearson:  0.6899079452086854
============rfr============
epoch:  89 pearson: ml_test_pearson:  0.6721870266787765
===============模型average结果==================
epoch:  89 pearson: ml_test_pearson:  0.7051938422420397
[Epoch 90]
[batch 1] cost: 0.93330216 training pearson: 0.6555796463272308
[batch 2] cost: 1.1371505 training pearson: 0.7670275139792959
[batch 3] cost: 1.183441 training pearson: 0.7752601801339638
[batch 4] cost: 0.97591203 training pearson: 0.7694184624662084
[batch 5] cost: 0.8297899 training pearson: 0.6671777146532875
[batch 6] cost: 0.9657354 training pearson: 0.8119694812682198
[batch 7] cost: 0.60072595 training pearson: 0.7310035163492744
[batch 8] cost: 0.94114596 training pearson: 0.6829421824081737
[batch 9] cost: 1.3227066 training pearson: 0.8279209912124798
[batch 10] cost: 0.8732425 training pearson: 0.6431535333173647
[batch 11] cost: 0.9030435 training pearson: 0.7333972645174244
[batch 12] cost: 1.4288583 training pearson: 0.8261093989843111
[batch 13] cost: 0.97792727 training pearson: 0.7719267200646961
[batch 14] cost: 1.0661219 training pearson: 0.8068548427496777
[batch 15] cost: 0.9474241 training pearson: 0.71095149665787
epoch:  90 pearson: test_pearson:  0.7187550617523973
============gbrt============
epoch:  90 pearson: ml_test_pearson:  0.7178857679063736
============xgb============
epoch:  90 pearson: ml_test_pearson:  0.6818306590099174
============rfr============
epoch:  90 pearson: ml_test_pearson:  0.681581943137316
===============模型average结果==================
epoch:  90 pearson: ml_test_pearson:  0.7111133023571922
[Epoch 91]
[batch 1] cost: 1.1755316 training pearson: 0.7032519462987333
[batch 2] cost: 1.0316275 training pearson: 0.8054794546853891
[batch 3] cost: 0.96948296 training pearson: 0.6728230785122902
[batch 4] cost: 0.92130935 training pearson: 0.7941505412147812
[batch 5] cost: 0.7405785 training pearson: 0.6701624392998067
[batch 6] cost: 1.4160755 training pearson: 0.7882372642243738
[batch 7] cost: 0.7348761 training pearson: 0.7416341417046033
[batch 8] cost: 1.3628855 training pearson: 0.8650570482088467
[batch 9] cost: 1.0201554 training pearson: 0.7056061458784674
[batch 10] cost: 1.2780153 training pearson: 0.7870973472930936
[batch 11] cost: 0.8604303 training pearson: 0.7652396207768467
[batch 12] cost: 0.8420238 training pearson: 0.7591960971346814
[batch 13] cost: 0.83835435 training pearson: 0.6845495296429711
[batch 14] cost: 0.8056788 training pearson: 0.6084150290565292
[batch 15] cost: 1.0343024 training pearson: 0.7277680935241154
epoch:  91 pearson: test_pearson:  0.7186863757733862
============gbrt============
epoch:  91 pearson: ml_test_pearson:  0.7039478302177634
============xgb============
epoch:  91 pearson: ml_test_pearson:  0.6848878653234605
============rfr============
epoch:  91 pearson: ml_test_pearson:  0.6816076583237262
===============模型average结果==================
epoch:  91 pearson: ml_test_pearson:  0.708053767628903
[Epoch 92]
[batch 1] cost: 1.0992234 training pearson: 0.6715478212354586
[batch 2] cost: 0.728838 training pearson: 0.7074401720126178
[batch 3] cost: 0.86346865 training pearson: 0.7329759205483598
[batch 4] cost: 1.510487 training pearson: 0.7578389399689724
[batch 5] cost: 0.7577312 training pearson: 0.7311706039118089
[batch 6] cost: 0.8042009 training pearson: 0.7517908142595815
[batch 7] cost: 0.7678128 training pearson: 0.7134194736230366
[batch 8] cost: 1.2279972 training pearson: 0.7938187812218542
[batch 9] cost: 0.7960789 training pearson: 0.7710036067454483
[batch 10] cost: 0.92003554 training pearson: 0.7165944144346607
[batch 11] cost: 1.1945901 training pearson: 0.7520075099110664
[batch 12] cost: 0.8566362 training pearson: 0.7022126879094535
[batch 13] cost: 1.3982288 training pearson: 0.7874706030678882
[batch 14] cost: 1.2562106 training pearson: 0.8326382868500389
[batch 15] cost: 0.76330256 training pearson: 0.6135563750116697
epoch:  92 pearson: test_pearson:  0.7186779719302016
============gbrt============
epoch:  92 pearson: ml_test_pearson:  0.7138580918477859
============xgb============
epoch:  92 pearson: ml_test_pearson:  0.6825299670109577
============rfr============
epoch:  92 pearson: ml_test_pearson:  0.6751519744253709
===============模型average结果==================
epoch:  92 pearson: ml_test_pearson:  0.707406365010215
[Epoch 93]
[batch 1] cost: 0.83222693 training pearson: 0.6825050937101602
[batch 2] cost: 0.6736221 training pearson: 0.8137988468397069
[batch 3] cost: 1.151725 training pearson: 0.8578965302405506
[batch 4] cost: 0.65888387 training pearson: 0.8084292174102815
[batch 5] cost: 1.3307456 training pearson: 0.591469003344342
[batch 6] cost: 1.1151538 training pearson: 0.7565865865543048
[batch 7] cost: 0.9685159 training pearson: 0.6976825335198238
[batch 8] cost: 1.2454405 training pearson: 0.7594923820275935
[batch 9] cost: 0.9601751 training pearson: 0.7923035159896687
[batch 10] cost: 1.1554351 training pearson: 0.7709572231031537
[batch 11] cost: 1.0710067 training pearson: 0.7070383219217411
[batch 12] cost: 0.66979426 training pearson: 0.6630100669372974
[batch 13] cost: 1.1965858 training pearson: 0.8399106244574087
[batch 14] cost: 1.2034311 training pearson: 0.7584470172997632
[batch 15] cost: 0.6616185 training pearson: 0.6057504490852371
epoch:  93 pearson: test_pearson:  0.7186407363681862
============gbrt============
epoch:  93 pearson: ml_test_pearson:  0.7000583943006291
============xgb============
epoch:  93 pearson: ml_test_pearson:  0.681466450714429
============rfr============
epoch:  93 pearson: ml_test_pearson:  0.6790996116680029
===============模型average结果==================
epoch:  93 pearson: ml_test_pearson:  0.7032322479299
[Epoch 94]
[batch 1] cost: 1.1408578 training pearson: 0.6868791840823284
[batch 2] cost: 1.2181919 training pearson: 0.8110089947321392
[batch 3] cost: 1.1670834 training pearson: 0.7815179631231645
[batch 4] cost: 1.2573161 training pearson: 0.7509781826970128
[batch 5] cost: 1.4269555 training pearson: 0.8235894467959295
[batch 6] cost: 1.3381743 training pearson: 0.7486307181105938
[batch 7] cost: 0.81357455 training pearson: 0.665349557996535
[batch 8] cost: 0.48839042 training pearson: 0.647577848012079
[batch 9] cost: 0.79109716 training pearson: 0.784173007945752
[batch 10] cost: 0.689693 training pearson: 0.7421574441274689
[batch 11] cost: 0.9859996 training pearson: 0.8063508540954174
[batch 12] cost: 0.9045211 training pearson: 0.7405601418828253
[batch 13] cost: 0.6569323 training pearson: 0.567565324707663
[batch 14] cost: 1.1712898 training pearson: 0.6957824308407256
[batch 15] cost: 0.7937464 training pearson: 0.7799419963102784
epoch:  94 pearson: test_pearson:  0.7185819561402105
============gbrt============
epoch:  94 pearson: ml_test_pearson:  0.7174116239564099
============xgb============
epoch:  94 pearson: ml_test_pearson:  0.682198336714382
============rfr============
epoch:  94 pearson: ml_test_pearson:  0.6878687572812967
===============模型average结果==================
epoch:  94 pearson: ml_test_pearson:  0.7136546598784682
[Epoch 95]
[batch 1] cost: 1.0434706 training pearson: 0.7410955091023732
[batch 2] cost: 0.6316998 training pearson: 0.5748326723698678
[batch 3] cost: 1.3231463 training pearson: 0.7289132144169808
[batch 4] cost: 0.8532797 training pearson: 0.6937021720640062
[batch 5] cost: 0.5781615 training pearson: 0.7504690766219638
[batch 6] cost: 0.7142996 training pearson: 0.7299065477671917
[batch 7] cost: 1.3091578 training pearson: 0.8389638771974844
[batch 8] cost: 1.2337686 training pearson: 0.7978402177320761
[batch 9] cost: 0.6708336 training pearson: 0.6649100482026222
[batch 10] cost: 1.2147807 training pearson: 0.6907171439491716
[batch 11] cost: 0.9748346 training pearson: 0.718196567060803
[batch 12] cost: 1.1087741 training pearson: 0.7802102532817353
[batch 13] cost: 0.7308383 training pearson: 0.7163612142087977
[batch 14] cost: 1.3306198 training pearson: 0.7583545449366345
[batch 15] cost: 1.0981264 training pearson: 0.7949715594255132
epoch:  95 pearson: test_pearson:  0.7185700358881217
============gbrt============
epoch:  95 pearson: ml_test_pearson:  0.7068861421811623
============xgb============
epoch:  95 pearson: ml_test_pearson:  0.6992080420359452
============rfr============
epoch:  95 pearson: ml_test_pearson:  0.6781951211824402
===============模型average结果==================
epoch:  95 pearson: ml_test_pearson:  0.7104334867634002
[Epoch 96]
[batch 1] cost: 1.0042387 training pearson: 0.610307839617558
[batch 2] cost: 1.06218 training pearson: 0.7393908519020486
[batch 3] cost: 0.9761206 training pearson: 0.7183667327530935
[batch 4] cost: 1.2238115 training pearson: 0.7398238896102927
[batch 5] cost: 0.88857794 training pearson: 0.6772916693188795
[batch 6] cost: 1.2605075 training pearson: 0.8127917385790734
[batch 7] cost: 1.0698068 training pearson: 0.6877198578901648
[batch 8] cost: 1.3746362 training pearson: 0.8180668872401528
[batch 9] cost: 0.70535356 training pearson: 0.715761831925586
[batch 10] cost: 0.8829958 training pearson: 0.8244114569709806
[batch 11] cost: 1.0620637 training pearson: 0.8553872402528304
[batch 12] cost: 0.57269394 training pearson: 0.7083752334702083
[batch 13] cost: 0.69614625 training pearson: 0.7197690034183373
[batch 14] cost: 0.93333894 training pearson: 0.6916213937319972
[batch 15] cost: 0.9735168 training pearson: 0.7841964024907606
epoch:  96 pearson: test_pearson:  0.7184696564060645
============gbrt============
epoch:  96 pearson: ml_test_pearson:  0.7195774996236884
============xgb============
epoch:  96 pearson: ml_test_pearson:  0.685762233966771
============rfr============
epoch:  96 pearson: ml_test_pearson:  0.6950121224114929
===============模型average结果==================
epoch:  96 pearson: ml_test_pearson:  0.717921789821113
[Epoch 97]
[batch 1] cost: 1.0144562 training pearson: 0.7684095816360179
[batch 2] cost: 1.0082377 training pearson: 0.8499774671822712
[batch 3] cost: 0.88249993 training pearson: 0.7083346993771248
[batch 4] cost: 0.59938437 training pearson: 0.8121002900032899
[batch 5] cost: 1.4610463 training pearson: 0.8228324896093996
[batch 6] cost: 0.6064747 training pearson: 0.6576681032915186
[batch 7] cost: 0.7586572 training pearson: 0.5834469410421017
[batch 8] cost: 0.8355212 training pearson: 0.7838561663284481
[batch 9] cost: 1.1691918 training pearson: 0.7722414238159141
[batch 10] cost: 1.0033413 training pearson: 0.7583225415108471
[batch 11] cost: 1.3877372 training pearson: 0.8089289204946801
[batch 12] cost: 1.0687183 training pearson: 0.7597448996299191
[batch 13] cost: 1.012855 training pearson: 0.5333853126805285
[batch 14] cost: 0.7517708 training pearson: 0.7985664361200715
[batch 15] cost: 1.0614892 training pearson: 0.722314479194199
epoch:  97 pearson: test_pearson:  0.7184924531363698
============gbrt============
epoch:  97 pearson: ml_test_pearson:  0.7121552830320055
============xgb============
epoch:  97 pearson: ml_test_pearson:  0.678314842088397
============rfr============
epoch:  97 pearson: ml_test_pearson:  0.6781915824230066
===============模型average结果==================
epoch:  97 pearson: ml_test_pearson:  0.7082658417544795
[Epoch 98]
[batch 1] cost: 0.79945207 training pearson: 0.7436575723272735
[batch 2] cost: 1.0512575 training pearson: 0.7490940238061081
[batch 3] cost: 0.91382563 training pearson: 0.6258400666784334
[batch 4] cost: 0.74447966 training pearson: 0.6017836606312233
[batch 5] cost: 0.76387465 training pearson: 0.8777491424804732
[batch 6] cost: 1.2209156 training pearson: 0.7184372761969118
[batch 7] cost: 0.78891945 training pearson: 0.7470974728032591
[batch 8] cost: 0.82087374 training pearson: 0.725184762017102
[batch 9] cost: 1.1293305 training pearson: 0.8003890798672433
[batch 10] cost: 0.8798847 training pearson: 0.7800995737810439
[batch 11] cost: 0.7962488 training pearson: 0.807683152725573
[batch 12] cost: 1.5943787 training pearson: 0.713493947748749
[batch 13] cost: 0.87306005 training pearson: 0.819879957097979
[batch 14] cost: 0.89390403 training pearson: 0.7936617511069404
[batch 15] cost: 1.3167748 training pearson: 0.6869740125759233
epoch:  98 pearson: test_pearson:  0.7183909670358661
============gbrt============
epoch:  98 pearson: ml_test_pearson:  0.718055504526239
============xgb============
epoch:  98 pearson: ml_test_pearson:  0.688280098413415
============rfr============
epoch:  98 pearson: ml_test_pearson:  0.6927943404485155
===============模型average结果==================
epoch:  98 pearson: ml_test_pearson:  0.7169198362424605
[Epoch 99]
[batch 1] cost: 0.58173853 training pearson: 0.7674804928817883
[batch 2] cost: 0.87380964 training pearson: 0.822409396349537
[batch 3] cost: 0.8309294 training pearson: 0.820942784863847
[batch 4] cost: 1.1910691 training pearson: 0.7375392707763344
[batch 5] cost: 1.202204 training pearson: 0.6434377858696129
[batch 6] cost: 1.3765465 training pearson: 0.7328086087788658
[batch 7] cost: 0.8670888 training pearson: 0.7921995587309845
[batch 8] cost: 0.7210676 training pearson: 0.7200331170768193
[batch 9] cost: 0.9147055 training pearson: 0.804431183005325
[batch 10] cost: 0.545012 training pearson: 0.5429276316552002
[batch 11] cost: 1.2273474 training pearson: 0.7281064112951057
[batch 12] cost: 1.29324 training pearson: 0.8229148010415337
[batch 13] cost: 0.90350235 training pearson: 0.6649978431710681
[batch 14] cost: 1.0264201 training pearson: 0.7544670696659967
[batch 15] cost: 1.0513616 training pearson: 0.7257379195656128
epoch:  99 pearson: test_pearson:  0.7183879207317222
============gbrt============
epoch:  99 pearson: ml_test_pearson:  0.7176693927995836
============xgb============
epoch:  99 pearson: ml_test_pearson:  0.6866816549173289
============rfr============
epoch:  99 pearson: ml_test_pearson:  0.6815217211379195
===============模型average结果==================
epoch:  99 pearson: ml_test_pearson:  0.7125661811893621
[Epoch 100]
[batch 1] cost: 1.133719 training pearson: 0.7371027862198468
[batch 2] cost: 1.2940469 training pearson: 0.723782608666974
[batch 3] cost: 1.143537 training pearson: 0.7771637278474012
[batch 4] cost: 1.1285712 training pearson: 0.6466219052538619
[batch 5] cost: 1.0063088 training pearson: 0.7634786042899302
[batch 6] cost: 1.2335359 training pearson: 0.8205070274583703
[batch 7] cost: 0.8668276 training pearson: 0.7797607106906351
[batch 8] cost: 0.76191485 training pearson: 0.7235144381266105
[batch 9] cost: 0.83208686 training pearson: 0.7853159879853251
[batch 10] cost: 1.0944387 training pearson: 0.8053419467074749
[batch 11] cost: 1.058251 training pearson: 0.7844975087931049
[batch 12] cost: 0.45812717 training pearson: 0.7364596308495515
[batch 13] cost: 0.7871788 training pearson: 0.6958731203951568
[batch 14] cost: 0.6957812 training pearson: 0.6787240084800993
[batch 15] cost: 0.9612337 training pearson: 0.7671913397810532
epoch:  100 pearson: test_pearson:  0.7183532282281486
============gbrt============
epoch:  100 pearson: ml_test_pearson:  0.7161140839343585
============xgb============
epoch:  100 pearson: ml_test_pearson:  0.6836958603791206
============rfr============
epoch:  100 pearson: ml_test_pearson:  0.6845831376694591
===============模型average结果==================
epoch:  100 pearson: ml_test_pearson:  0.7124619734746063
[Epoch 101]
[batch 1] cost: 0.9571196 training pearson: 0.7828723816312931
[batch 2] cost: 0.8258395 training pearson: 0.71133736645368
[batch 3] cost: 0.6619562 training pearson: 0.6500651156107645
[batch 4] cost: 0.89986646 training pearson: 0.739134957849203
[batch 5] cost: 0.6052568 training pearson: 0.7505799977794743
[batch 6] cost: 1.1411864 training pearson: 0.7406928700379252
[batch 7] cost: 0.88601875 training pearson: 0.8404752869299396
[batch 8] cost: 0.9501286 training pearson: 0.6722545325289493
[batch 9] cost: 0.65217257 training pearson: 0.6055854678305342
[batch 10] cost: 0.9394177 training pearson: 0.7977711757971921
[batch 11] cost: 1.4925563 training pearson: 0.824649111016785
[batch 12] cost: 1.0390319 training pearson: 0.7277268714739334
[batch 13] cost: 1.1925615 training pearson: 0.7439461011217778
[batch 14] cost: 1.0621312 training pearson: 0.5601229748028256
[batch 15] cost: 1.1185617 training pearson: 0.8251624483593764
epoch:  101 pearson: test_pearson:  0.7182933326904587
============gbrt============
epoch:  101 pearson: ml_test_pearson:  0.7239474645460546
============xgb============
epoch:  101 pearson: ml_test_pearson:  0.688811070515833
============rfr============
epoch:  101 pearson: ml_test_pearson:  0.6977129377447001
===============模型average结果==================
epoch:  101 pearson: ml_test_pearson:  0.7213636817921347
[Epoch 102]
[batch 1] cost: 1.2363253 training pearson: 0.5937450419128371
[batch 2] cost: 0.85588646 training pearson: 0.7552200841960914
[batch 3] cost: 0.7805431 training pearson: 0.6761468264673146
[batch 4] cost: 0.8126656 training pearson: 0.7735889958518679
[batch 5] cost: 1.0533391 training pearson: 0.831516276854176
[batch 6] cost: 0.87707657 training pearson: 0.7742695560564533
[batch 7] cost: 1.0722983 training pearson: 0.8152195039174011
[batch 8] cost: 0.8279409 training pearson: 0.7122019495544498
[batch 9] cost: 1.125217 training pearson: 0.7854659891738891
[batch 10] cost: 1.1306434 training pearson: 0.6620453615385276
[batch 11] cost: 0.94554687 training pearson: 0.781541268901324
[batch 12] cost: 0.796132 training pearson: 0.6326210492916551
[batch 13] cost: 0.7160112 training pearson: 0.732552703803282
[batch 14] cost: 1.1746279 training pearson: 0.7693018261836001
[batch 15] cost: 0.876486 training pearson: 0.8430194116162133
epoch:  102 pearson: test_pearson:  0.7182469310483457
============gbrt============
epoch:  102 pearson: ml_test_pearson:  0.7226566028910111
============xgb============
epoch:  102 pearson: ml_test_pearson:  0.6885865054427408
============rfr============
epoch:  102 pearson: ml_test_pearson:  0.7060875994546806
===============模型average结果==================
epoch:  102 pearson: ml_test_pearson:  0.7246704728062716
[Epoch 103]
[batch 1] cost: 0.82099676 training pearson: 0.665157981676942
[batch 2] cost: 1.0096278 training pearson: 0.7906980534256084
[batch 3] cost: 1.249583 training pearson: 0.6112058616167114
[batch 4] cost: 1.1523763 training pearson: 0.8427931436663887
[batch 5] cost: 0.7717539 training pearson: 0.7651128254774554
[batch 6] cost: 0.75682086 training pearson: 0.7416720924035841
[batch 7] cost: 0.8358017 training pearson: 0.7481605381488773
[batch 8] cost: 0.6640431 training pearson: 0.6573832226824343
[batch 9] cost: 1.2307255 training pearson: 0.7929021138889584
[batch 10] cost: 1.3736709 training pearson: 0.77052272611598
[batch 11] cost: 1.147266 training pearson: 0.7819062690783022
[batch 12] cost: 0.96646255 training pearson: 0.785975108939451
[batch 13] cost: 0.70661294 training pearson: 0.8186581358977907
[batch 14] cost: 0.70877075 training pearson: 0.726056867571088
[batch 15] cost: 0.85761213 training pearson: 0.6226155548366926
epoch:  103 pearson: test_pearson:  0.7182281426793752
============gbrt============
epoch:  103 pearson: ml_test_pearson:  0.7250177189486462
============xgb============
epoch:  103 pearson: ml_test_pearson:  0.6921826158515172
============rfr============
epoch:  103 pearson: ml_test_pearson:  0.6687124631333203
===============模型average结果==================
epoch:  103 pearson: ml_test_pearson:  0.7115698211705521
[Epoch 104]
[batch 1] cost: 0.5585607 training pearson: 0.6881993249923347
[batch 2] cost: 0.67473555 training pearson: 0.7496029727756257
[batch 3] cost: 0.94961786 training pearson: 0.689806873105323
[batch 4] cost: 1.0578567 training pearson: 0.6792566886329537
[batch 5] cost: 0.90560865 training pearson: 0.7007275727152484
[batch 6] cost: 0.75836885 training pearson: 0.805521793829298
[batch 7] cost: 0.9672113 training pearson: 0.6405578278282538
[batch 8] cost: 0.8735106 training pearson: 0.8627348464945667
[batch 9] cost: 0.90706635 training pearson: 0.7538333766585211
[batch 10] cost: 1.0093042 training pearson: 0.8196800812833478
[batch 11] cost: 1.2285116 training pearson: 0.7408707782851828
[batch 12] cost: 1.1659236 training pearson: 0.8048971460334964
[batch 13] cost: 1.1082588 training pearson: 0.7741254183277395
[batch 14] cost: 0.9597523 training pearson: 0.6900140076151714
[batch 15] cost: 1.041874 training pearson: 0.7265331017454005
epoch:  104 pearson: test_pearson:  0.7181786032958181
============gbrt============
epoch:  104 pearson: ml_test_pearson:  0.7240653966159291
============xgb============
epoch:  104 pearson: ml_test_pearson:  0.6886750735836853
============rfr============
epoch:  104 pearson: ml_test_pearson:  0.6993256840336121
===============模型average结果==================
epoch:  104 pearson: ml_test_pearson:  0.7228753337956728
[Epoch 105]
[batch 1] cost: 0.4450449 training pearson: 0.6732132041731783
[batch 2] cost: 1.1979545 training pearson: 0.7956518273678206
[batch 3] cost: 1.0850401 training pearson: 0.7885184428420399
[batch 4] cost: 0.8424629 training pearson: 0.6862691057266468
[batch 5] cost: 0.6194844 training pearson: 0.6536935472541704
[batch 6] cost: 0.95490336 training pearson: 0.6382827482479376
[batch 7] cost: 0.98119354 training pearson: 0.7650627466171404
[batch 8] cost: 0.73367935 training pearson: 0.7708022145022352
[batch 9] cost: 1.0299076 training pearson: 0.6845491990779281
[batch 10] cost: 0.86261284 training pearson: 0.7261023492424757
[batch 11] cost: 1.1950793 training pearson: 0.7969322432691068
[batch 12] cost: 1.2600398 training pearson: 0.7565317844764264
[batch 13] cost: 1.1612346 training pearson: 0.7428719580905224
[batch 14] cost: 0.8714929 training pearson: 0.7469635663530894
[batch 15] cost: 0.95178163 training pearson: 0.8746822117572697
epoch:  105 pearson: test_pearson:  0.7181583177709833
============gbrt============
epoch:  105 pearson: ml_test_pearson:  0.71457135123896
============xgb============
epoch:  105 pearson: ml_test_pearson:  0.6867546134761421
============rfr============
epoch:  105 pearson: ml_test_pearson:  0.6889593920771516
===============模型average结果==================
epoch:  105 pearson: ml_test_pearson:  0.7134533952709919
[Epoch 106]
[batch 1] cost: 0.9732092 training pearson: 0.7837579708898672
[batch 2] cost: 0.6228063 training pearson: 0.7733436156740517
[batch 3] cost: 0.7498653 training pearson: 0.7414693720299422
[batch 4] cost: 0.91482896 training pearson: 0.6678478086128081
[batch 5] cost: 0.9248799 training pearson: 0.752555730673974
[batch 6] cost: 1.0470159 training pearson: 0.7282784776785761
[batch 7] cost: 1.148939 training pearson: 0.8512059323305237
[batch 8] cost: 1.3016428 training pearson: 0.8253653731202679
[batch 9] cost: 1.0145056 training pearson: 0.652202346369353
[batch 10] cost: 0.9582425 training pearson: 0.7614040190854648
[batch 11] cost: 0.98226076 training pearson: 0.7299487871381031
[batch 12] cost: 1.0381954 training pearson: 0.7701254307105675
[batch 13] cost: 0.6948555 training pearson: 0.7642583480791126
[batch 14] cost: 0.9674078 training pearson: 0.7025170768088375
[batch 15] cost: 0.7603522 training pearson: 0.7169375433267128
epoch:  106 pearson: test_pearson:  0.7180594740554954
============gbrt============
epoch:  106 pearson: ml_test_pearson:  0.7072843513754002
============xgb============
epoch:  106 pearson: ml_test_pearson:  0.6815822338159145
============rfr============
epoch:  106 pearson: ml_test_pearson:  0.6832129305030019
===============模型average结果==================
epoch:  106 pearson: ml_test_pearson:  0.7068341664380748
[Epoch 107]
[batch 1] cost: 0.7081988 training pearson: 0.7304608883726215
[batch 2] cost: 0.6864402 training pearson: 0.7512321877301523
[batch 3] cost: 1.3491439 training pearson: 0.7492532910383873
[batch 4] cost: 1.3473914 training pearson: 0.6780662006296039
[batch 5] cost: 0.759567 training pearson: 0.5331360446648866
[batch 6] cost: 1.3146309 training pearson: 0.773040558516487
[batch 7] cost: 0.81496835 training pearson: 0.7602770286612494
[batch 8] cost: 1.3079953 training pearson: 0.7513778734585331
[batch 9] cost: 1.0347065 training pearson: 0.7545075379647002
[batch 10] cost: 0.8138847 training pearson: 0.7973765254566634
[batch 11] cost: 0.5580358 training pearson: 0.5548807481300381
[batch 12] cost: 0.8494942 training pearson: 0.8872817524884244
[batch 13] cost: 0.81832623 training pearson: 0.8287997151844938
[batch 14] cost: 1.0247748 training pearson: 0.7130359537109897
[batch 15] cost: 0.6303296 training pearson: 0.8305851642447069
epoch:  107 pearson: test_pearson:  0.7181496950598188
============gbrt============
epoch:  107 pearson: ml_test_pearson:  0.7019210410308755
============xgb============
epoch:  107 pearson: ml_test_pearson:  0.6760349531303232
============rfr============
epoch:  107 pearson: ml_test_pearson:  0.671007022744651
===============模型average结果==================
epoch:  107 pearson: ml_test_pearson:  0.6992755335365698
[Epoch 108]
[batch 1] cost: 0.66296494 training pearson: 0.597927853496611
[batch 2] cost: 0.93455774 training pearson: 0.7526993388351702
[batch 3] cost: 0.63819194 training pearson: 0.7270896524345697
[batch 4] cost: 1.0766759 training pearson: 0.8136565308639022
[batch 5] cost: 1.3377746 training pearson: 0.8019026406059225
[batch 6] cost: 0.71462166 training pearson: 0.7695450190628084
[batch 7] cost: 1.2410796 training pearson: 0.7159213166393751
[batch 8] cost: 0.9557275 training pearson: 0.7031196418052732
[batch 9] cost: 0.517074 training pearson: 0.7378993015193651
[batch 10] cost: 1.3238628 training pearson: 0.7571899380661511
[batch 11] cost: 0.9260958 training pearson: 0.710901936654489
[batch 12] cost: 1.1734743 training pearson: 0.7804567383041319
[batch 13] cost: 0.84314567 training pearson: 0.7750060791353129
[batch 14] cost: 0.7856932 training pearson: 0.7361344019089004
[batch 15] cost: 0.83031756 training pearson: 0.7610234719353017
epoch:  108 pearson: test_pearson:  0.7182599304190671
============gbrt============
epoch:  108 pearson: ml_test_pearson:  0.6939974681623897
============xgb============
epoch:  108 pearson: ml_test_pearson:  0.6557798201447126
============rfr============
epoch:  108 pearson: ml_test_pearson:  0.6497075050546717
===============模型average结果==================
epoch:  108 pearson: ml_test_pearson:  0.6845971429750624
[Epoch 109]
[batch 1] cost: 0.6596031 training pearson: 0.7924801517321433
[batch 2] cost: 0.70792955 training pearson: 0.672945138073899
[batch 3] cost: 1.1599282 training pearson: 0.8622294546212972
[batch 4] cost: 0.8013623 training pearson: 0.7445644558831362
[batch 5] cost: 0.9206836 training pearson: 0.7311566968217786
[batch 6] cost: 1.0707134 training pearson: 0.8445889909866852
[batch 7] cost: 0.88243955 training pearson: 0.6196189643172755
[batch 8] cost: 0.87265396 training pearson: 0.801497591250698
[batch 9] cost: 0.90887237 training pearson: 0.7715618168930592
[batch 10] cost: 0.95217055 training pearson: 0.7355285972915566
[batch 11] cost: 1.1513041 training pearson: 0.7268045527727325
[batch 12] cost: 0.8279033 training pearson: 0.5423094245835225
[batch 13] cost: 1.40047 training pearson: 0.7595528112236284
[batch 14] cost: 0.7358968 training pearson: 0.7934650116800256
[batch 15] cost: 0.8301461 training pearson: 0.7243496285926525
epoch:  109 pearson: test_pearson:  0.7182252986207577
============gbrt============
epoch:  109 pearson: ml_test_pearson:  0.6709387319980614
============xgb============
epoch:  109 pearson: ml_test_pearson:  0.6580315894433078
============rfr============
epoch:  109 pearson: ml_test_pearson:  0.6529174147550328
===============模型average结果==================
epoch:  109 pearson: ml_test_pearson:  0.6820236205305673
[Epoch 110]
[batch 1] cost: 1.0145572 training pearson: 0.7738750490555546
[batch 2] cost: 0.6566604 training pearson: 0.7897412728348412
[batch 3] cost: 1.2286637 training pearson: 0.812717201854523
[batch 4] cost: 0.83630174 training pearson: 0.659203568352166
[batch 5] cost: 0.7322414 training pearson: 0.7841187321400361
[batch 6] cost: 0.39811334 training pearson: 0.590839558968115
[batch 7] cost: 0.716082 training pearson: 0.7566512173511231
[batch 8] cost: 0.6503088 training pearson: 0.6316671856341095
[batch 9] cost: 0.9665654 training pearson: 0.6781692578562588
[batch 10] cost: 0.84305495 training pearson: 0.7350318250220312
[batch 11] cost: 0.98790663 training pearson: 0.8063004105678454
[batch 12] cost: 1.0100533 training pearson: 0.7290725268912426
[batch 13] cost: 1.403831 training pearson: 0.7705255177834304
[batch 14] cost: 1.113955 training pearson: 0.805377412058953
[batch 15] cost: 1.2331086 training pearson: 0.8111392835927673
epoch:  110 pearson: test_pearson:  0.7182255529028603
============gbrt============
epoch:  110 pearson: ml_test_pearson:  0.6798783108844069
============xgb============
epoch:  110 pearson: ml_test_pearson:  0.6851612609955892
============rfr============
epoch:  110 pearson: ml_test_pearson:  0.6540614762990759
===============模型average结果==================
epoch:  110 pearson: ml_test_pearson:  0.6878121694512119
[Epoch 111]
[batch 1] cost: 0.81021845 training pearson: 0.7689132547005948
[batch 2] cost: 0.9584828 training pearson: 0.7469180554674723
[batch 3] cost: 0.4906615 training pearson: 0.682482604922541
[batch 4] cost: 0.7885696 training pearson: 0.6656462221648478
[batch 5] cost: 1.1399692 training pearson: 0.7433469323282551
[batch 6] cost: 1.1411273 training pearson: 0.8194393794613987
[batch 7] cost: 0.7657906 training pearson: 0.7604479037413796
[batch 8] cost: 0.7840982 training pearson: 0.6517747778554069
[batch 9] cost: 1.1601902 training pearson: 0.830181520518494
[batch 10] cost: 1.003078 training pearson: 0.5768279919021139
[batch 11] cost: 1.0331541 training pearson: 0.7592804229676833
[batch 12] cost: 0.7108298 training pearson: 0.7898484432342733
[batch 13] cost: 0.8467476 training pearson: 0.8086083504964314
[batch 14] cost: 1.1617591 training pearson: 0.7933005527628433
[batch 15] cost: 0.9140665 training pearson: 0.7105167004238808
epoch:  111 pearson: test_pearson:  0.7182216000715562
============gbrt============
epoch:  111 pearson: ml_test_pearson:  0.6790930697006473
============xgb============
epoch:  111 pearson: ml_test_pearson:  0.6897495876340789
============rfr============
epoch:  111 pearson: ml_test_pearson:  0.6697874080688314
===============模型average结果==================
epoch:  111 pearson: ml_test_pearson:  0.6916721299608589
[Epoch 112]
[batch 1] cost: 0.66008246 training pearson: 0.8233764471139509
[batch 2] cost: 0.9126436 training pearson: 0.8049316055421428
[batch 3] cost: 0.86436373 training pearson: 0.7387982799087333
[batch 4] cost: 0.47554803 training pearson: 0.7408593180039136
[batch 5] cost: 1.0863101 training pearson: 0.7271017671795713
[batch 6] cost: 0.92184526 training pearson: 0.8302329966156795
[batch 7] cost: 0.6743048 training pearson: 0.7384898268965242
[batch 8] cost: 0.96446526 training pearson: 0.6630721534010283
[batch 9] cost: 0.5251514 training pearson: 0.8132846476582095
[batch 10] cost: 1.0120397 training pearson: 0.7375695299582601
[batch 11] cost: 1.0081327 training pearson: 0.805020709082328
[batch 12] cost: 1.5865219 training pearson: 0.6895576417865762
[batch 13] cost: 0.88866043 training pearson: 0.6952547438690637
[batch 14] cost: 0.86984175 training pearson: 0.6897623937602214
[batch 15] cost: 1.244981 training pearson: 0.814317263788173
epoch:  112 pearson: test_pearson:  0.7182194461465953
============gbrt============
epoch:  112 pearson: ml_test_pearson:  0.687090045372432
============xgb============
epoch:  112 pearson: ml_test_pearson:  0.6920342437505888
============rfr============
epoch:  112 pearson: ml_test_pearson:  0.6793753374356553
===============模型average结果==================
epoch:  112 pearson: ml_test_pearson:  0.6992448375811936
[Epoch 113]
[batch 1] cost: 0.9592331 training pearson: 0.7726745321848135
[batch 2] cost: 1.0638766 training pearson: 0.8111711371975725
[batch 3] cost: 1.0125915 training pearson: 0.7906803715424817
[batch 4] cost: 1.0339051 training pearson: 0.5186866570532995
[batch 5] cost: 0.66064364 training pearson: 0.7475797035521425
[batch 6] cost: 0.9345981 training pearson: 0.7862482284533809
[batch 7] cost: 1.0214937 training pearson: 0.8157421793564329
[batch 8] cost: 1.0702488 training pearson: 0.7827318255187371
[batch 9] cost: 1.2193238 training pearson: 0.7123660818799704
[batch 10] cost: 0.8108697 training pearson: 0.6333661540337926
[batch 11] cost: 0.6280744 training pearson: 0.7480123253409943
[batch 12] cost: 0.73704886 training pearson: 0.7034126645973493
[batch 13] cost: 0.96153915 training pearson: 0.7325621962878296
[batch 14] cost: 0.6672938 training pearson: 0.7334045603946799
[batch 15] cost: 0.90204954 training pearson: 0.8309807376460006
epoch:  113 pearson: test_pearson:  0.7182180497996979
============gbrt============
epoch:  113 pearson: ml_test_pearson:  0.6908754092043926
============xgb============
epoch:  113 pearson: ml_test_pearson:  0.6941024492042831
============rfr============
epoch:  113 pearson: ml_test_pearson:  0.6699870888843515
===============模型average结果==================
epoch:  113 pearson: ml_test_pearson:  0.6994528479567658
[Epoch 114]
[batch 1] cost: 0.9183074 training pearson: 0.7602688730619721
[batch 2] cost: 1.1084468 training pearson: 0.7647747785662292
[batch 3] cost: 0.8891887 training pearson: 0.8018536021419262
[batch 4] cost: 0.9152289 training pearson: 0.6179273005462288
[batch 5] cost: 0.7361452 training pearson: 0.7410437612513522
[batch 6] cost: 0.8266447 training pearson: 0.7982068992368977
[batch 7] cost: 1.0421715 training pearson: 0.8415867711652235
[batch 8] cost: 1.507041 training pearson: 0.8136260685090978
[batch 9] cost: 0.6632189 training pearson: 0.6834584760093763
[batch 10] cost: 0.69617045 training pearson: 0.8037564169820457
[batch 11] cost: 0.89165694 training pearson: 0.6759182715659464
[batch 12] cost: 0.9924747 training pearson: 0.6506583458883067
[batch 13] cost: 0.63916075 training pearson: 0.6651719760975572
[batch 14] cost: 0.8507893 training pearson: 0.794874172056651
[batch 15] cost: 0.89542925 training pearson: 0.6691645394965914
epoch:  114 pearson: test_pearson:  0.7182110398553674
============gbrt============
epoch:  114 pearson: ml_test_pearson:  0.6868108390252894
============xgb============
epoch:  114 pearson: ml_test_pearson:  0.693610392089125
============rfr============
epoch:  114 pearson: ml_test_pearson:  0.6699548643078973
===============模型average结果==================
epoch:  114 pearson: ml_test_pearson:  0.6976580690221511
[Epoch 115]
[batch 1] cost: 1.070324 training pearson: 0.8186545177235853
[batch 2] cost: 1.0965943 training pearson: 0.7488113865216831
[batch 3] cost: 0.79535264 training pearson: 0.6764679865721344
[batch 4] cost: 0.89095336 training pearson: 0.7434491443579405
[batch 5] cost: 0.7929927 training pearson: 0.8713619379120596
[batch 6] cost: 0.7990067 training pearson: 0.8185975878835591
[batch 7] cost: 1.2578909 training pearson: 0.6993335354206514
[batch 8] cost: 0.8905075 training pearson: 0.7631498289042843
[batch 9] cost: 0.9511337 training pearson: 0.7086551785367936
[batch 10] cost: 0.47789314 training pearson: 0.7634747194919473
[batch 11] cost: 0.7959398 training pearson: 0.5165206920630384
[batch 12] cost: 1.0802972 training pearson: 0.7802367100812614
[batch 13] cost: 1.0316532 training pearson: 0.7843414748899528
[batch 14] cost: 0.8378928 training pearson: 0.7924365719860561
[batch 15] cost: 0.74035937 training pearson: 0.7664141800745651
epoch:  115 pearson: test_pearson:  0.7182144398602243
============gbrt============
epoch:  115 pearson: ml_test_pearson:  0.6838993924704008
============xgb============
epoch:  115 pearson: ml_test_pearson:  0.6929143140013241
============rfr============
epoch:  115 pearson: ml_test_pearson:  0.6710956104144906
===============模型average结果==================
epoch:  115 pearson: ml_test_pearson:  0.6958932102746418
[Epoch 116]
[batch 1] cost: 0.57619095 training pearson: 0.7608607053447023
[batch 2] cost: 0.7489562 training pearson: 0.6508218056424345
[batch 3] cost: 1.5917685 training pearson: 0.7200003424466501
[batch 4] cost: 0.8325636 training pearson: 0.6883173633214313
[batch 5] cost: 0.6464574 training pearson: 0.7818446839196563
[batch 6] cost: 0.96130264 training pearson: 0.6878854752006167
[batch 7] cost: 0.7932016 training pearson: 0.6986952708856295
[batch 8] cost: 0.88374496 training pearson: 0.7854212619930707
[batch 9] cost: 0.99438006 training pearson: 0.779813967844292
[batch 10] cost: 1.1319497 training pearson: 0.7388785593407243
[batch 11] cost: 1.0588429 training pearson: 0.852679393008862
[batch 12] cost: 0.7043986 training pearson: 0.7536936121864568
[batch 13] cost: 0.76667106 training pearson: 0.7819073903269338
[batch 14] cost: 1.1246518 training pearson: 0.8171145099232705
[batch 15] cost: 0.6058343 training pearson: 0.7366702038148781
epoch:  116 pearson: test_pearson:  0.7182170220322329
============gbrt============
epoch:  116 pearson: ml_test_pearson:  0.6858290578184731
============xgb============
epoch:  116 pearson: ml_test_pearson:  0.6867057111212723
============rfr============
epoch:  116 pearson: ml_test_pearson:  0.6840572215393969
===============模型average结果==================
epoch:  116 pearson: ml_test_pearson:  0.7006826012340462
[Epoch 117]
[batch 1] cost: 0.5656625 training pearson: 0.7038530504080938
[batch 2] cost: 1.145431 training pearson: 0.7403376732628588
[batch 3] cost: 0.7027614 training pearson: 0.8342044559135958
[batch 4] cost: 0.84117126 training pearson: 0.6869101971103937
[batch 5] cost: 0.36294067 training pearson: 0.5186470849293549
[batch 6] cost: 1.0522326 training pearson: 0.7702582296954265
[batch 7] cost: 0.9842868 training pearson: 0.7810469692192614
[batch 8] cost: 0.77280444 training pearson: 0.7437146919414236
[batch 9] cost: 0.9071326 training pearson: 0.5355669162440979
[batch 10] cost: 1.2150258 training pearson: 0.7763211559226361
[batch 11] cost: 1.2585126 training pearson: 0.7389059050908522
[batch 12] cost: 0.952476 training pearson: 0.78973964286206
[batch 13] cost: 0.6087361 training pearson: 0.7641383049312932
[batch 14] cost: 0.8331242 training pearson: 0.849128029003181
[batch 15] cost: 1.1574371 training pearson: 0.8233484945187661
epoch:  117 pearson: test_pearson:  0.7182189699269449
============gbrt============
epoch:  117 pearson: ml_test_pearson:  0.6897512459054199
============xgb============
epoch:  117 pearson: ml_test_pearson:  0.6857343594281508
============rfr============
epoch:  117 pearson: ml_test_pearson:  0.6699688221954093
===============模型average结果==================
epoch:  117 pearson: ml_test_pearson:  0.6970451303710954
[Epoch 118]
[batch 1] cost: 0.8488985 training pearson: 0.7321380324678755
[batch 2] cost: 0.8723455 training pearson: 0.8174491186230531
[batch 3] cost: 1.2541133 training pearson: 0.8175996479130502
[batch 4] cost: 1.0955858 training pearson: 0.7096638550168947
[batch 5] cost: 0.5736637 training pearson: 0.7490939648749759
[batch 6] cost: 0.87908745 training pearson: 0.6573417788668471
[batch 7] cost: 0.77571356 training pearson: 0.6483748447368453
[batch 8] cost: 0.9591864 training pearson: 0.6961049851640788
[batch 9] cost: 0.76384735 training pearson: 0.6876295394315646
[batch 10] cost: 0.8402977 training pearson: 0.7939309488915647
[batch 11] cost: 0.861014 training pearson: 0.7875560729081
[batch 12] cost: 0.6903832 training pearson: 0.7686875692132111
[batch 13] cost: 0.95291275 training pearson: 0.7935703823292721
[batch 14] cost: 0.578156 training pearson: 0.7260120719037737
[batch 15] cost: 1.3487407 training pearson: 0.7663438746081609
epoch:  118 pearson: test_pearson:  0.7182205206152454
============gbrt============
epoch:  118 pearson: ml_test_pearson:  0.6840357438788658
============xgb============
epoch:  118 pearson: ml_test_pearson:  0.6969088627448332
============rfr============
epoch:  118 pearson: ml_test_pearson:  0.6763570225898843
===============模型average结果==================
epoch:  118 pearson: ml_test_pearson:  0.7001251810318814
[Epoch 119]
[batch 1] cost: 0.84931535 training pearson: 0.8151636129364833
[batch 2] cost: 0.9380365 training pearson: 0.8026858971187472
[batch 3] cost: 0.76324785 training pearson: 0.7725570372860445
[batch 4] cost: 0.79523957 training pearson: 0.6114896507109709
[batch 5] cost: 0.7188239 training pearson: 0.5700389376833782
[batch 6] cost: 1.0238081 training pearson: 0.8184286250717244
[batch 7] cost: 0.8279587 training pearson: 0.7724193221784437
[batch 8] cost: 1.0017112 training pearson: 0.7868817667459799
[batch 9] cost: 1.0837543 training pearson: 0.7536964335989501
[batch 10] cost: 0.9665886 training pearson: 0.7977071829228385
[batch 11] cost: 0.6145287 training pearson: 0.5819934547872534
[batch 12] cost: 0.6172529 training pearson: 0.6475592719391176
[batch 13] cost: 0.80483866 training pearson: 0.7222749861785811
[batch 14] cost: 1.209911 training pearson: 0.7795915156300991
[batch 15] cost: 1.0588058 training pearson: 0.8000419101538095
epoch:  119 pearson: test_pearson:  0.7182189237799879
============gbrt============
epoch:  119 pearson: ml_test_pearson:  0.6883665129261672
============xgb============
epoch:  119 pearson: ml_test_pearson:  0.6949118710331224
============rfr============
epoch:  119 pearson: ml_test_pearson:  0.6856696005968806
===============模型average结果==================
epoch:  119 pearson: ml_test_pearson:  0.7063450636508615
[Epoch 120]
[batch 1] cost: 0.962449 training pearson: 0.6843448253922001
[batch 2] cost: 0.6408371 training pearson: 0.6768052457268414
[batch 3] cost: 1.0008063 training pearson: 0.6384003598727872
[batch 4] cost: 0.7561836 training pearson: 0.802655670240981
[batch 5] cost: 0.7538643 training pearson: 0.7467433186752943
[batch 6] cost: 0.754767 training pearson: 0.8112481368431204
[batch 7] cost: 0.7436485 training pearson: 0.7672060456183728
[batch 8] cost: 0.6781235 training pearson: 0.8253325419518381
[batch 9] cost: 1.0485379 training pearson: 0.8278811778939386
[batch 10] cost: 1.1701417 training pearson: 0.6336067248023757
[batch 11] cost: 0.9370442 training pearson: 0.7785180968597829
[batch 12] cost: 0.6722237 training pearson: 0.7101783257655992
[batch 13] cost: 0.9195576 training pearson: 0.7232148354381286
[batch 14] cost: 1.1234944 training pearson: 0.7831732700666914
[batch 15] cost: 0.9993898 training pearson: 0.7817013416634921
epoch:  120 pearson: test_pearson:  0.7182165324597156
============gbrt============
epoch:  120 pearson: ml_test_pearson:  0.6830963812731462
============xgb============
epoch:  120 pearson: ml_test_pearson:  0.6971139275180038
============rfr============
epoch:  120 pearson: ml_test_pearson:  0.6789079418457643
===============模型average结果==================
epoch:  120 pearson: ml_test_pearson:  0.7037563753686178
[Epoch 121]
[batch 1] cost: 1.004637 training pearson: 0.8072589036352174
[batch 2] cost: 1.04427 training pearson: 0.6880411810247556
[batch 3] cost: 1.2439691 training pearson: 0.7604782569180951
[batch 4] cost: 0.85246134 training pearson: 0.6848979299388732
[batch 5] cost: 0.83794457 training pearson: 0.752660231381092
[batch 6] cost: 1.1098112 training pearson: 0.7176052846184579
[batch 7] cost: 0.9593189 training pearson: 0.7671566340716612
[batch 8] cost: 0.7049811 training pearson: 0.6799142204209003
[batch 9] cost: 0.902023 training pearson: 0.7002849401868954
[batch 10] cost: 0.8420949 training pearson: 0.7359727188295794
[batch 11] cost: 0.70828736 training pearson: 0.8281091067569927
[batch 12] cost: 0.62118345 training pearson: 0.7646203253662955
[batch 13] cost: 0.7264461 training pearson: 0.7732614658578696
[batch 14] cost: 1.1085579 training pearson: 0.8285565673170125
[batch 15] cost: 0.478259 training pearson: 0.7073617089104266
epoch:  121 pearson: test_pearson:  0.7182219963900116
============gbrt============
epoch:  121 pearson: ml_test_pearson:  0.677268535742159
============xgb============
epoch:  121 pearson: ml_test_pearson:  0.6805154937590946
============rfr============
epoch:  121 pearson: ml_test_pearson:  0.6763756879106164
===============模型average结果==================
epoch:  121 pearson: ml_test_pearson:  0.6963722136810272
[Epoch 122]
[batch 1] cost: 0.66498613 training pearson: 0.8287017764364095
[batch 2] cost: 0.84571755 training pearson: 0.6227343272158897
[batch 3] cost: 0.6743151 training pearson: 0.8402680972079922
[batch 4] cost: 0.9564531 training pearson: 0.8612723919270786
[batch 5] cost: 0.8062542 training pearson: 0.8035643762823967
[batch 6] cost: 1.1093265 training pearson: 0.5460996074054452
[batch 7] cost: 1.0037675 training pearson: 0.6618873223915871
[batch 8] cost: 0.65097845 training pearson: 0.6696507562586763
[batch 9] cost: 0.6110824 training pearson: 0.7621616382158295
[batch 10] cost: 0.7877886 training pearson: 0.6878066913596252
[batch 11] cost: 0.6770304 training pearson: 0.7110563626451618
[batch 12] cost: 0.946291 training pearson: 0.748223152326713
[batch 13] cost: 1.2424887 training pearson: 0.8216374868159403
[batch 14] cost: 1.0922967 training pearson: 0.7067517276757276
[batch 15] cost: 1.0022757 training pearson: 0.7574610051954256
epoch:  122 pearson: test_pearson:  0.7182167735156022
============gbrt============
epoch:  122 pearson: ml_test_pearson:  0.6842203170286374
============xgb============
epoch:  122 pearson: ml_test_pearson:  0.6890329928383166
============rfr============
epoch:  122 pearson: ml_test_pearson:  0.6620433730175114
===============模型average结果==================
epoch:  122 pearson: ml_test_pearson:  0.6936765760289539
[Epoch 123]
[batch 1] cost: 0.7169705 training pearson: 0.7739022398501826
[batch 2] cost: 0.8403974 training pearson: 0.7474313617315025
[batch 3] cost: 0.97111726 training pearson: 0.7775423084976842
[batch 4] cost: 0.8600951 training pearson: 0.7576743674685696
[batch 5] cost: 1.0160995 training pearson: 0.7884940840178162
[batch 6] cost: 0.7730539 training pearson: 0.7378890030336146
[batch 7] cost: 0.7463873 training pearson: 0.7529085019287548
[batch 8] cost: 0.80200577 training pearson: 0.7221939953691866
[batch 9] cost: 0.7989633 training pearson: 0.5636351655040295
[batch 10] cost: 0.90628517 training pearson: 0.7674116353001365
[batch 11] cost: 1.2577951 training pearson: 0.8517615997218206
[batch 12] cost: 0.7937048 training pearson: 0.8087360278805323
[batch 13] cost: 0.9516638 training pearson: 0.6146903186395802
[batch 14] cost: 0.9269783 training pearson: 0.797743237699993
[batch 15] cost: 0.73844224 training pearson: 0.7525987066533437
epoch:  123 pearson: test_pearson:  0.7182269713009974
============gbrt============
epoch:  123 pearson: ml_test_pearson:  0.6733947388268529
============xgb============
epoch:  123 pearson: ml_test_pearson:  0.6894280443470414
============rfr============
epoch:  123 pearson: ml_test_pearson:  0.6820792438140191
===============模型average结果==================
epoch:  123 pearson: ml_test_pearson:  0.6992937205185462
[Epoch 124]
[batch 1] cost: 0.54624534 training pearson: 0.7573548825931847
[batch 2] cost: 1.1382893 training pearson: 0.8126653792282822
[batch 3] cost: 0.9219827 training pearson: 0.7928934620506001
[batch 4] cost: 0.8514374 training pearson: 0.7973505169331134
[batch 5] cost: 0.64247406 training pearson: 0.6800336107020559
[batch 6] cost: 0.44468075 training pearson: 0.7369446771254492
[batch 7] cost: 1.1071912 training pearson: 0.5882541740277201
[batch 8] cost: 1.0958921 training pearson: 0.8482437972533902
[batch 9] cost: 0.9593702 training pearson: 0.7538779367356924
[batch 10] cost: 0.9823788 training pearson: 0.8179402649577165
[batch 11] cost: 0.7161659 training pearson: 0.7303852208672333
[batch 12] cost: 0.790239 training pearson: 0.6749456641560151
[batch 13] cost: 0.69936484 training pearson: 0.4790973594198389
[batch 14] cost: 1.1886078 training pearson: 0.7245352445949919
[batch 15] cost: 0.8865875 training pearson: 0.7913083749967197
epoch:  124 pearson: test_pearson:  0.7182255836188411
============gbrt============
epoch:  124 pearson: ml_test_pearson:  0.6832494609915934
============xgb============
epoch:  124 pearson: ml_test_pearson:  0.6938320827090203
============rfr============
epoch:  124 pearson: ml_test_pearson:  0.6670268312407184
===============模型average结果==================
epoch:  124 pearson: ml_test_pearson:  0.699688156983605
[Epoch 125]
[batch 1] cost: 0.6612219 training pearson: 0.7315474818962441
[batch 2] cost: 0.8921416 training pearson: 0.7346421474691344
[batch 3] cost: 1.1324394 training pearson: 0.7481446250357237
[batch 4] cost: 0.7172917 training pearson: 0.8159120232887012
[batch 5] cost: 1.037548 training pearson: 0.6520402101299275
[batch 6] cost: 0.64978707 training pearson: 0.8312670588358703
[batch 7] cost: 0.86612535 training pearson: 0.7593401637516147
[batch 8] cost: 0.7261573 training pearson: 0.7410852432403664
[batch 9] cost: 1.0558516 training pearson: 0.6975120073789934
[batch 10] cost: 0.7866214 training pearson: 0.7942279604099275
[batch 11] cost: 0.7285938 training pearson: 0.7506392446457686
[batch 12] cost: 0.9406795 training pearson: 0.5743756179909019
[batch 13] cost: 1.1941446 training pearson: 0.7651514985545814
[batch 14] cost: 0.90304613 training pearson: 0.8101523281971481
[batch 15] cost: 0.6233231 training pearson: 0.80863729188751
epoch:  125 pearson: test_pearson:  0.718253277375235
============gbrt============
epoch:  125 pearson: ml_test_pearson:  0.6825881138846138
============xgb============
epoch:  125 pearson: ml_test_pearson:  0.6934393176539844
============rfr============
epoch:  125 pearson: ml_test_pearson:  0.6529819096492183
===============模型average结果==================
epoch:  125 pearson: ml_test_pearson:  0.6935166422914976
[Epoch 126]
[batch 1] cost: 0.5692741 training pearson: 0.6609485837239392
[batch 2] cost: 0.99134386 training pearson: 0.7704564221533857
[batch 3] cost: 0.75458354 training pearson: 0.7180384305007725
[batch 4] cost: 0.89325845 training pearson: 0.7624012690461779
[batch 5] cost: 1.1553049 training pearson: 0.8544444488377821
[batch 6] cost: 0.9849054 training pearson: 0.7189140187441598
[batch 7] cost: 0.868819 training pearson: 0.7663469210039523
[batch 8] cost: 0.89929795 training pearson: 0.7572087446021588
[batch 9] cost: 0.5732307 training pearson: 0.6895924358383619
[batch 10] cost: 1.0999227 training pearson: 0.7024404846806138
[batch 11] cost: 0.8744625 training pearson: 0.7860438451195149
[batch 12] cost: 0.71495456 training pearson: 0.7604731328695951
[batch 13] cost: 0.69113886 training pearson: 0.6421612444306354
[batch 14] cost: 0.93745637 training pearson: 0.7564969064067184
[batch 15] cost: 0.89063317 training pearson: 0.7776163282840344
epoch:  126 pearson: test_pearson:  0.7182977702951299
============gbrt============
epoch:  126 pearson: ml_test_pearson:  0.6782553936316054
============xgb============
epoch:  126 pearson: ml_test_pearson:  0.692159978438902
============rfr============
epoch:  126 pearson: ml_test_pearson:  0.6533537268644226
===============模型average结果==================
epoch:  126 pearson: ml_test_pearson:  0.6918451960731925
[Epoch 127]
[batch 1] cost: 0.7497011 training pearson: 0.7547696800930379
[batch 2] cost: 0.851272 training pearson: 0.7779100009310552
[batch 3] cost: 0.4321913 training pearson: 0.6799990680716191
[batch 4] cost: 0.9906069 training pearson: 0.7837966804109029
[batch 5] cost: 0.74195296 training pearson: 0.7370264718953903
[batch 6] cost: 1.0954269 training pearson: 0.8234005754675426
[batch 7] cost: 0.6321201 training pearson: 0.5919099776718273
[batch 8] cost: 0.75196403 training pearson: 0.5988978943380492
[batch 9] cost: 1.1366767 training pearson: 0.7042841671615467
[batch 10] cost: 0.7967933 training pearson: 0.7184927634803995
[batch 11] cost: 1.1278965 training pearson: 0.7087742038782696
[batch 12] cost: 0.891573 training pearson: 0.7808552970608273
[batch 13] cost: 0.81109345 training pearson: 0.8623957316566215
[batch 14] cost: 1.1845721 training pearson: 0.8074421994956414
[batch 15] cost: 0.5878986 training pearson: 0.6795929079234642
epoch:  127 pearson: test_pearson:  0.7183063719362038
============gbrt============
epoch:  127 pearson: ml_test_pearson:  0.6828643112620243
============xgb============
epoch:  127 pearson: ml_test_pearson:  0.6952428991425609
============rfr============
epoch:  127 pearson: ml_test_pearson:  0.6596306097498398
===============模型average结果==================
epoch:  127 pearson: ml_test_pearson:  0.6960429127179625
[Epoch 128]
[batch 1] cost: 0.7371681 training pearson: 0.8082553550092878
[batch 2] cost: 0.7886189 training pearson: 0.7938044188338684
[batch 3] cost: 0.70988446 training pearson: 0.7722252582885151
[batch 4] cost: 0.34497097 training pearson: 0.5518931214800326
[batch 5] cost: 0.7444284 training pearson: 0.806960378282404
[batch 6] cost: 0.46938825 training pearson: 0.664109920729643
[batch 7] cost: 1.0627735 training pearson: 0.6437070025657378
[batch 8] cost: 1.0705632 training pearson: 0.8006944748363967
[batch 9] cost: 0.98170424 training pearson: 0.63308451139424
[batch 10] cost: 0.9803726 training pearson: 0.7482740611013157
[batch 11] cost: 1.0954267 training pearson: 0.6600210060793663
[batch 12] cost: 1.0130658 training pearson: 0.8013042198170675
[batch 13] cost: 1.2598376 training pearson: 0.766706204635583
[batch 14] cost: 0.88527143 training pearson: 0.8112829024149001
[batch 15] cost: 0.6436249 training pearson: 0.7715905226952833
epoch:  128 pearson: test_pearson:  0.7183106386962892
============gbrt============
epoch:  128 pearson: ml_test_pearson:  0.6947819384873304
============xgb============
epoch:  128 pearson: ml_test_pearson:  0.7038322315303857
============rfr============
epoch:  128 pearson: ml_test_pearson:  0.6654622695676699
===============模型average结果==================
epoch:  128 pearson: ml_test_pearson:  0.7018117956600484
[Epoch 129]
[batch 1] cost: 1.0628135 training pearson: 0.7090433610413862
[batch 2] cost: 1.0529641 training pearson: 0.7297116740717177
[batch 3] cost: 0.489478 training pearson: 0.683578461529644
[batch 4] cost: 0.8473908 training pearson: 0.6628935867779244
[batch 5] cost: 0.6915734 training pearson: 0.574619772587762
[batch 6] cost: 0.58228374 training pearson: 0.6683089336329645
[batch 7] cost: 0.705174 training pearson: 0.8385700260424586
[batch 8] cost: 0.8696275 training pearson: 0.7381772403321024
[batch 9] cost: 0.7814732 training pearson: 0.7017208203733931
[batch 10] cost: 0.5738126 training pearson: 0.722318527965565
[batch 11] cost: 1.0208017 training pearson: 0.8074945021820648
[batch 12] cost: 0.82601047 training pearson: 0.8551241540853158
[batch 13] cost: 1.2903003 training pearson: 0.7498191613115944
[batch 14] cost: 1.0410049 training pearson: 0.6922851009865045
[batch 15] cost: 0.90994585 training pearson: 0.8913881278181005
epoch:  129 pearson: test_pearson:  0.7183269022138701
============gbrt============
epoch:  129 pearson: ml_test_pearson:  0.6854005624639764
============xgb============
epoch:  129 pearson: ml_test_pearson:  0.6917271954399347
============rfr============
epoch:  129 pearson: ml_test_pearson:  0.642305900102348
===============模型average结果==================
epoch:  129 pearson: ml_test_pearson:  0.6880846634177669
[Epoch 130]
[batch 1] cost: 0.7758035 training pearson: 0.6330625199931155
[batch 2] cost: 1.2498502 training pearson: 0.735764735343013
[batch 3] cost: 0.86521894 training pearson: 0.8393244574360665
[batch 4] cost: 0.9719437 training pearson: 0.671915782912757
[batch 5] cost: 0.6434845 training pearson: 0.7232353845152043
[batch 6] cost: 0.98964363 training pearson: 0.8427937205150073
[batch 7] cost: 0.45373657 training pearson: 0.7259359663525098
[batch 8] cost: 0.76970565 training pearson: 0.7563791739711613
[batch 9] cost: 0.9969681 training pearson: 0.6823579018540306
[batch 10] cost: 0.82563514 training pearson: 0.7528432981498776
[batch 11] cost: 0.5767291 training pearson: 0.7830502079498382
[batch 12] cost: 1.2473103 training pearson: 0.807328629867697
[batch 13] cost: 0.56323904 training pearson: 0.8328045142121837
[batch 14] cost: 0.949137 training pearson: 0.6602623198485649
[batch 15] cost: 0.76046157 training pearson: 0.7252128876155246
epoch:  130 pearson: test_pearson:  0.7183471137518043
============gbrt============
epoch:  130 pearson: ml_test_pearson:  0.6924283526725881
============xgb============
epoch:  130 pearson: ml_test_pearson:  0.6980040997824453
============rfr============
epoch:  130 pearson: ml_test_pearson:  0.6822931172442298
===============模型average结果==================
epoch:  130 pearson: ml_test_pearson:  0.7061921468042017
[Epoch 131]
[batch 1] cost: 1.1331929 training pearson: 0.6206474257541816
[batch 2] cost: 0.8815889 training pearson: 0.7549447104108487
[batch 3] cost: 0.8756291 training pearson: 0.7952893238503314
[batch 4] cost: 0.8423938 training pearson: 0.7536144223350892
[batch 5] cost: 1.1233132 training pearson: 0.7446359326506506
[batch 6] cost: 0.60704345 training pearson: 0.7702501129695773
[batch 7] cost: 0.8060193 training pearson: 0.5295358347000689
[batch 8] cost: 0.53123885 training pearson: 0.6614310702031438
[batch 9] cost: 1.0195318 training pearson: 0.8054145595063249
[batch 10] cost: 1.1676549 training pearson: 0.7541737422247334
[batch 11] cost: 0.7337611 training pearson: 0.8335356540103755
[batch 12] cost: 0.52939874 training pearson: 0.7676649324878011
[batch 13] cost: 0.94480497 training pearson: 0.7579048891037361
[batch 14] cost: 0.57882524 training pearson: 0.5778639821980284
[batch 15] cost: 0.80985796 training pearson: 0.8775472146899046
epoch:  131 pearson: test_pearson:  0.7183614110917159
============gbrt============
epoch:  131 pearson: ml_test_pearson:  0.6943300714322345
============xgb============
epoch:  131 pearson: ml_test_pearson:  0.7009188002064695
============rfr============
epoch:  131 pearson: ml_test_pearson:  0.6707170534808852
===============模型average结果==================
epoch:  131 pearson: ml_test_pearson:  0.7042824648475955
[Epoch 132]
[batch 1] cost: 0.8787689 training pearson: 0.7615102520496071
[batch 2] cost: 0.8817801 training pearson: 0.7760328784433312
[batch 3] cost: 0.516724 training pearson: 0.41145259694297376
[batch 4] cost: 0.62174445 training pearson: 0.6885811446585475
[batch 5] cost: 1.066369 training pearson: 0.7669204835174165
[batch 6] cost: 1.0039686 training pearson: 0.8065868301681985
[batch 7] cost: 0.76676786 training pearson: 0.8106222702763569
[batch 8] cost: 1.0292569 training pearson: 0.6364983778949593
[batch 9] cost: 0.5221141 training pearson: 0.6662237265657448
[batch 10] cost: 0.7066296 training pearson: 0.7535968054372745
[batch 11] cost: 0.86385745 training pearson: 0.7200392683913099
[batch 12] cost: 1.1439176 training pearson: 0.8011737638308101
[batch 13] cost: 0.8437953 training pearson: 0.8383590489484426
[batch 14] cost: 0.91745543 training pearson: 0.7356648749159447
[batch 15] cost: 0.77144533 training pearson: 0.8105118732342989
epoch:  132 pearson: test_pearson:  0.7183674081862513
============gbrt============
epoch:  132 pearson: ml_test_pearson:  0.6892559944046585
============xgb============
epoch:  132 pearson: ml_test_pearson:  0.6977164474218474
============rfr============
epoch:  132 pearson: ml_test_pearson:  0.6759487055412657
===============模型average结果==================
epoch:  132 pearson: ml_test_pearson:  0.7040355940431807
[Epoch 133]
[batch 1] cost: 0.6359147 training pearson: 0.6884160876447811
[batch 2] cost: 0.60348326 training pearson: 0.7753091225794261
[batch 3] cost: 1.0452075 training pearson: 0.8379874136209232
[batch 4] cost: 0.7749707 training pearson: 0.6581348103305441
[batch 5] cost: 1.0682452 training pearson: 0.8557517504902391
[batch 6] cost: 0.8186253 training pearson: 0.6684179029895926
[batch 7] cost: 1.1944257 training pearson: 0.7745650477659265
[batch 8] cost: 1.080287 training pearson: 0.7463909566923685
[batch 9] cost: 0.6633356 training pearson: 0.6908310412932783
[batch 10] cost: 0.5849396 training pearson: 0.7303511445143737
[batch 11] cost: 0.49923852 training pearson: 0.7316552948873541
[batch 12] cost: 1.126399 training pearson: 0.7554751515967159
[batch 13] cost: 0.80868536 training pearson: 0.7033847764828374
[batch 14] cost: 0.66720116 training pearson: 0.7201379031434335
[batch 15] cost: 0.9187469 training pearson: 0.767692056723748
epoch:  133 pearson: test_pearson:  0.7183871913109677
============gbrt============
epoch:  133 pearson: ml_test_pearson:  0.6823901641521248
============xgb============
epoch:  133 pearson: ml_test_pearson:  0.698112301863193
============rfr============
epoch:  133 pearson: ml_test_pearson:  0.6865630186317719
===============模型average结果==================
epoch:  133 pearson: ml_test_pearson:  0.7076656593580166
[Epoch 134]
[batch 1] cost: 0.6795186 training pearson: 0.6144670708295689
[batch 2] cost: 0.96481246 training pearson: 0.744464959906978
[batch 3] cost: 0.85725814 training pearson: 0.6743840759366744
[batch 4] cost: 0.70426255 training pearson: 0.8395824269302589
[batch 5] cost: 0.8300136 training pearson: 0.7904928516578082
[batch 6] cost: 0.709505 training pearson: 0.829529256468155
[batch 7] cost: 0.7566839 training pearson: 0.7830412625513175
[batch 8] cost: 0.7528983 training pearson: 0.7217595781501129
[batch 9] cost: 1.0532104 training pearson: 0.802839375702906
[batch 10] cost: 0.71484154 training pearson: 0.6773803600352554
[batch 11] cost: 0.8710098 training pearson: 0.7771039761923315
[batch 12] cost: 0.68375933 training pearson: 0.7672601996051938
[batch 13] cost: 0.96744704 training pearson: 0.7163006310022882
[batch 14] cost: 1.2644005 training pearson: 0.6448686944894787
[batch 15] cost: 0.6121889 training pearson: 0.7835627404834022
epoch:  134 pearson: test_pearson:  0.7183972541925394
============gbrt============
epoch:  134 pearson: ml_test_pearson:  0.6841912027649958
============xgb============
epoch:  134 pearson: ml_test_pearson:  0.6980145543127653
============rfr============
epoch:  134 pearson: ml_test_pearson:  0.6768352540961702
===============模型average结果==================
epoch:  134 pearson: ml_test_pearson:  0.7084995190299586
[Epoch 135]
[batch 1] cost: 0.8720175 training pearson: 0.6649188288675643
[batch 2] cost: 0.8150522 training pearson: 0.6789594811567815
[batch 3] cost: 0.9367795 training pearson: 0.6051201841529851
[batch 4] cost: 0.7092432 training pearson: 0.7868678475479559
[batch 5] cost: 0.7522343 training pearson: 0.8336856816961564
[batch 6] cost: 0.8602783 training pearson: 0.7323156694872223
[batch 7] cost: 0.7479965 training pearson: 0.7217297341201414
[batch 8] cost: 0.75896424 training pearson: 0.7358836060612628
[batch 9] cost: 1.5597811 training pearson: 0.8093301832977324
[batch 10] cost: 0.9332584 training pearson: 0.7671798862251537
[batch 11] cost: 0.85901093 training pearson: 0.7360631498409332
[batch 12] cost: 0.8888334 training pearson: 0.8124297085795312
[batch 13] cost: 0.60935074 training pearson: 0.8027490747067033
[batch 14] cost: 0.494044 training pearson: 0.6611152926462736
[batch 15] cost: 0.61295927 training pearson: 0.8255941744456782
epoch:  135 pearson: test_pearson:  0.7184125156632557
============gbrt============
epoch:  135 pearson: ml_test_pearson:  0.6789301487939249
============xgb============
epoch:  135 pearson: ml_test_pearson:  0.6889061998779542
============rfr============
epoch:  135 pearson: ml_test_pearson:  0.661246395311601
===============模型average结果==================
epoch:  135 pearson: ml_test_pearson:  0.6956893707746344
[Epoch 136]
[batch 1] cost: 0.74672097 training pearson: 0.643820631024225
[batch 2] cost: 0.8850722 training pearson: 0.7243791840452954
[batch 3] cost: 0.8614456 training pearson: 0.6273223638149189
[batch 4] cost: 0.76001036 training pearson: 0.8207209942538916
[batch 5] cost: 0.9529868 training pearson: 0.495029338106519
[batch 6] cost: 0.67508453 training pearson: 0.7821666953685416
[batch 7] cost: 0.5251778 training pearson: 0.7277131578426227
[batch 8] cost: 1.0708231 training pearson: 0.6629497224905638
[batch 9] cost: 0.7562619 training pearson: 0.8147870620057218
[batch 10] cost: 0.4354651 training pearson: 0.5447062169941673
[batch 11] cost: 1.0259546 training pearson: 0.7146322999000242
[batch 12] cost: 0.78094405 training pearson: 0.7846376699960667
[batch 13] cost: 0.623845 training pearson: 0.7950347979502697
[batch 14] cost: 1.1440452 training pearson: 0.8536419267501608
[batch 15] cost: 1.1090375 training pearson: 0.8885213013195645
epoch:  136 pearson: test_pearson:  0.7184237052762942
============gbrt============
epoch:  136 pearson: ml_test_pearson:  0.6828414757207254
============xgb============
epoch:  136 pearson: ml_test_pearson:  0.6936221104316395
============rfr============
epoch:  136 pearson: ml_test_pearson:  0.6526510364354294
===============模型average结果==================
epoch:  136 pearson: ml_test_pearson:  0.6931080326898714
[Epoch 137]
[batch 1] cost: 1.0448804 training pearson: 0.7711201969087851
[batch 2] cost: 0.41772583 training pearson: 0.7741823912942842
[batch 3] cost: 0.8354693 training pearson: 0.7171233937887552
[batch 4] cost: 0.8121498 training pearson: 0.6656825195412427
[batch 5] cost: 0.48728412 training pearson: 0.7604777113918655
[batch 6] cost: 0.75604784 training pearson: 0.7753309259874548
[batch 7] cost: 1.065062 training pearson: 0.7458629629645772
[batch 8] cost: 0.80073076 training pearson: 0.7935425499417184
[batch 9] cost: 0.8318712 training pearson: 0.8292908368789152
[batch 10] cost: 0.7887648 training pearson: 0.7733114994083083
[batch 11] cost: 0.710018 training pearson: 0.6225316057835752
[batch 12] cost: 0.8582447 training pearson: 0.7423955817009309
[batch 13] cost: 0.863539 training pearson: 0.7529599900985618
[batch 14] cost: 0.9286512 training pearson: 0.775164871263543
[batch 15] cost: 1.0796088 training pearson: 0.6525937564518856
epoch:  137 pearson: test_pearson:  0.7184400609965167
============gbrt============
epoch:  137 pearson: ml_test_pearson:  0.6749953200391083
============xgb============
epoch:  137 pearson: ml_test_pearson:  0.6936168145273759
============rfr============
epoch:  137 pearson: ml_test_pearson:  0.6428318485219782
===============模型average结果==================
epoch:  137 pearson: ml_test_pearson:  0.6866347694110388
[Epoch 138]
[batch 1] cost: 0.6329427 training pearson: 0.6599897392837032
[batch 2] cost: 0.67657965 training pearson: 0.6842859348769439
[batch 3] cost: 0.8293092 training pearson: 0.7902389521635348
[batch 4] cost: 1.1295208 training pearson: 0.7787268925164486
[batch 5] cost: 0.99438477 training pearson: 0.6994423148203107
[batch 6] cost: 0.71600866 training pearson: 0.710704535934113
[batch 7] cost: 0.96679413 training pearson: 0.7544812638144057
[batch 8] cost: 1.0623709 training pearson: 0.7223957210897861
[batch 9] cost: 0.87893605 training pearson: 0.8624514828826273
[batch 10] cost: 0.6704031 training pearson: 0.6376148163118853
[batch 11] cost: 0.91106325 training pearson: 0.7182195501404722
[batch 12] cost: 1.0193487 training pearson: 0.8481561275396423
[batch 13] cost: 0.5525031 training pearson: 0.4895224184513944
[batch 14] cost: 0.6234607 training pearson: 0.7404841904864639
[batch 15] cost: 0.65717345 training pearson: 0.8410624619636088
epoch:  138 pearson: test_pearson:  0.7184722195129989
============gbrt============
epoch:  138 pearson: ml_test_pearson:  0.6789125389082113
============xgb============
epoch:  138 pearson: ml_test_pearson:  0.6960807737889161
============rfr============
epoch:  138 pearson: ml_test_pearson:  0.6768852592842145
===============模型average结果==================
epoch:  138 pearson: ml_test_pearson:  0.7004329415047801
[Epoch 139]
[batch 1] cost: 1.0916982 training pearson: 0.6853997692941084
[batch 2] cost: 0.4567815 training pearson: 0.7262097604157512
[batch 3] cost: 0.581707 training pearson: 0.5252806308939709
[batch 4] cost: 0.8871292 training pearson: 0.7931910689646223
[batch 5] cost: 0.72253096 training pearson: 0.852734986250687
[batch 6] cost: 0.87921613 training pearson: 0.7104245978739356
[batch 7] cost: 1.23185 training pearson: 0.7028279390846576
[batch 8] cost: 0.8101614 training pearson: 0.7850069605197625
[batch 9] cost: 0.839244 training pearson: 0.7937261045923154
[batch 10] cost: 1.0874581 training pearson: 0.8235785791326321
[batch 11] cost: 0.86503905 training pearson: 0.7766027548061686
[batch 12] cost: 0.78186804 training pearson: 0.8045043830970724
[batch 13] cost: 0.71705896 training pearson: 0.7670421310492298
[batch 14] cost: 0.5718413 training pearson: 0.529442219680215
[batch 15] cost: 0.7378584 training pearson: 0.8320973334253625
epoch:  139 pearson: test_pearson:  0.7184784785171006
============gbrt============
epoch:  139 pearson: ml_test_pearson:  0.678301425564506
============xgb============
epoch:  139 pearson: ml_test_pearson:  0.697439780431715
============rfr============
epoch:  139 pearson: ml_test_pearson:  0.6346614168228853
===============模型average结果==================
epoch:  139 pearson: ml_test_pearson:  0.6838545258952708
[Epoch 140]
[batch 1] cost: 0.8365372 training pearson: 0.828331282350663
[batch 2] cost: 0.8247913 training pearson: 0.6517596478302407
[batch 3] cost: 0.71557593 training pearson: 0.6782085893100351
[batch 4] cost: 0.7858212 training pearson: 0.7765160790100297
[batch 5] cost: 0.74011564 training pearson: 0.6817135952661255
[batch 6] cost: 0.9036693 training pearson: 0.8561536504361298
[batch 7] cost: 0.48411846 training pearson: 0.5083045376685535
[batch 8] cost: 0.7351701 training pearson: 0.7285364045106547
[batch 9] cost: 0.6097081 training pearson: 0.7764749156174321
[batch 10] cost: 0.8745213 training pearson: 0.7719925681174763
[batch 11] cost: 0.7169996 training pearson: 0.7512767190190232
[batch 12] cost: 0.942075 training pearson: 0.6837776905939287
[batch 13] cost: 1.1756285 training pearson: 0.8221845041066241
[batch 14] cost: 0.98976153 training pearson: 0.6480504518171002
[batch 15] cost: 0.85943276 training pearson: 0.8173904817044949
epoch:  140 pearson: test_pearson:  0.7184900681964316
============gbrt============
epoch:  140 pearson: ml_test_pearson:  0.679152908337543
============xgb============
epoch:  140 pearson: ml_test_pearson:  0.695772597513112
============rfr============
epoch:  140 pearson: ml_test_pearson:  0.6344769540677548
===============模型average结果==================
epoch:  140 pearson: ml_test_pearson:  0.6864182306125356
[Epoch 141]
[batch 1] cost: 1.1095974 training pearson: 0.6555844083802653
[batch 2] cost: 0.89465606 training pearson: 0.6990089328028036
[batch 3] cost: 0.7479886 training pearson: 0.7504287032932779
[batch 4] cost: 1.1244559 training pearson: 0.7975581665767119
[batch 5] cost: 0.6395643 training pearson: 0.2612219289851034
[batch 6] cost: 0.8187495 training pearson: 0.770541561247148
[batch 7] cost: 0.787914 training pearson: 0.8000563345222327
[batch 8] cost: 0.70754427 training pearson: 0.7734610202909242
[batch 9] cost: 0.6318604 training pearson: 0.7717925345075966
[batch 10] cost: 0.59601074 training pearson: 0.8109184317047067
[batch 11] cost: 0.7456189 training pearson: 0.8319545842406879
[batch 12] cost: 0.74528414 training pearson: 0.8163539523366087
[batch 13] cost: 0.8840477 training pearson: 0.8163037512797064
[batch 14] cost: 0.81849366 training pearson: 0.6922176584815042
[batch 15] cost: 0.84695494 training pearson: 0.7884595343340671
epoch:  141 pearson: test_pearson:  0.7185195865012143
============gbrt============
epoch:  141 pearson: ml_test_pearson:  0.6859722138580818
============xgb============
epoch:  141 pearson: ml_test_pearson:  0.6963166755793139
============rfr============
epoch:  141 pearson: ml_test_pearson:  0.6407598796621168
===============模型average结果==================
epoch:  141 pearson: ml_test_pearson:  0.692179625390215
[Epoch 142]
[batch 1] cost: 0.84264207 training pearson: 0.8576350895689325
[batch 2] cost: 1.1125249 training pearson: 0.6707134032677439
[batch 3] cost: 0.65393966 training pearson: 0.660258757329281
[batch 4] cost: 0.9653705 training pearson: 0.743494344750668
[batch 5] cost: 0.73715913 training pearson: 0.7241968852903498
[batch 6] cost: 0.7951748 training pearson: 0.8155831698939116
[batch 7] cost: 0.6779853 training pearson: 0.7715211605209124
[batch 8] cost: 1.0191946 training pearson: 0.7126349293046425
[batch 9] cost: 0.37069455 training pearson: 0.7219391583135919
[batch 10] cost: 0.70055044 training pearson: 0.6665612461062876
[batch 11] cost: 0.93654114 training pearson: 0.6718016042670817
[batch 12] cost: 0.73238 training pearson: 0.6255877682888068
[batch 13] cost: 0.64707094 training pearson: 0.6196618017174669
[batch 14] cost: 0.8346204 training pearson: 0.8769579296553907
[batch 15] cost: 1.0515463 training pearson: 0.8049566527176258
epoch:  142 pearson: test_pearson:  0.7185213330394612
============gbrt============
epoch:  142 pearson: ml_test_pearson:  0.6792551696347013
============xgb============
epoch:  142 pearson: ml_test_pearson:  0.701870256822329
============rfr============
epoch:  142 pearson: ml_test_pearson:  0.6422551518584986
===============模型average结果==================
epoch:  142 pearson: ml_test_pearson:  0.6864969171796572
[Epoch 143]
[batch 1] cost: 0.7010196 training pearson: 0.7965170228725083
[batch 2] cost: 0.7873627 training pearson: 0.7415628452595074
[batch 3] cost: 1.1374846 training pearson: 0.6843515361887847
[batch 4] cost: 0.83966047 training pearson: 0.7861872770533304
[batch 5] cost: 0.82349205 training pearson: 0.5339035357984668
[batch 6] cost: 0.87511826 training pearson: 0.8128491975978471
[batch 7] cost: 0.7718234 training pearson: 0.7892109928602856
[batch 8] cost: 0.76356936 training pearson: 0.5590346057562222
[batch 9] cost: 0.6593273 training pearson: 0.8134489760447474
[batch 10] cost: 0.70760274 training pearson: 0.7526235955560261
[batch 11] cost: 0.88616234 training pearson: 0.8267056957166481
[batch 12] cost: 0.7121294 training pearson: 0.7335402598666307
[batch 13] cost: 0.59536344 training pearson: 0.5858534565700654
[batch 14] cost: 0.740461 training pearson: 0.8198854505602822
[batch 15] cost: 1.0795338 training pearson: 0.7939341658902586
epoch:  143 pearson: test_pearson:  0.7185389561899429
============gbrt============
epoch:  143 pearson: ml_test_pearson:  0.6813782387629558
============xgb============
epoch:  143 pearson: ml_test_pearson:  0.6955514116646144
============rfr============
epoch:  143 pearson: ml_test_pearson:  0.6346030711044561
===============模型average结果==================
epoch:  143 pearson: ml_test_pearson:  0.685326954082748
[Epoch 144]
[batch 1] cost: 0.83674836 training pearson: 0.8315834501202359
[batch 2] cost: 0.8312796 training pearson: 0.7712384253722866
[batch 3] cost: 0.54934 training pearson: 0.6416398802719412
[batch 4] cost: 0.90796244 training pearson: 0.7901867605655408
[batch 5] cost: 0.54586005 training pearson: 0.6106330613742121
[batch 6] cost: 0.8353113 training pearson: 0.6508316885700948
[batch 7] cost: 1.2137449 training pearson: 0.7716059018890323
[batch 8] cost: 0.9497925 training pearson: 0.7888899173671149
[batch 9] cost: 0.7943693 training pearson: 0.6898890968356264
[batch 10] cost: 0.8152729 training pearson: 0.7562784442592119
[batch 11] cost: 0.97150415 training pearson: 0.6488773562794986
[batch 12] cost: 0.9249379 training pearson: 0.8051652874424566
[batch 13] cost: 0.574936 training pearson: 0.7548148367544109
[batch 14] cost: 0.63986033 training pearson: 0.760789556144501
[batch 15] cost: 0.6445383 training pearson: 0.8068336061409733
epoch:  144 pearson: test_pearson:  0.7185741247079646
============gbrt============
epoch:  144 pearson: ml_test_pearson:  0.6778032129127171
============xgb============
epoch:  144 pearson: ml_test_pearson:  0.7012924438431517
============rfr============
epoch:  144 pearson: ml_test_pearson:  0.6463427089698597
===============模型average结果==================
epoch:  144 pearson: ml_test_pearson:  0.690034294694204
[Epoch 145]
[batch 1] cost: 1.0633885 training pearson: 0.6160786795027579
[batch 2] cost: 0.8539608 training pearson: 0.6150620015675442
[batch 3] cost: 1.1248511 training pearson: 0.7697508858127233
[batch 4] cost: 0.64726853 training pearson: 0.8295177616916366
[batch 5] cost: 0.6981256 training pearson: 0.6620605445659338
[batch 6] cost: 0.9718625 training pearson: 0.777682892526974
[batch 7] cost: 0.6717875 training pearson: 0.811010464122866
[batch 8] cost: 0.76163816 training pearson: 0.7018089059212134
[batch 9] cost: 0.94830793 training pearson: 0.7572396082085046
[batch 10] cost: 0.47950563 training pearson: 0.762866089789748
[batch 11] cost: 0.8152675 training pearson: 0.7823478012355284
[batch 12] cost: 0.54265505 training pearson: 0.6522614731591273
[batch 13] cost: 0.76489687 training pearson: 0.7588365910862562
[batch 14] cost: 0.633355 training pearson: 0.678712732919283
[batch 15] cost: 0.9615634 training pearson: 0.8452818732773285
epoch:  145 pearson: test_pearson:  0.7185850618649966
============gbrt============
epoch:  145 pearson: ml_test_pearson:  0.6861440012637395
============xgb============
epoch:  145 pearson: ml_test_pearson:  0.701746880683141
============rfr============
epoch:  145 pearson: ml_test_pearson:  0.6582582970099684
===============模型average结果==================
epoch:  145 pearson: ml_test_pearson:  0.6993047494279887
[Epoch 146]
[batch 1] cost: 0.49848384 training pearson: 0.5812686471119451
[batch 2] cost: 0.7573561 training pearson: 0.6982016858071962
[batch 3] cost: 0.9420359 training pearson: 0.7758283819905787
[batch 4] cost: 0.7447237 training pearson: 0.602031969129524
[batch 5] cost: 0.691136 training pearson: 0.7685760546711534
[batch 6] cost: 1.1333978 training pearson: 0.7896184072232162
[batch 7] cost: 0.64994586 training pearson: 0.7724566202495495
[batch 8] cost: 0.7153589 training pearson: 0.7483035069581091
[batch 9] cost: 0.71049654 training pearson: 0.7859182979278615
[batch 10] cost: 0.6426438 training pearson: 0.8369846688246907
[batch 11] cost: 1.1234183 training pearson: 0.7465408870462754
[batch 12] cost: 0.8942858 training pearson: 0.7866903292525458
[batch 13] cost: 0.887427 training pearson: 0.7368741826583272
[batch 14] cost: 0.9687429 training pearson: 0.7869355519481003
[batch 15] cost: 0.66455215 training pearson: 0.8188219232396546
epoch:  146 pearson: test_pearson:  0.718678096994705
============gbrt============
epoch:  146 pearson: ml_test_pearson:  0.6793234176686551
============xgb============
epoch:  146 pearson: ml_test_pearson:  0.6990615282974199
============rfr============
epoch:  146 pearson: ml_test_pearson:  0.6329918845466858
===============模型average结果==================
epoch:  146 pearson: ml_test_pearson:  0.6835464105671263
[Epoch 147]
[batch 1] cost: 0.5715549 training pearson: 0.7525477308753808
[batch 2] cost: 0.79330957 training pearson: 0.7043171788696868
[batch 3] cost: 0.78214574 training pearson: 0.7392852826768674
[batch 4] cost: 0.91084075 training pearson: 0.7043467327433897
[batch 5] cost: 0.877575 training pearson: 0.6656001987143557
[batch 6] cost: 0.9191906 training pearson: 0.7388478930028627
[batch 7] cost: 0.8181683 training pearson: 0.7592562685417503
[batch 8] cost: 0.623831 training pearson: 0.8340646279086551
[batch 9] cost: 0.45271045 training pearson: 0.7143283790449605
[batch 10] cost: 0.90659356 training pearson: 0.7591548424715387
[batch 11] cost: 0.6345081 training pearson: 0.7697673781294052
[batch 12] cost: 0.96973765 training pearson: 0.7012515298679554
[batch 13] cost: 0.8017976 training pearson: 0.7807479315453418
[batch 14] cost: 1.095494 training pearson: 0.8506368229106116
[batch 15] cost: 0.737851 training pearson: 0.8266403685793933
epoch:  147 pearson: test_pearson:  0.7186780705465653
============gbrt============
epoch:  147 pearson: ml_test_pearson:  0.6702849022453073
============xgb============
epoch:  147 pearson: ml_test_pearson:  0.6810242093840049
============rfr============
epoch:  147 pearson: ml_test_pearson:  0.635553751886072
===============模型average结果==================
epoch:  147 pearson: ml_test_pearson:  0.6764110698534439
[Epoch 148]
[batch 1] cost: 0.85809493 training pearson: 0.7464973252701134
[batch 2] cost: 0.7086915 training pearson: 0.6888587097134184
[batch 3] cost: 0.9202482 training pearson: 0.8275728597458176
[batch 4] cost: 0.8742248 training pearson: 0.7938768209396387
[batch 5] cost: 0.5454881 training pearson: 0.7051016720842801
[batch 6] cost: 0.89825785 training pearson: 0.6908445343332903
[batch 7] cost: 0.9746829 training pearson: 0.7578161013362591
[batch 8] cost: 0.720446 training pearson: 0.792085916684442
[batch 9] cost: 0.7197434 training pearson: 0.7253533976335664
[batch 10] cost: 0.5987023 training pearson: 0.6960391998288431
[batch 11] cost: 0.8563598 training pearson: 0.8224440507882981
[batch 12] cost: 0.805743 training pearson: 0.7823324345314843
[batch 13] cost: 0.71355414 training pearson: 0.7736231992848093
[batch 14] cost: 1.1320149 training pearson: 0.6954094644333858
[batch 15] cost: 0.50654364 training pearson: 0.6857098589578751
epoch:  148 pearson: test_pearson:  0.7191841733039545
============gbrt============
epoch:  148 pearson: ml_test_pearson:  0.6934386857165525
============xgb============
epoch:  148 pearson: ml_test_pearson:  0.6999392656844725
============rfr============
epoch:  148 pearson: ml_test_pearson:  0.6606250997785643
===============模型average结果==================
epoch:  148 pearson: ml_test_pearson:  0.6975239280064395
[Epoch 149]
[batch 1] cost: 0.6583254 training pearson: 0.6054599021878359
[batch 2] cost: 0.58592194 training pearson: 0.7680195660986142
[batch 3] cost: 1.0248404 training pearson: 0.82615421603228
[batch 4] cost: 0.7872075 training pearson: 0.7872933243110438
[batch 5] cost: 0.6321115 training pearson: 0.672706839213409
[batch 6] cost: 0.6598244 training pearson: 0.8084632579874467
[batch 7] cost: 0.849204 training pearson: 0.8537602069022011
[batch 8] cost: 0.9803041 training pearson: 0.6776182542783945
[batch 9] cost: 0.7814064 training pearson: 0.7799043896586224
[batch 10] cost: 0.76511705 training pearson: 0.6896536277633432
[batch 11] cost: 0.78187406 training pearson: 0.767031301766105
[batch 12] cost: 0.4903492 training pearson: 0.7506673459028169
[batch 13] cost: 0.7061999 training pearson: 0.7795903700236494
[batch 14] cost: 1.1137317 training pearson: 0.6356521492295018
[batch 15] cost: 0.9148571 training pearson: 0.8080505655887551
epoch:  149 pearson: test_pearson:  0.7189634560018481
============gbrt============
epoch:  149 pearson: ml_test_pearson:  0.684633851184267
============xgb============
epoch:  149 pearson: ml_test_pearson:  0.6975875065293516
============rfr============
epoch:  149 pearson: ml_test_pearson:  0.6648906395457567
===============模型average结果==================
epoch:  149 pearson: ml_test_pearson:  0.7002130817321639
[Epoch 150]
[batch 1] cost: 0.96738404 training pearson: 0.7505768819803684
[batch 2] cost: 0.81734157 training pearson: 0.789501137706395
[batch 3] cost: 1.0320934 training pearson: 0.6985997093303331
[batch 4] cost: 0.8117877 training pearson: 0.750026047895675
[batch 5] cost: 0.63680875 training pearson: 0.7689547753071002
[batch 6] cost: 0.8025905 training pearson: 0.7985085827634659
[batch 7] cost: 0.4343334 training pearson: 0.7070656507618124
[batch 8] cost: 0.64662284 training pearson: 0.7816859349685712
[batch 9] cost: 0.74446785 training pearson: 0.7979891730863876
[batch 10] cost: 0.5394795 training pearson: 0.7690922846419381
[batch 11] cost: 0.8645922 training pearson: 0.6420465853364306
[batch 12] cost: 0.92703605 training pearson: 0.7937999042295087
[batch 13] cost: 0.91702807 training pearson: 0.828127344667359
[batch 14] cost: 0.63413095 training pearson: 0.6402715572216076
[batch 15] cost: 0.910428 training pearson: 0.7315644248967423
epoch:  150 pearson: test_pearson:  0.7189989905858497
============gbrt============
epoch:  150 pearson: ml_test_pearson:  0.6863341138460236
============xgb============
epoch:  150 pearson: ml_test_pearson:  0.7014348408715827
============rfr============
epoch:  150 pearson: ml_test_pearson:  0.6623457629591307
===============模型average结果==================
epoch:  150 pearson: ml_test_pearson:  0.6979981894387202
[Epoch 151]
[batch 1] cost: 0.97032106 training pearson: 0.7674711412125117
[batch 2] cost: 0.7989316 training pearson: 0.7695900631912779
[batch 3] cost: 0.62193525 training pearson: 0.6961784014943646
[batch 4] cost: 0.7749315 training pearson: 0.7316449072254827
[batch 5] cost: 0.78287965 training pearson: 0.6862107778024363
[batch 6] cost: 1.0173535 training pearson: 0.6594841898239949
[batch 7] cost: 0.7853659 training pearson: 0.8051920631040785
[batch 8] cost: 0.68195456 training pearson: 0.7702176520964619
[batch 9] cost: 0.91139907 training pearson: 0.7671092849018905
[batch 10] cost: 0.8586546 training pearson: 0.7189185030513843
[batch 11] cost: 1.0226482 training pearson: 0.8449170534284962
[batch 12] cost: 0.55372196 training pearson: 0.8480173611778007
[batch 13] cost: 0.559038 training pearson: 0.6590493763554772
[batch 14] cost: 0.70621127 training pearson: 0.8208953044137458
[batch 15] cost: 0.6192868 training pearson: 0.7845187784695277
epoch:  151 pearson: test_pearson:  0.7193299082775584
============gbrt============
epoch:  151 pearson: ml_test_pearson:  0.6905352849037624
============xgb============
epoch:  151 pearson: ml_test_pearson:  0.7029913716792969
============rfr============
epoch:  151 pearson: ml_test_pearson:  0.6416997251800209
===============模型average结果==================
epoch:  151 pearson: ml_test_pearson:  0.6892184119024154
[Epoch 152]
[batch 1] cost: 0.7599581 training pearson: 0.8760304518808919
[batch 2] cost: 0.9185173 training pearson: 0.7702491991276199
[batch 3] cost: 0.45264465 training pearson: 0.637488571135648
[batch 4] cost: 0.6510968 training pearson: 0.6334897944323427
[batch 5] cost: 0.56272626 training pearson: 0.6644186409847865
[batch 6] cost: 0.85486716 training pearson: 0.7380727784848864
[batch 7] cost: 1.0840577 training pearson: 0.8318500453902921
[batch 8] cost: 0.81166923 training pearson: 0.7020601658894775
[batch 9] cost: 0.71077764 training pearson: 0.7360269317914219
[batch 10] cost: 0.88495135 training pearson: 0.7715891169007624
[batch 11] cost: 0.66453654 training pearson: 0.7662296925677821
[batch 12] cost: 0.8674958 training pearson: 0.7457518930334529
[batch 13] cost: 0.95792085 training pearson: 0.7913711304149137
[batch 14] cost: 0.88582337 training pearson: 0.6429727516336879
[batch 15] cost: 0.55138224 training pearson: 0.6769178551300531
epoch:  152 pearson: test_pearson:  0.7199161634693472
============gbrt============
epoch:  152 pearson: ml_test_pearson:  0.7009313209721301
============xgb============
epoch:  152 pearson: ml_test_pearson:  0.716834323747734
============rfr============
epoch:  152 pearson: ml_test_pearson:  0.659168899942932
===============模型average结果==================
epoch:  152 pearson: ml_test_pearson:  0.7033206564935846
[Epoch 153]
[batch 1] cost: 0.71677095 training pearson: 0.7546724305801992
[batch 2] cost: 0.58776706 training pearson: 0.7251836499464764
[batch 3] cost: 0.8337282 training pearson: 0.7705962862610208
[batch 4] cost: 0.7399302 training pearson: 0.7829966044954966
[batch 5] cost: 0.90204614 training pearson: 0.7843560683053572
[batch 6] cost: 0.73610276 training pearson: 0.6809854340908251
[batch 7] cost: 0.60402477 training pearson: 0.7623586339666798
[batch 8] cost: 0.7057016 training pearson: 0.7978120277095402
[batch 9] cost: 0.76127046 training pearson: 0.761713982269104
[batch 10] cost: 0.68523467 training pearson: 0.8278926193393212
[batch 11] cost: 1.0835799 training pearson: 0.6637066945679208
[batch 12] cost: 0.7978216 training pearson: 0.7465948552348328
[batch 13] cost: 0.75927335 training pearson: 0.663058214314888
[batch 14] cost: 0.557278 training pearson: 0.7441752653230359
[batch 15] cost: 1.0858551 training pearson: 0.7788002068697771
epoch:  153 pearson: test_pearson:  0.7204806950289562
============gbrt============
epoch:  153 pearson: ml_test_pearson:  0.7071942967299435
============xgb============
epoch:  153 pearson: ml_test_pearson:  0.7161602724916847
============rfr============
epoch:  153 pearson: ml_test_pearson:  0.6731453653016755
===============模型average结果==================
epoch:  153 pearson: ml_test_pearson:  0.7126463963230275
[Epoch 154]
[batch 1] cost: 0.8256563 training pearson: 0.7994855278856096
[batch 2] cost: 0.83264005 training pearson: 0.6809116449649637
[batch 3] cost: 0.5048142 training pearson: 0.7124613883846453
[batch 4] cost: 0.8682613 training pearson: 0.7539512760977065
[batch 5] cost: 0.8621074 training pearson: 0.75112155748836
[batch 6] cost: 0.70679474 training pearson: 0.7632343162639545
[batch 7] cost: 0.7152146 training pearson: 0.6458188225775702
[batch 8] cost: 0.50916404 training pearson: 0.7675432827042202
[batch 9] cost: 0.451913 training pearson: 0.7453236412446931
[batch 10] cost: 0.9891674 training pearson: 0.695883123266937
[batch 11] cost: 0.9121295 training pearson: 0.7511153390677556
[batch 12] cost: 0.81653786 training pearson: 0.8057609758948514
[batch 13] cost: 0.6434618 training pearson: 0.8403999810233491
[batch 14] cost: 1.0096081 training pearson: 0.8026781248629279
[batch 15] cost: 0.88584363 training pearson: 0.643716276185918
epoch:  154 pearson: test_pearson:  0.72059872229004
============gbrt============
epoch:  154 pearson: ml_test_pearson:  0.709574974744295
============xgb============
epoch:  154 pearson: ml_test_pearson:  0.7109177755197261
============rfr============
epoch:  154 pearson: ml_test_pearson:  0.6708724297270618
===============模型average结果==================
epoch:  154 pearson: ml_test_pearson:  0.7123695968760875
[Epoch 155]
[batch 1] cost: 0.5590131 training pearson: 0.49486768610155907
[batch 2] cost: 0.6197312 training pearson: 0.8131197016225163
[batch 3] cost: 0.79106027 training pearson: 0.689320933689866
[batch 4] cost: 0.59239686 training pearson: 0.5469387651588468
[batch 5] cost: 1.1611847 training pearson: 0.8582896414542865
[batch 6] cost: 0.5959057 training pearson: 0.8334002845604966
[batch 7] cost: 0.665436 training pearson: 0.7945432069447687
[batch 8] cost: 0.81524336 training pearson: 0.6623290542282704
[batch 9] cost: 1.1314067 training pearson: 0.6911179915906775
[batch 10] cost: 0.78396314 training pearson: 0.7556219495468918
[batch 11] cost: 0.69757766 training pearson: 0.645299910819073
[batch 12] cost: 0.50334096 training pearson: 0.48345907235536467
[batch 13] cost: 0.9524722 training pearson: 0.8817471571614857
[batch 14] cost: 0.9078714 training pearson: 0.7765948145197074
[batch 15] cost: 0.71969855 training pearson: 0.7624588397084757
epoch:  155 pearson: test_pearson:  0.7202247946681285
============gbrt============
epoch:  155 pearson: ml_test_pearson:  0.6924097358509486
============xgb============
epoch:  155 pearson: ml_test_pearson:  0.7023588428929008
============rfr============
epoch:  155 pearson: ml_test_pearson:  0.669897633820724
===============模型average结果==================
epoch:  155 pearson: ml_test_pearson:  0.7004369331941371
[Epoch 156]
[batch 1] cost: 0.59319663 training pearson: 0.7417176845736482
[batch 2] cost: 0.55340284 training pearson: 0.7926485365429478
[batch 3] cost: 0.71665484 training pearson: 0.7681826042289168
[batch 4] cost: 1.0786308 training pearson: 0.8491609863038981
[batch 5] cost: 0.8665907 training pearson: 0.6188906822407771
[batch 6] cost: 0.7862549 training pearson: 0.6414427425371829
[batch 7] cost: 0.84820986 training pearson: 0.6831442324416409
[batch 8] cost: 0.65150505 training pearson: 0.7817151199422052
[batch 9] cost: 0.65146136 training pearson: 0.6513112033165188
[batch 10] cost: 0.58506066 training pearson: 0.7782198096341945
[batch 11] cost: 0.7728196 training pearson: 0.7208935240494518
[batch 12] cost: 0.72186416 training pearson: 0.7456193407889975
[batch 13] cost: 0.6471185 training pearson: 0.798157383889107
[batch 14] cost: 0.8820738 training pearson: 0.8071902337121977
[batch 15] cost: 1.0632937 training pearson: 0.7868091064532837
epoch:  156 pearson: test_pearson:  0.7208383250956395
============gbrt============
epoch:  156 pearson: ml_test_pearson:  0.685443966943212
============xgb============
epoch:  156 pearson: ml_test_pearson:  0.7129899310143859
============rfr============
epoch:  156 pearson: ml_test_pearson:  0.6503925220591597
===============模型average结果==================
epoch:  156 pearson: ml_test_pearson:  0.6923605885812072
[Epoch 157]
[batch 1] cost: 0.6160694 training pearson: 0.6990904924888639
[batch 2] cost: 0.74565524 training pearson: 0.8307910992699411
[batch 3] cost: 0.508641 training pearson: 0.5126499808403787
[batch 4] cost: 0.85859007 training pearson: 0.7371769147771696
[batch 5] cost: 0.6677642 training pearson: 0.7418022568720286
[batch 6] cost: 0.6534356 training pearson: 0.676410788455506
[batch 7] cost: 1.3464886 training pearson: 0.7924174347697059
[batch 8] cost: 0.5874285 training pearson: 0.7694846904486073
[batch 9] cost: 0.6633014 training pearson: 0.7717411158800718
[batch 10] cost: 0.69145614 training pearson: 0.7930776491019935
[batch 11] cost: 0.9856918 training pearson: 0.7836146751018087
[batch 12] cost: 0.78019214 training pearson: 0.7364211372069294
[batch 13] cost: 0.67747355 training pearson: 0.7355702629358102
[batch 14] cost: 0.79627246 training pearson: 0.6688867836009128
[batch 15] cost: 0.83411384 training pearson: 0.7772169538766639
epoch:  157 pearson: test_pearson:  0.7219015551045113
============gbrt============
epoch:  157 pearson: ml_test_pearson:  0.6941379548851065
============xgb============
epoch:  157 pearson: ml_test_pearson:  0.7255521044220138
============rfr============
epoch:  157 pearson: ml_test_pearson:  0.6292181678796475
===============模型average结果==================
epoch:  157 pearson: ml_test_pearson:  0.6941840837955746
[Epoch 158]
[batch 1] cost: 1.0616043 training pearson: 0.7275041453321189
[batch 2] cost: 0.5384465 training pearson: 0.523186442764365
[batch 3] cost: 0.7498441 training pearson: 0.8130033799528136
[batch 4] cost: 0.95579374 training pearson: 0.7634570531547837
[batch 5] cost: 0.48696527 training pearson: 0.7356267276515748
[batch 6] cost: 0.8864209 training pearson: 0.788909010318009
[batch 7] cost: 0.75254965 training pearson: 0.7199806978518849
[batch 8] cost: 0.40288934 training pearson: 0.7080881297861865
[batch 9] cost: 0.91994005 training pearson: 0.8370866678847788
[batch 10] cost: 0.6656236 training pearson: 0.8299029896572557
[batch 11] cost: 0.8359573 training pearson: 0.8080337640490316
[batch 12] cost: 0.50993013 training pearson: 0.681427431131895
[batch 13] cost: 0.9127499 training pearson: 0.7237224736390487
[batch 14] cost: 0.7761621 training pearson: 0.6929958625971148
[batch 15] cost: 0.87556833 training pearson: 0.7132586978135053
epoch:  158 pearson: test_pearson:  0.7204830826346807
============gbrt============
epoch:  158 pearson: ml_test_pearson:  0.7093635049073618
============xgb============
epoch:  158 pearson: ml_test_pearson:  0.7235687881333138
============rfr============
epoch:  158 pearson: ml_test_pearson:  0.6775664132917766
===============模型average结果==================
epoch:  158 pearson: ml_test_pearson:  0.7162832063249971
[Epoch 159]
[batch 1] cost: 0.7447578 training pearson: 0.6742252621356504
[batch 2] cost: 0.808013 training pearson: 0.7294922177735313
[batch 3] cost: 0.40190455 training pearson: 0.7894968350650993
[batch 4] cost: 0.7091618 training pearson: 0.7971090843295219
[batch 5] cost: 0.8605532 training pearson: 0.6546305332788076
[batch 6] cost: 1.1485516 training pearson: 0.7320931740906523
[batch 7] cost: 0.7193261 training pearson: 0.74847951045826
[batch 8] cost: 0.5656948 training pearson: 0.7481597711886754
[batch 9] cost: 0.6370767 training pearson: 0.6987882017279295
[batch 10] cost: 0.7203565 training pearson: 0.7716951961668593
[batch 11] cost: 0.78735673 training pearson: 0.840453006165081
[batch 12] cost: 0.70324254 training pearson: 0.6841464828936574
[batch 13] cost: 0.79748833 training pearson: 0.6654536565683096
[batch 14] cost: 0.80871415 training pearson: 0.784951678506068
[batch 15] cost: 0.92557096 training pearson: 0.8154004439717186
epoch:  159 pearson: test_pearson:  0.7212562149243853
============gbrt============
epoch:  159 pearson: ml_test_pearson:  0.7073472113173583
============xgb============
epoch:  159 pearson: ml_test_pearson:  0.7262510916407942
============rfr============
epoch:  159 pearson: ml_test_pearson:  0.6749536820122288
===============模型average结果==================
epoch:  159 pearson: ml_test_pearson:  0.7146575677583966
[Epoch 160]
[batch 1] cost: 0.64865273 training pearson: 0.7670943866082058
[batch 2] cost: 0.89049876 training pearson: 0.7421431238809981
[batch 3] cost: 0.5924537 training pearson: 0.5131765894067079
[batch 4] cost: 0.8442494 training pearson: 0.8273317436391285
[batch 5] cost: 0.6568712 training pearson: 0.7755084950070955
[batch 6] cost: 0.74594325 training pearson: 0.7489100096536092
[batch 7] cost: 0.90858454 training pearson: 0.8261348532442988
[batch 8] cost: 0.7565539 training pearson: 0.645003690963389
[batch 9] cost: 0.5731027 training pearson: 0.7957646663374814
[batch 10] cost: 0.920459 training pearson: 0.690825294333195
[batch 11] cost: 0.69849277 training pearson: 0.7896777416807215
[batch 12] cost: 0.6354908 training pearson: 0.7934597767159596
[batch 13] cost: 0.8922724 training pearson: 0.8033201067081855
[batch 14] cost: 0.6660736 training pearson: 0.7621512417296247
[batch 15] cost: 0.8663957 training pearson: 0.7729281621063476
epoch:  160 pearson: test_pearson:  0.7204112650437627
============gbrt============
epoch:  160 pearson: ml_test_pearson:  0.6945675095149643
============xgb============
epoch:  160 pearson: ml_test_pearson:  0.6999420832423123
============rfr============
epoch:  160 pearson: ml_test_pearson:  0.6939218633421596
===============模型average结果==================
epoch:  160 pearson: ml_test_pearson:  0.7098707798342191
[Epoch 161]
[batch 1] cost: 0.76125914 training pearson: 0.7849897156597389
[batch 2] cost: 0.62306654 training pearson: 0.6515960070289151
[batch 3] cost: 0.7834552 training pearson: 0.7545696768027217
[batch 4] cost: 0.72234726 training pearson: 0.7418651549317525
[batch 5] cost: 0.6505317 training pearson: 0.7160564727897516
[batch 6] cost: 0.65182894 training pearson: 0.8050120093920506
[batch 7] cost: 0.6607936 training pearson: 0.676317803067528
[batch 8] cost: 0.8010056 training pearson: 0.7792592732263396
[batch 9] cost: 0.47806272 training pearson: 0.7822145216658407
[batch 10] cost: 0.7754762 training pearson: 0.8193563647400167
[batch 11] cost: 1.108165 training pearson: 0.8029149271269125
[batch 12] cost: 0.866291 training pearson: 0.7990126727132778
[batch 13] cost: 0.5671755 training pearson: 0.787020142636178
[batch 14] cost: 0.89499557 training pearson: 0.5476205294067312
[batch 15] cost: 0.95270073 training pearson: 0.6428587133392414
epoch:  161 pearson: test_pearson:  0.7210470490883707
============gbrt============
epoch:  161 pearson: ml_test_pearson:  0.695804766565318
============xgb============
epoch:  161 pearson: ml_test_pearson:  0.6938034936500653
============rfr============
epoch:  161 pearson: ml_test_pearson:  0.6781353270334631
===============模型average结果==================
epoch:  161 pearson: ml_test_pearson:  0.7072219243984256
[Epoch 162]
[batch 1] cost: 0.76244795 training pearson: 0.7986709269321758
[batch 2] cost: 0.83074075 training pearson: 0.823857442174041
[batch 3] cost: 0.74957246 training pearson: 0.7486360296652466
[batch 4] cost: 1.0125365 training pearson: 0.7480229347109918
[batch 5] cost: 0.7972439 training pearson: 0.6195135543876659
[batch 6] cost: 0.7801677 training pearson: 0.7055749173887325
[batch 7] cost: 0.7635503 training pearson: 0.7351553542890327
[batch 8] cost: 0.598638 training pearson: 0.8208024606265136
[batch 9] cost: 0.7723953 training pearson: 0.7976196751198793
[batch 10] cost: 0.7077331 training pearson: 0.6934067892354457
[batch 11] cost: 0.4871373 training pearson: 0.6617432419211382
[batch 12] cost: 0.84407514 training pearson: 0.7438887788367714
[batch 13] cost: 0.74511075 training pearson: 0.7722660637563729
[batch 14] cost: 0.40214646 training pearson: 0.696341013806978
[batch 15] cost: 0.9350306 training pearson: 0.7702352820221897
epoch:  162 pearson: test_pearson:  0.7218269810641186
============gbrt============
epoch:  162 pearson: ml_test_pearson:  0.7028399812599742
============xgb============
epoch:  162 pearson: ml_test_pearson:  0.7038862961205634
============rfr============
epoch:  162 pearson: ml_test_pearson:  0.6801276790962393
===============模型average结果==================
epoch:  162 pearson: ml_test_pearson:  0.7080131689133436
[Epoch 163]
[batch 1] cost: 0.6792849 training pearson: 0.8299434783172231
[batch 2] cost: 0.7473181 training pearson: 0.8840050268968818
[batch 3] cost: 0.8861 training pearson: 0.706217910708415
[batch 4] cost: 0.8366644 training pearson: 0.76055099758529
[batch 5] cost: 0.6528133 training pearson: 0.79665314731818
[batch 6] cost: 0.62385255 training pearson: 0.7367823720262383
[batch 7] cost: 0.5478704 training pearson: 0.6620267694059844
[batch 8] cost: 0.6963367 training pearson: 0.787865622003344
[batch 9] cost: 0.755376 training pearson: 0.6939889142887242
[batch 10] cost: 0.6856915 training pearson: 0.6666848726513948
[batch 11] cost: 0.7192156 training pearson: 0.673436703084943
[batch 12] cost: 0.6176835 training pearson: 0.7759406539366748
[batch 13] cost: 0.5062304 training pearson: 0.7040069453121475
[batch 14] cost: 0.9081129 training pearson: 0.7056416900773944
[batch 15] cost: 1.309065 training pearson: 0.8040149917475178
epoch:  163 pearson: test_pearson:  0.7213652502397824
============gbrt============
epoch:  163 pearson: ml_test_pearson:  0.6835956651158849
============xgb============
epoch:  163 pearson: ml_test_pearson:  0.6986849043051131
============rfr============
epoch:  163 pearson: ml_test_pearson:  0.6808629474969593
===============模型average结果==================
epoch:  163 pearson: ml_test_pearson:  0.7007129594369469
[Epoch 164]
[batch 1] cost: 0.69955504 training pearson: 0.7287955762497075
[batch 2] cost: 0.34977493 training pearson: 0.6192720377207722
[batch 3] cost: 0.5418003 training pearson: 0.7970978961254978
[batch 4] cost: 0.8466606 training pearson: 0.7168839964831136
[batch 5] cost: 0.6790545 training pearson: 0.6524353189752181
[batch 6] cost: 0.5557589 training pearson: 0.7707569458056663
[batch 7] cost: 0.81897044 training pearson: 0.8054295167034953
[batch 8] cost: 1.2786037 training pearson: 0.747443870042546
[batch 9] cost: 0.73698556 training pearson: 0.8114270436693396
[batch 10] cost: 0.52224374 training pearson: 0.6202188468441394
[batch 11] cost: 1.0202872 training pearson: 0.7429594787738778
[batch 12] cost: 0.70758265 training pearson: 0.744042333023824
[batch 13] cost: 0.6302355 training pearson: 0.7842556451234736
[batch 14] cost: 0.7938429 training pearson: 0.9004313022718186
[batch 15] cost: 0.9437198 training pearson: 0.6877077831873009
epoch:  164 pearson: test_pearson:  0.7208867992970388
============gbrt============
epoch:  164 pearson: ml_test_pearson:  0.7037801331340661
============xgb============
epoch:  164 pearson: ml_test_pearson:  0.7062113436935391
============rfr============
epoch:  164 pearson: ml_test_pearson:  0.657612957657422
===============模型average结果==================
epoch:  164 pearson: ml_test_pearson:  0.699730375513886
[Epoch 165]
[batch 1] cost: 0.76916033 training pearson: 0.802173461304468
[batch 2] cost: 0.3362722 training pearson: 0.668619642266331
[batch 3] cost: 0.5501868 training pearson: 0.6450699128965
[batch 4] cost: 0.565461 training pearson: 0.7980876448990981
[batch 5] cost: 0.78148055 training pearson: 0.8004827786993647
[batch 6] cost: 0.8866452 training pearson: 0.7325979339105918
[batch 7] cost: 0.79471 training pearson: 0.8148119216431134
[batch 8] cost: 0.82311165 training pearson: 0.8269372932359065
[batch 9] cost: 0.76697004 training pearson: 0.7371212898674869
[batch 10] cost: 0.9070024 training pearson: 0.7661799458019767
[batch 11] cost: 0.95360655 training pearson: 0.7641539688424162
[batch 12] cost: 0.7149253 training pearson: 0.7766966882262433
[batch 13] cost: 0.48266047 training pearson: 0.6823699171664873
[batch 14] cost: 0.970849 training pearson: 0.6909255829288021
[batch 15] cost: 0.7776933 training pearson: 0.7383008294601975
epoch:  165 pearson: test_pearson:  0.7215492868065565
============gbrt============
epoch:  165 pearson: ml_test_pearson:  0.6968318237396632
============xgb============
epoch:  165 pearson: ml_test_pearson:  0.7013996758391068
============rfr============
epoch:  165 pearson: ml_test_pearson:  0.6921322059355971
===============模型average结果==================
epoch:  165 pearson: ml_test_pearson:  0.7100729585859731
[Epoch 166]
[batch 1] cost: 0.58526766 training pearson: 0.6973872970664622
[batch 2] cost: 0.8604399 training pearson: 0.815904399477215
[batch 3] cost: 0.74186295 training pearson: 0.6688247846875643
[batch 4] cost: 0.5278753 training pearson: 0.7042447902421722
[batch 5] cost: 0.8027632 training pearson: 0.6214801170635158
[batch 6] cost: 0.9202902 training pearson: 0.7863668241125622
[batch 7] cost: 0.81943834 training pearson: 0.7346826836107772
[batch 8] cost: 0.6489157 training pearson: 0.66981512836302
[batch 9] cost: 0.45471513 training pearson: 0.823946115014963
[batch 10] cost: 0.6510344 training pearson: 0.7389308130100926
[batch 11] cost: 0.7016094 training pearson: 0.6911749346229593
[batch 12] cost: 1.0684149 training pearson: 0.8319062937376142
[batch 13] cost: 1.1278073 training pearson: 0.7983517488959537
[batch 14] cost: 0.59769326 training pearson: 0.8243110401496947
[batch 15] cost: 0.6167151 training pearson: 0.7057967441734078
epoch:  166 pearson: test_pearson:  0.7231735291898254
============gbrt============
epoch:  166 pearson: ml_test_pearson:  0.7164615932960884
============xgb============
epoch:  166 pearson: ml_test_pearson:  0.7092163341665209
============rfr============
epoch:  166 pearson: ml_test_pearson:  0.7028825025718255
===============模型average结果==================
epoch:  166 pearson: ml_test_pearson:  0.7219166025697061
[Epoch 167]
[batch 1] cost: 0.74151903 training pearson: 0.6043282066037802
[batch 2] cost: 0.7473001 training pearson: 0.8382423708794061
[batch 3] cost: 0.69339365 training pearson: 0.8543007113616448
[batch 4] cost: 0.56590265 training pearson: 0.663004900217063
[batch 5] cost: 1.0782828 training pearson: 0.7408060927565154
[batch 6] cost: 0.6000647 training pearson: 0.8282408374700178
[batch 7] cost: 0.7426747 training pearson: 0.4874346359636614
[batch 8] cost: 0.9639519 training pearson: 0.7836676289524641
[batch 9] cost: 0.966779 training pearson: 0.815678040010868
[batch 10] cost: 0.63942903 training pearson: 0.7498918461583092
[batch 11] cost: 0.81839824 training pearson: 0.782285583077307
[batch 12] cost: 0.54657876 training pearson: 0.6793922482552143
[batch 13] cost: 0.63332963 training pearson: 0.7580359671642349
[batch 14] cost: 0.83336467 training pearson: 0.806881926179588
[batch 15] cost: 0.45987836 training pearson: 0.6265778279874016
epoch:  167 pearson: test_pearson:  0.7222132848894862
============gbrt============
epoch:  167 pearson: ml_test_pearson:  0.7003901662779042
============xgb============
epoch:  167 pearson: ml_test_pearson:  0.6924892415720504
============rfr============
epoch:  167 pearson: ml_test_pearson:  0.6898143052404243
===============模型average结果==================
epoch:  167 pearson: ml_test_pearson:  0.7104473527997642
[Epoch 168]
[batch 1] cost: 0.6894493 training pearson: 0.7710573182557449
[batch 2] cost: 0.88338304 training pearson: 0.6501013075966166
[batch 3] cost: 0.6727859 training pearson: 0.7737569421973093
[batch 4] cost: 0.42868093 training pearson: 0.5289916200590565
[batch 5] cost: 0.6480813 training pearson: 0.8565700264334832
[batch 6] cost: 0.5976522 training pearson: 0.6079640968903276
[batch 7] cost: 0.8291921 training pearson: 0.7862288295333949
[batch 8] cost: 0.71737134 training pearson: 0.6841807363989914
[batch 9] cost: 0.9892881 training pearson: 0.8232187379950975
[batch 10] cost: 0.9259306 training pearson: 0.8539410123046605
[batch 11] cost: 0.88929206 training pearson: 0.7951649742384425
[batch 12] cost: 0.61677814 training pearson: 0.7144216067893253
[batch 13] cost: 0.6051353 training pearson: 0.5608678101615499
[batch 14] cost: 0.69255537 training pearson: 0.6166940755475988
[batch 15] cost: 0.90562075 training pearson: 0.7320744918217078
epoch:  168 pearson: test_pearson:  0.7228825552901138
============gbrt============
epoch:  168 pearson: ml_test_pearson:  0.6972938423604175
============xgb============
epoch:  168 pearson: ml_test_pearson:  0.705121360449947
============rfr============
epoch:  168 pearson: ml_test_pearson:  0.6792647865097837
===============模型average结果==================
epoch:  168 pearson: ml_test_pearson:  0.7084297660578316
[Epoch 169]
[batch 1] cost: 0.3684728 training pearson: 0.7495265121125437
[batch 2] cost: 0.8434442 training pearson: 0.655888701609033
[batch 3] cost: 0.5199896 training pearson: 0.49579223839952724
[batch 4] cost: 0.7619976 training pearson: 0.8149636054578734
[batch 5] cost: 0.72432494 training pearson: 0.8009912295232418
[batch 6] cost: 1.0809207 training pearson: 0.694333926621612
[batch 7] cost: 0.9396652 training pearson: 0.751610023542602
[batch 8] cost: 0.46816802 training pearson: 0.4870856485753357
[batch 9] cost: 0.5695961 training pearson: 0.6592771100804811
[batch 10] cost: 1.0986198 training pearson: 0.8283690686596531
[batch 11] cost: 0.87068945 training pearson: 0.7662505167037605
[batch 12] cost: 0.8853351 training pearson: 0.7551244144520357
[batch 13] cost: 0.5258629 training pearson: 0.774794076915922
[batch 14] cost: 0.6284567 training pearson: 0.9050201927989747
[batch 15] cost: 0.6384143 training pearson: 0.6979684148153316
epoch:  169 pearson: test_pearson:  0.722889566304191
============gbrt============
epoch:  169 pearson: ml_test_pearson:  0.7100671686896622
============xgb============
epoch:  169 pearson: ml_test_pearson:  0.7044613584391975
============rfr============
epoch:  169 pearson: ml_test_pearson:  0.6971073766503358
===============模型average结果==================
epoch:  169 pearson: ml_test_pearson:  0.7183485346207276
[Epoch 170]
[batch 1] cost: 0.614688 training pearson: 0.7040905892681881
[batch 2] cost: 0.60454077 training pearson: 0.6821637530881933
[batch 3] cost: 0.80831546 training pearson: 0.6400447650311993
[batch 4] cost: 0.6140789 training pearson: 0.7841854320048804
[batch 5] cost: 0.63158464 training pearson: 0.6832852807555256
[batch 6] cost: 0.7288307 training pearson: 0.77865441102764
[batch 7] cost: 0.50980777 training pearson: 0.7968109566024685
[batch 8] cost: 0.77848464 training pearson: 0.8247724228265426
[batch 9] cost: 0.97880876 training pearson: 0.8119443206853768
[batch 10] cost: 0.9725163 training pearson: 0.7943363380524308
[batch 11] cost: 0.88733774 training pearson: 0.8165491002826722
[batch 12] cost: 0.9157165 training pearson: 0.7773974083428344
[batch 13] cost: 0.5522788 training pearson: 0.6850795791420596
[batch 14] cost: 0.76761156 training pearson: 0.750437086755569
[batch 15] cost: 0.67609894 training pearson: 0.7535349357188227
epoch:  170 pearson: test_pearson:  0.7239349385938078
============gbrt============
epoch:  170 pearson: ml_test_pearson:  0.7123259500052219
============xgb============
epoch:  170 pearson: ml_test_pearson:  0.7118647659847124
============rfr============
epoch:  170 pearson: ml_test_pearson:  0.7085877103872743
===============模型average结果==================
epoch:  170 pearson: ml_test_pearson:  0.724187925140424
[Epoch 171]
[batch 1] cost: 0.6721031 training pearson: 0.7850832401551346
[batch 2] cost: 0.5372552 training pearson: 0.7800808735594545
[batch 3] cost: 0.89794695 training pearson: 0.848102623319321
[batch 4] cost: 0.7293023 training pearson: 0.7429279064828397
[batch 5] cost: 0.72242975 training pearson: 0.7263454815340873
[batch 6] cost: 0.8386381 training pearson: 0.6567560409735809
[batch 7] cost: 0.8632922 training pearson: 0.6884331952441902
[batch 8] cost: 0.76386636 training pearson: 0.7987750730660641
[batch 9] cost: 0.8828691 training pearson: 0.811475502093724
[batch 10] cost: 0.61578584 training pearson: 0.726128604101423
[batch 11] cost: 1.0328616 training pearson: 0.7492907014305903
[batch 12] cost: 0.69929564 training pearson: 0.7421445762734623
[batch 13] cost: 0.7515997 training pearson: 0.7454660892443139
[batch 14] cost: 0.5484433 training pearson: 0.7154528946279451
[batch 15] cost: 0.54421115 training pearson: 0.7364378046153053
epoch:  171 pearson: test_pearson:  0.7240054763572744
============gbrt============
epoch:  171 pearson: ml_test_pearson:  0.7178184808336645
============xgb============
epoch:  171 pearson: ml_test_pearson:  0.7072564498287116
============rfr============
epoch:  171 pearson: ml_test_pearson:  0.6819793330272095
===============模型average结果==================
epoch:  171 pearson: ml_test_pearson:  0.7191039982127116
[Epoch 172]
[batch 1] cost: 0.6010827 training pearson: 0.8136688733544187
[batch 2] cost: 0.7221571 training pearson: 0.5750739547364336
[batch 3] cost: 0.5374192 training pearson: 0.6377972443489279
[batch 4] cost: 0.6597372 training pearson: 0.7526691925101956
[batch 5] cost: 0.9888394 training pearson: 0.7805261024145236
[batch 6] cost: 0.50073767 training pearson: 0.8183182065186991
[batch 7] cost: 0.9531583 training pearson: 0.6567085960482257
[batch 8] cost: 0.9454082 training pearson: 0.7062509211941413
[batch 9] cost: 0.5581052 training pearson: 0.709241760938306
[batch 10] cost: 0.9584321 training pearson: 0.7165530934020667
[batch 11] cost: 0.5369991 training pearson: 0.8070239933944323
[batch 12] cost: 0.7174269 training pearson: 0.7978296382825933
[batch 13] cost: 0.8980658 training pearson: 0.786370536430806
[batch 14] cost: 0.5722807 training pearson: 0.842409208533489
[batch 15] cost: 0.7556282 training pearson: 0.7782715695378489
epoch:  172 pearson: test_pearson:  0.724985015746799
============gbrt============
epoch:  172 pearson: ml_test_pearson:  0.7018023260812732
============xgb============
epoch:  172 pearson: ml_test_pearson:  0.6922436572717626
============rfr============
epoch:  172 pearson: ml_test_pearson:  0.6655566045609066
===============模型average结果==================
epoch:  172 pearson: ml_test_pearson:  0.7011255555205562
[Epoch 173]
[batch 1] cost: 0.68111646 training pearson: 0.7177832639299233
[batch 2] cost: 0.64052445 training pearson: 0.6256183645937176
[batch 3] cost: 0.61071974 training pearson: 0.7117089691842864
[batch 4] cost: 0.695806 training pearson: 0.8014431356171354
[batch 5] cost: 0.7739953 training pearson: 0.6644507475386213
[batch 6] cost: 0.8158258 training pearson: 0.7932790118951583
[batch 7] cost: 0.6997329 training pearson: 0.8389882857063263
[batch 8] cost: 0.74484444 training pearson: 0.801153852380571
[batch 9] cost: 0.77271706 training pearson: 0.7586757534087784
[batch 10] cost: 1.1299049 training pearson: 0.7324754118908076
[batch 11] cost: 0.6515998 training pearson: 0.7539419637559726
[batch 12] cost: 0.75535125 training pearson: 0.7935161814416267
[batch 13] cost: 0.67805475 training pearson: 0.762251862381304
[batch 14] cost: 0.4861146 training pearson: 0.6054040527536066
[batch 15] cost: 0.68754715 training pearson: 0.790800707823223
epoch:  173 pearson: test_pearson:  0.7242979801702921
============gbrt============
epoch:  173 pearson: ml_test_pearson:  0.7097775878684273
============xgb============
epoch:  173 pearson: ml_test_pearson:  0.7181976534174561
============rfr============
epoch:  173 pearson: ml_test_pearson:  0.6488630856430787
===============模型average结果==================
epoch:  173 pearson: ml_test_pearson:  0.7052919733784789
[Epoch 174]
[batch 1] cost: 0.6357526 training pearson: 0.7961751665465198
[batch 2] cost: 0.8460586 training pearson: 0.6110567867680872
[batch 3] cost: 0.7092018 training pearson: 0.6621590801516068
[batch 4] cost: 0.78507143 training pearson: 0.7699948529500218
[batch 5] cost: 0.55425143 training pearson: 0.6358828632680834
[batch 6] cost: 0.836315 training pearson: 0.8256025374949574
[batch 7] cost: 0.5183214 training pearson: 0.7522892314684211
[batch 8] cost: 0.83690995 training pearson: 0.7531971165536239
[batch 9] cost: 0.61624223 training pearson: 0.557368180559985
[batch 10] cost: 0.6203076 training pearson: 0.7850327343239287
[batch 11] cost: 0.94714934 training pearson: 0.7724757366759862
[batch 12] cost: 0.57467484 training pearson: 0.830617178823552
[batch 13] cost: 0.8910353 training pearson: 0.8463996230776042
[batch 14] cost: 0.7204282 training pearson: 0.6101890929941544
[batch 15] cost: 0.6902904 training pearson: 0.740674368102365
epoch:  174 pearson: test_pearson:  0.7244056837756759
============gbrt============
epoch:  174 pearson: ml_test_pearson:  0.7277271209230544
============xgb============
epoch:  174 pearson: ml_test_pearson:  0.7440770327799551
============rfr============
epoch:  174 pearson: ml_test_pearson:  0.6732544072363587
===============模型average结果==================
epoch:  174 pearson: ml_test_pearson:  0.7249759616083873
[Epoch 175]
[batch 1] cost: 0.6516958 training pearson: 0.6396086685208756
[batch 2] cost: 0.7441711 training pearson: 0.6811098155644996
[batch 3] cost: 0.67688185 training pearson: 0.7934265543847105
[batch 4] cost: 0.69381964 training pearson: 0.714629128843466
[batch 5] cost: 1.008493 training pearson: 0.7779411060588538
[batch 6] cost: 0.80362076 training pearson: 0.7090483648032034
[batch 7] cost: 0.72594786 training pearson: 0.7447968037505123
[batch 8] cost: 0.7165693 training pearson: 0.7746842602701953
[batch 9] cost: 0.4907518 training pearson: 0.7804498466660896
[batch 10] cost: 0.37664855 training pearson: 0.31839734795298436
[batch 11] cost: 0.7404368 training pearson: 0.8434120367772674
[batch 12] cost: 0.9557869 training pearson: 0.7669574341077257
[batch 13] cost: 0.8513309 training pearson: 0.8481333672016645
[batch 14] cost: 0.6292946 training pearson: 0.533077133824161
[batch 15] cost: 0.6706364 training pearson: 0.7797008139233385
epoch:  175 pearson: test_pearson:  0.7258010235112337
============gbrt============
epoch:  175 pearson: ml_test_pearson:  0.7525243851237958
============xgb============
epoch:  175 pearson: ml_test_pearson:  0.7238128600290883
============rfr============
epoch:  175 pearson: ml_test_pearson:  0.7121544371660257
===============模型average结果==================
epoch:  175 pearson: ml_test_pearson:  0.7476631040098568
[Epoch 176]
[batch 1] cost: 0.6810764 training pearson: 0.7917448844779849
[batch 2] cost: 0.6326085 training pearson: 0.7893454140788344
[batch 3] cost: 0.8031698 training pearson: 0.757905779583516
[batch 4] cost: 0.8224499 training pearson: 0.7137238157398965
[batch 5] cost: 0.7041861 training pearson: 0.7453673885538886
[batch 6] cost: 0.6327149 training pearson: 0.690106559434217
[batch 7] cost: 0.8179081 training pearson: 0.8452392915092773
[batch 8] cost: 0.47742122 training pearson: 0.611491830309067
[batch 9] cost: 0.6646874 training pearson: 0.7370546297422662
[batch 10] cost: 0.96462035 training pearson: 0.7459023224154749
[batch 11] cost: 0.8083366 training pearson: 0.8085598584780795
[batch 12] cost: 0.7797258 training pearson: 0.7677119062889348
[batch 13] cost: 0.6614137 training pearson: 0.7412883924705571
[batch 14] cost: 0.71781564 training pearson: 0.7787619317587787
[batch 15] cost: 0.5422318 training pearson: 0.8169853802757635
epoch:  176 pearson: test_pearson:  0.7261179694710894
============gbrt============
epoch:  176 pearson: ml_test_pearson:  0.7296314440263774
============xgb============
epoch:  176 pearson: ml_test_pearson:  0.7355587697986342
============rfr============
epoch:  176 pearson: ml_test_pearson:  0.6923560614156856
===============模型average结果==================
epoch:  176 pearson: ml_test_pearson:  0.731441634895247
[Epoch 177]
[batch 1] cost: 0.88445824 training pearson: 0.7981936565397509
[batch 2] cost: 0.6315904 training pearson: 0.7269781711401898
[batch 3] cost: 0.5932302 training pearson: 0.6759554173004267
[batch 4] cost: 0.66833574 training pearson: 0.8589886177301673
[batch 5] cost: 0.7241629 training pearson: 0.7837375106451088
[batch 6] cost: 0.6288971 training pearson: 0.823090095124513
[batch 7] cost: 0.41418883 training pearson: 0.7715027878768621
[batch 8] cost: 0.96164876 training pearson: 0.6648299649209939
[batch 9] cost: 0.8674998 training pearson: 0.747015532054815
[batch 10] cost: 0.80686986 training pearson: 0.7778012840326834
[batch 11] cost: 0.8315117 training pearson: 0.6333245845602782
[batch 12] cost: 0.6599033 training pearson: 0.816924438619447
[batch 13] cost: 0.8159423 training pearson: 0.7385004741779422
[batch 14] cost: 0.69182587 training pearson: 0.6782010496395424
[batch 15] cost: 0.45036507 training pearson: 0.704557180139508
epoch:  177 pearson: test_pearson:  0.7258415959316148
============gbrt============
epoch:  177 pearson: ml_test_pearson:  0.7263953667088799
============xgb============
epoch:  177 pearson: ml_test_pearson:  0.7269573431881222
============rfr============
epoch:  177 pearson: ml_test_pearson:  0.6975642260797063
===============模型average结果==================
epoch:  177 pearson: ml_test_pearson:  0.732817634869388
[Epoch 178]
[batch 1] cost: 0.7606382 training pearson: 0.7619693783688394
[batch 2] cost: 0.89578974 training pearson: 0.5016740418092203
[batch 3] cost: 0.47995594 training pearson: 0.7610208756013309
[batch 4] cost: 0.6917 training pearson: 0.7529349514222946
[batch 5] cost: 0.44065547 training pearson: 0.6252129184328562
[batch 6] cost: 0.7619043 training pearson: 0.7775559779208259
[batch 7] cost: 0.7814236 training pearson: 0.7506893352805549
[batch 8] cost: 0.69959307 training pearson: 0.7158388778397965
[batch 9] cost: 0.7983494 training pearson: 0.5773352254931102
[batch 10] cost: 0.7833772 training pearson: 0.8374560074100599
[batch 11] cost: 0.4601879 training pearson: 0.8193276079472501
[batch 12] cost: 0.8869594 training pearson: 0.8480042196214814
[batch 13] cost: 0.7403991 training pearson: 0.7706708811958025
[batch 14] cost: 0.6850368 training pearson: 0.766970958101438
[batch 15] cost: 0.7851438 training pearson: 0.8319389082275593
epoch:  178 pearson: test_pearson:  0.7214270960287097
============gbrt============
epoch:  178 pearson: ml_test_pearson:  0.7108655972626341
============xgb============
epoch:  178 pearson: ml_test_pearson:  0.6898498705570807
============rfr============
epoch:  178 pearson: ml_test_pearson:  0.668163332995918
===============模型average结果==================
epoch:  178 pearson: ml_test_pearson:  0.7025858639663012
[Epoch 179]
[batch 1] cost: 0.84241873 training pearson: 0.7502365944527314
[batch 2] cost: 0.84604925 training pearson: 0.7231614397311837
[batch 3] cost: 0.54486376 training pearson: 0.8407219534208416
[batch 4] cost: 0.7650296 training pearson: 0.815316366301945
[batch 5] cost: 0.75800073 training pearson: 0.7257233767440191
[batch 6] cost: 0.7979686 training pearson: 0.7340870554189579
[batch 7] cost: 0.6489724 training pearson: 0.7218272570882488
[batch 8] cost: 0.8814912 training pearson: 0.8132325798290276
[batch 9] cost: 0.5585249 training pearson: 0.821032785797164
[batch 10] cost: 0.7504862 training pearson: 0.689171282317996
[batch 11] cost: 0.61055094 training pearson: 0.6645167550525327
[batch 12] cost: 0.9206718 training pearson: 0.7177673801553389
[batch 13] cost: 0.63148844 training pearson: 0.7378270583105223
[batch 14] cost: 0.3715615 training pearson: 0.5913107720768082
[batch 15] cost: 0.810103 training pearson: 0.6997420858804296
epoch:  179 pearson: test_pearson:  0.7215403605526417
============gbrt============
epoch:  179 pearson: ml_test_pearson:  0.722216936478323
============xgb============
epoch:  179 pearson: ml_test_pearson:  0.7249412632968536
============rfr============
epoch:  179 pearson: ml_test_pearson:  0.6541077514218413
===============模型average结果==================
epoch:  179 pearson: ml_test_pearson:  0.7092838303071878
[Epoch 180]
[batch 1] cost: 0.7210501 training pearson: 0.6940559565271142
[batch 2] cost: 0.5368298 training pearson: 0.7759411968653434
[batch 3] cost: 0.6902225 training pearson: 0.7262628438440115
[batch 4] cost: 0.6370732 training pearson: 0.8015611541879507
[batch 5] cost: 0.62265277 training pearson: 0.8172795470148472
[batch 6] cost: 0.75611067 training pearson: 0.7725921896181028
[batch 7] cost: 0.94867074 training pearson: 0.8160223067874945
[batch 8] cost: 0.39527717 training pearson: 0.7096853837016079
[batch 9] cost: 0.72000796 training pearson: 0.7159016347641939
[batch 10] cost: 1.0321001 training pearson: 0.6559841424587809
[batch 11] cost: 0.7253197 training pearson: 0.6777509334740532
[batch 12] cost: 0.7976074 training pearson: 0.7428990895211691
[batch 13] cost: 0.84370637 training pearson: 0.8265755627474323
[batch 14] cost: 0.51335174 training pearson: 0.5561673311551907
[batch 15] cost: 0.8506277 training pearson: 0.7926496295285406
epoch:  180 pearson: test_pearson:  0.7218736595676172
============gbrt============
epoch:  180 pearson: ml_test_pearson:  0.7226484258846224
============xgb============
epoch:  180 pearson: ml_test_pearson:  0.7251127136335678
============rfr============
epoch:  180 pearson: ml_test_pearson:  0.6614933390829904
===============模型average结果==================
epoch:  180 pearson: ml_test_pearson:  0.7128538673128438
[Epoch 181]
[batch 1] cost: 1.045939 training pearson: 0.6613304648877837
[batch 2] cost: 0.7388073 training pearson: 0.8038212629137581
[batch 3] cost: 0.94039 training pearson: 0.7844670085011356
[batch 4] cost: 0.8683373 training pearson: 0.7966825552757857
[batch 5] cost: 1.1016339 training pearson: 0.7629621123842267
[batch 6] cost: 0.717926 training pearson: 0.6307545688077575
[batch 7] cost: 0.6357398 training pearson: 0.7900666020319822
[batch 8] cost: 0.47565457 training pearson: 0.7511269045008344
[batch 9] cost: 0.5129275 training pearson: 0.5735372739053445
[batch 10] cost: 0.66504884 training pearson: 0.7337725542179372
[batch 11] cost: 0.47208187 training pearson: 0.8488370844596183
[batch 12] cost: 0.70921296 training pearson: 0.7344325345837935
[batch 13] cost: 0.6214436 training pearson: 0.7495667445337691
[batch 14] cost: 0.6023636 training pearson: 0.722264154442258
[batch 15] cost: 0.4819798 training pearson: 0.8201655108646034
epoch:  181 pearson: test_pearson:  0.7219646459908342
============gbrt============
epoch:  181 pearson: ml_test_pearson:  0.7047961193475282
============xgb============
epoch:  181 pearson: ml_test_pearson:  0.7271076623316427
============rfr============
epoch:  181 pearson: ml_test_pearson:  0.6763125888796515
===============模型average结果==================
epoch:  181 pearson: ml_test_pearson:  0.7102692076281467
[Epoch 182]
[batch 1] cost: 0.5908153 training pearson: 0.7105825060985732
[batch 2] cost: 0.3782895 training pearson: 0.7474500935600519
[batch 3] cost: 0.83835983 training pearson: 0.751656997305893
[batch 4] cost: 0.6144059 training pearson: 0.6886468455983148
[batch 5] cost: 0.9758878 training pearson: 0.8690662960130754
[batch 6] cost: 0.77475476 training pearson: 0.73969234051972
[batch 7] cost: 0.59977806 training pearson: 0.836082069653962
[batch 8] cost: 0.7505223 training pearson: 0.7884335725625102
[batch 9] cost: 0.8030986 training pearson: 0.7192246350732225
[batch 10] cost: 0.8852402 training pearson: 0.7716373962278396
[batch 11] cost: 0.6348831 training pearson: 0.5723829437040638
[batch 12] cost: 0.8321898 training pearson: 0.7817729175551139
[batch 13] cost: 0.7257996 training pearson: 0.7465377808537362
[batch 14] cost: 0.7539265 training pearson: 0.6194216660822678
[batch 15] cost: 0.47596282 training pearson: 0.821764835637847
epoch:  182 pearson: test_pearson:  0.7220923387186803
============gbrt============
epoch:  182 pearson: ml_test_pearson:  0.727910948150638
============xgb============
epoch:  182 pearson: ml_test_pearson:  0.726201856901995
============rfr============
epoch:  182 pearson: ml_test_pearson:  0.6798153168602105
===============模型average结果==================
epoch:  182 pearson: ml_test_pearson:  0.7211120471282382
[Epoch 183]
[batch 1] cost: 0.5689312 training pearson: 0.8215500532567419
[batch 2] cost: 0.5596838 training pearson: 0.7101746667543155
[batch 3] cost: 0.8183271 training pearson: 0.7193889100146136
[batch 4] cost: 0.5026729 training pearson: 0.7443351804052424
[batch 5] cost: 0.9898877 training pearson: 0.7278379857994606
[batch 6] cost: 0.6083848 training pearson: 0.5694931568453715
[batch 7] cost: 0.80537874 training pearson: 0.8672841994963871
[batch 8] cost: 0.34681943 training pearson: 0.5832957694476595
[batch 9] cost: 0.9742543 training pearson: 0.7538013314220781
[batch 10] cost: 0.60523295 training pearson: 0.6996983560826894
[batch 11] cost: 0.7073961 training pearson: 0.7242922692166377
[batch 12] cost: 0.9725592 training pearson: 0.7024148393740671
[batch 13] cost: 0.73452836 training pearson: 0.6100518656685904
[batch 14] cost: 0.6592359 training pearson: 0.8805244143606806
[batch 15] cost: 0.754345 training pearson: 0.8439419693672509
epoch:  183 pearson: test_pearson:  0.7223061424291672
============gbrt============
epoch:  183 pearson: ml_test_pearson:  0.7301409482307953
============xgb============
epoch:  183 pearson: ml_test_pearson:  0.7332015527517348
============rfr============
epoch:  183 pearson: ml_test_pearson:  0.6968170372140443
===============模型average结果==================
epoch:  183 pearson: ml_test_pearson:  0.7306496640243811
[Epoch 184]
[batch 1] cost: 0.64327073 training pearson: 0.762962440864063
[batch 2] cost: 0.5945964 training pearson: 0.7934848592683439
[batch 3] cost: 0.65860206 training pearson: 0.7168843326171068
[batch 4] cost: 1.0726404 training pearson: 0.7164730894367873
[batch 5] cost: 0.4986158 training pearson: 0.40739352653947764
[batch 6] cost: 0.7302324 training pearson: 0.7027863544069572
[batch 7] cost: 0.4314419 training pearson: 0.4328581728077458
[batch 8] cost: 0.5507091 training pearson: 0.7035761368379272
[batch 9] cost: 0.98511285 training pearson: 0.8054152864995969
[batch 10] cost: 0.67835146 training pearson: 0.7673624354130316
[batch 11] cost: 0.82126117 training pearson: 0.7976262016402219
[batch 12] cost: 0.6953006 training pearson: 0.8101304705039967
[batch 13] cost: 0.6577253 training pearson: 0.7912804548249597
[batch 14] cost: 0.7604142 training pearson: 0.7980256315898622
[batch 15] cost: 0.80326754 training pearson: 0.791596072128683
epoch:  184 pearson: test_pearson:  0.7225571899361317
============gbrt============
epoch:  184 pearson: ml_test_pearson:  0.7109057631572232
============xgb============
epoch:  184 pearson: ml_test_pearson:  0.7334743998846937
============rfr============
epoch:  184 pearson: ml_test_pearson:  0.6942511318118965
===============模型average结果==================
epoch:  184 pearson: ml_test_pearson:  0.7218884563772254
[Epoch 185]
[batch 1] cost: 0.5723784 training pearson: 0.7292645173250856
[batch 2] cost: 0.84367996 training pearson: 0.744639544091592
[batch 3] cost: 0.5328396 training pearson: 0.7197240076072264
[batch 4] cost: 0.5573679 training pearson: 0.610858651210056
[batch 5] cost: 0.7844608 training pearson: 0.7496641370386249
[batch 6] cost: 1.0112745 training pearson: 0.8060981865512536
[batch 7] cost: 0.4642092 training pearson: 0.6798578251888951
[batch 8] cost: 0.6280829 training pearson: 0.7616241765402018
[batch 9] cost: 0.6476866 training pearson: 0.8146467964851712
[batch 10] cost: 0.5501005 training pearson: 0.8149719087857037
[batch 11] cost: 0.68791354 training pearson: 0.704539198684074
[batch 12] cost: 1.0747743 training pearson: 0.5866370893723981
[batch 13] cost: 0.59112734 training pearson: 0.7807019616161188
[batch 14] cost: 0.79822695 training pearson: 0.8142108195827763
[batch 15] cost: 0.7355142 training pearson: 0.7860081660563552
epoch:  185 pearson: test_pearson:  0.723215739723384
============gbrt============
epoch:  185 pearson: ml_test_pearson:  0.7145374490821381
============xgb============
epoch:  185 pearson: ml_test_pearson:  0.7345550217915393
============rfr============
epoch:  185 pearson: ml_test_pearson:  0.6884448243455598
===============模型average结果==================
epoch:  185 pearson: ml_test_pearson:  0.7216810792002076
[Epoch 186]
[batch 1] cost: 0.68145066 training pearson: 0.5921938841939477
[batch 2] cost: 0.6862212 training pearson: 0.877914590968393
[batch 3] cost: 0.61241126 training pearson: 0.7580992452323378
[batch 4] cost: 0.5197661 training pearson: 0.7338402787776868
[batch 5] cost: 0.54785323 training pearson: 0.7254316040046416
[batch 6] cost: 0.88603455 training pearson: 0.5126244100731602
[batch 7] cost: 0.758392 training pearson: 0.8665696111685516
[batch 8] cost: 0.651876 training pearson: 0.75898284127031
[batch 9] cost: 0.63228726 training pearson: 0.8326650581871343
[batch 10] cost: 0.78252983 training pearson: 0.8457734139880569
[batch 11] cost: 0.8150273 training pearson: 0.7109422457391492
[batch 12] cost: 0.9036123 training pearson: 0.6558528902179054
[batch 13] cost: 0.71444076 training pearson: 0.7579231654803597
[batch 14] cost: 0.6859313 training pearson: 0.7995866979458917
[batch 15] cost: 0.6033668 training pearson: 0.6888248353236714
epoch:  186 pearson: test_pearson:  0.7234406805803709
============gbrt============
epoch:  186 pearson: ml_test_pearson:  0.7127317816449955
============xgb============
epoch:  186 pearson: ml_test_pearson:  0.7360837464449033
============rfr============
epoch:  186 pearson: ml_test_pearson:  0.6729946419322177
===============模型average结果==================
epoch:  186 pearson: ml_test_pearson:  0.7141906157283731
[Epoch 187]
[batch 1] cost: 0.99569017 training pearson: 0.6383827625725175
[batch 2] cost: 0.5948599 training pearson: 0.7550793811729949
[batch 3] cost: 1.0335679 training pearson: 0.8140904251295304
[batch 4] cost: 0.58061904 training pearson: 0.7649587280106567
[batch 5] cost: 0.77399534 training pearson: 0.8008235082989872
[batch 6] cost: 1.0926472 training pearson: 0.734618450326247
[batch 7] cost: 0.6324099 training pearson: 0.7367555776036456
[batch 8] cost: 0.7250527 training pearson: 0.7861099046251393
[batch 9] cost: 0.6785122 training pearson: 0.8172279434200039
[batch 10] cost: 0.61075133 training pearson: 0.7464908181925439
[batch 11] cost: 0.5763222 training pearson: 0.824186138549601
[batch 12] cost: 0.5312912 training pearson: 0.751008949591928
[batch 13] cost: 0.4361529 training pearson: 0.6525768563501314
[batch 14] cost: 0.5816868 training pearson: 0.6855778115518751
[batch 15] cost: 0.57462066 training pearson: 0.7453175514622725
epoch:  187 pearson: test_pearson:  0.7232407490013071
============gbrt============
epoch:  187 pearson: ml_test_pearson:  0.7081124454991969
============xgb============
epoch:  187 pearson: ml_test_pearson:  0.7314756530011084
============rfr============
epoch:  187 pearson: ml_test_pearson:  0.6653579204739627
===============模型average结果==================
epoch:  187 pearson: ml_test_pearson:  0.7130718514690889
[Epoch 188]
[batch 1] cost: 0.6578914 training pearson: 0.591749174873418
[batch 2] cost: 0.703795 training pearson: 0.8648587012632052
[batch 3] cost: 0.6997173 training pearson: 0.8225800317437736
[batch 4] cost: 0.68883073 training pearson: 0.5420510515319156
[batch 5] cost: 0.70116323 training pearson: 0.552256227183257
[batch 6] cost: 0.647005 training pearson: 0.8062608152716577
[batch 7] cost: 0.66533923 training pearson: 0.6826870485376126
[batch 8] cost: 0.90230286 training pearson: 0.7931493784436693
[batch 9] cost: 0.7939276 training pearson: 0.831667570804744
[batch 10] cost: 0.81814855 training pearson: 0.7223330246769072
[batch 11] cost: 0.5840141 training pearson: 0.8579196614066241
[batch 12] cost: 0.46990916 training pearson: 0.7397732882836241
[batch 13] cost: 0.7051915 training pearson: 0.6920655872858265
[batch 14] cost: 0.58485395 training pearson: 0.7693492780923482
[batch 15] cost: 0.7481253 training pearson: 0.7190578834715275
epoch:  188 pearson: test_pearson:  0.7237559178909367
============gbrt============
epoch:  188 pearson: ml_test_pearson:  0.7290481932374867
============xgb============
epoch:  188 pearson: ml_test_pearson:  0.736034781425102
============rfr============
epoch:  188 pearson: ml_test_pearson:  0.6915748529436608
===============模型average结果==================
epoch:  188 pearson: ml_test_pearson:  0.7282480668901778
[Epoch 189]
[batch 1] cost: 0.7396129 training pearson: 0.7854695751851385
[batch 2] cost: 0.511914 training pearson: 0.7676797722167158
[batch 3] cost: 0.78363615 training pearson: 0.6808820923277803
[batch 4] cost: 0.7501836 training pearson: 0.6640716177138396
[batch 5] cost: 0.5260069 training pearson: 0.8291162073526402
[batch 6] cost: 0.7932564 training pearson: 0.8229607514899736
[batch 7] cost: 0.870787 training pearson: 0.7496652512158273
[batch 8] cost: 0.8470684 training pearson: 0.819821600210496
[batch 9] cost: 0.54410285 training pearson: 0.6992364533200779
[batch 10] cost: 1.0740077 training pearson: 0.6769189480645684
[batch 11] cost: 0.70509344 training pearson: 0.6951453651701195
[batch 12] cost: 0.60366106 training pearson: 0.7181542797306874
[batch 13] cost: 0.49899957 training pearson: 0.7392857426149283
[batch 14] cost: 0.4194764 training pearson: 0.7740557427534741
[batch 15] cost: 0.668142 training pearson: 0.8139559812297945
epoch:  189 pearson: test_pearson:  0.7240981475582108
============gbrt============
epoch:  189 pearson: ml_test_pearson:  0.7202519577020892
============xgb============
epoch:  189 pearson: ml_test_pearson:  0.7330111368604056
============rfr============
epoch:  189 pearson: ml_test_pearson:  0.6743169141768827
===============模型average结果==================
epoch:  189 pearson: ml_test_pearson:  0.7169121086007485
[Epoch 190]
[batch 1] cost: 0.4594664 training pearson: 0.7747820132294144
[batch 2] cost: 1.0580473 training pearson: 0.7878730560066377
[batch 3] cost: 0.8152101 training pearson: 0.7139070216667411
[batch 4] cost: 0.5728941 training pearson: 0.7520330859756265
[batch 5] cost: 1.0007734 training pearson: 0.48224729851200526
[batch 6] cost: 0.64632964 training pearson: 0.726470101135637
[batch 7] cost: 0.6910957 training pearson: 0.7999193336664051
[batch 8] cost: 0.43889603 training pearson: 0.7498126041882153
[batch 9] cost: 0.7110483 training pearson: 0.7484583625752587
[batch 10] cost: 0.46199852 training pearson: 0.8507138249015679
[batch 11] cost: 0.66058576 training pearson: 0.8301903891901162
[batch 12] cost: 0.6745131 training pearson: 0.7698878946049743
[batch 13] cost: 0.58173037 training pearson: 0.7262237274636199
[batch 14] cost: 0.9399008 training pearson: 0.8223395221737326
[batch 15] cost: 0.6183041 training pearson: 0.7013095551095964
epoch:  190 pearson: test_pearson:  0.7240861824618858
============gbrt============
epoch:  190 pearson: ml_test_pearson:  0.7250316375389787
============xgb============
epoch:  190 pearson: ml_test_pearson:  0.7235774297718831
============rfr============
epoch:  190 pearson: ml_test_pearson:  0.6989527434930736
===============模型average结果==================
epoch:  190 pearson: ml_test_pearson:  0.7271075529846412
[Epoch 191]
[batch 1] cost: 0.6428666 training pearson: 0.6644985183579433
[batch 2] cost: 0.92430085 training pearson: 0.7944491386126887
[batch 3] cost: 0.84796906 training pearson: 0.44442467151313836
[batch 4] cost: 0.68833697 training pearson: 0.7564853826208715
[batch 5] cost: 0.6096918 training pearson: 0.8086228014791316
[batch 6] cost: 0.7022643 training pearson: 0.812530626132704
[batch 7] cost: 0.82132316 training pearson: 0.5622122928212676
[batch 8] cost: 0.52018297 training pearson: 0.8262305042992961
[batch 9] cost: 0.7157018 training pearson: 0.8482560307139965
[batch 10] cost: 0.54003054 training pearson: 0.7070352967372171
[batch 11] cost: 0.5243612 training pearson: 0.7909410566687894
[batch 12] cost: 0.8124821 training pearson: 0.7888443213545908
[batch 13] cost: 0.71878624 training pearson: 0.8627867366440878
[batch 14] cost: 0.63395536 training pearson: 0.7868001847392294
[batch 15] cost: 0.57077444 training pearson: 0.7056785543674708
epoch:  191 pearson: test_pearson:  0.7244275561099309
============gbrt============
epoch:  191 pearson: ml_test_pearson:  0.7200153057307414
============xgb============
epoch:  191 pearson: ml_test_pearson:  0.7180484882997893
============rfr============
epoch:  191 pearson: ml_test_pearson:  0.6838181975817442
===============模型average结果==================
epoch:  191 pearson: ml_test_pearson:  0.7196379532832706
[Epoch 192]
[batch 1] cost: 0.82101196 training pearson: 0.8469818692611217
[batch 2] cost: 0.9022385 training pearson: 0.7902201335881741
[batch 3] cost: 0.58838105 training pearson: 0.701985733026625
[batch 4] cost: 0.5363163 training pearson: 0.8286778936660962
[batch 5] cost: 0.7318219 training pearson: 0.6200476280203879
[batch 6] cost: 0.34742087 training pearson: 0.601715817956547
[batch 7] cost: 0.8108986 training pearson: 0.7769621461904258
[batch 8] cost: 0.52120095 training pearson: 0.7122956141559805
[batch 9] cost: 0.77368975 training pearson: 0.703664837110559
[batch 10] cost: 0.77004886 training pearson: 0.5972202261575484
[batch 11] cost: 0.7702294 training pearson: 0.8560960211548495
[batch 12] cost: 0.8229853 training pearson: 0.7314309246181774
[batch 13] cost: 0.59577966 training pearson: 0.7303447281994706
[batch 14] cost: 0.5526986 training pearson: 0.7411265334722207
[batch 15] cost: 0.7327682 training pearson: 0.7777658690922398
epoch:  192 pearson: test_pearson:  0.7232684704789843
============gbrt============
epoch:  192 pearson: ml_test_pearson:  0.7239274463924956
============xgb============
epoch:  192 pearson: ml_test_pearson:  0.7155079666505898
============rfr============
epoch:  192 pearson: ml_test_pearson:  0.7014274826842262
===============模型average结果==================
epoch:  192 pearson: ml_test_pearson:  0.7253085201365008
[Epoch 193]
[batch 1] cost: 0.7009038 training pearson: 0.8250803018538345
[batch 2] cost: 0.7082018 training pearson: 0.7386327168525747
[batch 3] cost: 0.848722 training pearson: 0.7909811796627095
[batch 4] cost: 0.46900436 training pearson: 0.7821829014800153
[batch 5] cost: 0.6001347 training pearson: 0.7779350229690062
[batch 6] cost: 0.6549877 training pearson: 0.7615980960637425
[batch 7] cost: 0.76239705 training pearson: 0.8131901013288573
[batch 8] cost: 0.7094623 training pearson: 0.5275550344698143
[batch 9] cost: 0.71413237 training pearson: 0.8062052799208521
[batch 10] cost: 0.73316103 training pearson: 0.7113177426234696
[batch 11] cost: 0.9338179 training pearson: 0.7280058765774415
[batch 12] cost: 0.6809033 training pearson: 0.7419840220145457
[batch 13] cost: 0.7448021 training pearson: 0.6571599803816472
[batch 14] cost: 0.41966996 training pearson: 0.7654895737804359
[batch 15] cost: 0.58967626 training pearson: 0.8470083239915969
epoch:  193 pearson: test_pearson:  0.7244358470618318
============gbrt============
epoch:  193 pearson: ml_test_pearson:  0.7112340145948708
============xgb============
epoch:  193 pearson: ml_test_pearson:  0.7187123299521684
============rfr============
epoch:  193 pearson: ml_test_pearson:  0.6777666204172325
===============模型average结果==================
epoch:  193 pearson: ml_test_pearson:  0.7106227514943678
[Epoch 194]
[batch 1] cost: 0.84414816 training pearson: 0.7164385252670638
[batch 2] cost: 0.6373015 training pearson: 0.8499180162098374
[batch 3] cost: 0.8116575 training pearson: 0.8366497512123038
[batch 4] cost: 0.6862819 training pearson: 0.7844679212206271
[batch 5] cost: 0.5546747 training pearson: 0.5925768493902286
[batch 6] cost: 0.7015048 training pearson: 0.7831762908740989
[batch 7] cost: 0.7190748 training pearson: 0.796839692478354
[batch 8] cost: 0.7819881 training pearson: 0.6693805738380123
[batch 9] cost: 0.6266467 training pearson: 0.7361023058136529
[batch 10] cost: 0.396651 training pearson: 0.7675901671012977
[batch 11] cost: 0.79868454 training pearson: 0.8038170162574967
[batch 12] cost: 0.6500168 training pearson: 0.7038132071675611
[batch 13] cost: 0.6367032 training pearson: 0.7953978379318212
[batch 14] cost: 0.50714195 training pearson: 0.6562184879152736
[batch 15] cost: 0.79649293 training pearson: 0.7750017360993464
epoch:  194 pearson: test_pearson:  0.7245607454714053
============gbrt============
epoch:  194 pearson: ml_test_pearson:  0.7236652952140983
============xgb============
epoch:  194 pearson: ml_test_pearson:  0.7136963147518363
============rfr============
epoch:  194 pearson: ml_test_pearson:  0.7043451852495093
===============模型average结果==================
epoch:  194 pearson: ml_test_pearson:  0.7265782084218793
[Epoch 195]
[batch 1] cost: 0.7624382 training pearson: 0.7439319801541507
[batch 2] cost: 0.98047507 training pearson: 0.8393573380231109
[batch 3] cost: 0.6033638 training pearson: 0.790875254909676
[batch 4] cost: 0.6314815 training pearson: 0.6709714843443289
[batch 5] cost: 0.70184004 training pearson: 0.6897395809825324
[batch 6] cost: 0.63994 training pearson: 0.7110977277000762
[batch 7] cost: 0.90673655 training pearson: 0.7892590341537725
[batch 8] cost: 0.7365505 training pearson: 0.564764687484783
[batch 9] cost: 0.5166492 training pearson: 0.7763171204913943
[batch 10] cost: 0.7550608 training pearson: 0.8402583111865166
[batch 11] cost: 0.63953936 training pearson: 0.7334828567484418
[batch 12] cost: 0.5314071 training pearson: 0.7388088080167801
[batch 13] cost: 0.45107123 training pearson: 0.8515048005814845
[batch 14] cost: 0.8846996 training pearson: 0.7200451397401995
[batch 15] cost: 0.49303848 training pearson: 0.7489259982286871
epoch:  195 pearson: test_pearson:  0.7251983554577822
============gbrt============
epoch:  195 pearson: ml_test_pearson:  0.7037757997087913
============xgb============
epoch:  195 pearson: ml_test_pearson:  0.7205575850851101
============rfr============
epoch:  195 pearson: ml_test_pearson:  0.6686507932357145
===============模型average结果==================
epoch:  195 pearson: ml_test_pearson:  0.705184378267006
[Epoch 196]
[batch 1] cost: 0.454867 training pearson: 0.7771367995418561
[batch 2] cost: 0.84268105 training pearson: 0.7700352119186418
[batch 3] cost: 0.8359829 training pearson: 0.7498780553134264
[batch 4] cost: 0.9725348 training pearson: 0.78855694684632
[batch 5] cost: 0.7561667 training pearson: 0.6447393589042244
[batch 6] cost: 0.68671227 training pearson: 0.6175471318885343
[batch 7] cost: 0.50188917 training pearson: 0.802905216423504
[batch 8] cost: 0.6811776 training pearson: 0.6180041445237494
[batch 9] cost: 0.54691464 training pearson: 0.7518967607181909
[batch 10] cost: 0.5466538 training pearson: 0.6023837126244713
[batch 11] cost: 0.45972824 training pearson: 0.5981738038964739
[batch 12] cost: 0.9886596 training pearson: 0.7639578173902342
[batch 13] cost: 0.72759277 training pearson: 0.8774992961025404
[batch 14] cost: 0.6828941 training pearson: 0.8225765971055063
[batch 15] cost: 0.48335317 training pearson: 0.723973499344144
epoch:  196 pearson: test_pearson:  0.7241276109492071
============gbrt============
epoch:  196 pearson: ml_test_pearson:  0.7158235189134491
============xgb============
epoch:  196 pearson: ml_test_pearson:  0.7157354004148772
============rfr============
epoch:  196 pearson: ml_test_pearson:  0.6828241154537864
===============模型average结果==================
epoch:  196 pearson: ml_test_pearson:  0.7157164056778395
[Epoch 197]
[batch 1] cost: 0.7177348 training pearson: 0.8245830719832649
[batch 2] cost: 0.87072206 training pearson: 0.7994911137010495
[batch 3] cost: 0.89673376 training pearson: 0.7527008016700119
[batch 4] cost: 0.66144514 training pearson: 0.8256846089362985
[batch 5] cost: 0.5410823 training pearson: 0.5807742560176612
[batch 6] cost: 0.5652454 training pearson: 0.7913892792696483
[batch 7] cost: 0.55984 training pearson: 0.7323406912426275
[batch 8] cost: 0.5825205 training pearson: 0.7134861706193457
[batch 9] cost: 0.72323096 training pearson: 0.6910954805380413
[batch 10] cost: 0.81499666 training pearson: 0.7687429511025382
[batch 11] cost: 0.66198164 training pearson: 0.7413998124081475
[batch 12] cost: 0.38309538 training pearson: 0.7334221253913655
[batch 13] cost: 0.4931605 training pearson: 0.7202402096567816
[batch 14] cost: 0.8700254 training pearson: 0.7399522853189516
[batch 15] cost: 0.8567736 training pearson: 0.7405682272363988
epoch:  197 pearson: test_pearson:  0.7242538953534099
============gbrt============
epoch:  197 pearson: ml_test_pearson:  0.723129002396949
============xgb============
epoch:  197 pearson: ml_test_pearson:  0.7263305639329617
============rfr============
epoch:  197 pearson: ml_test_pearson:  0.6733316968398515
===============模型average结果==================
epoch:  197 pearson: ml_test_pearson:  0.7156809814163665
[Epoch 198]
[batch 1] cost: 0.43665382 training pearson: 0.7075718005746313
[batch 2] cost: 0.6956827 training pearson: 0.8221714951927378
[batch 3] cost: 0.47557876 training pearson: 0.7982376577797955
[batch 4] cost: 0.41664448 training pearson: 0.8095261356407456
[batch 5] cost: 0.8664406 training pearson: 0.680760064395339
[batch 6] cost: 0.5528817 training pearson: 0.6783252651994912
[batch 7] cost: 0.5140932 training pearson: 0.8030313998009799
[batch 8] cost: 0.48112977 training pearson: 0.7505198404880842
[batch 9] cost: 0.60330325 training pearson: 0.7835117782446127
[batch 10] cost: 0.9067149 training pearson: 0.6191057652617126
[batch 11] cost: 0.65950376 training pearson: 0.8121785464271778
[batch 12] cost: 0.8444389 training pearson: 0.8388961264664468
[batch 13] cost: 1.0366044 training pearson: 0.6281140338680908
[batch 14] cost: 0.99250394 training pearson: 0.7679622923695921
[batch 15] cost: 0.595498 training pearson: 0.7777744080288442
epoch:  198 pearson: test_pearson:  0.7236260482687593
============gbrt============
epoch:  198 pearson: ml_test_pearson:  0.7119735518333902
============xgb============
epoch:  198 pearson: ml_test_pearson:  0.7026150032725148
============rfr============
epoch:  198 pearson: ml_test_pearson:  0.7026419236127324
===============模型average结果==================
epoch:  198 pearson: ml_test_pearson:  0.7193904659328743
[Epoch 199]
[batch 1] cost: 1.1317883 training pearson: 0.7238885021322352
[batch 2] cost: 0.7492296 training pearson: 0.7592151265338798
[batch 3] cost: 0.58939207 training pearson: 0.6800560669252778
[batch 4] cost: 0.6220419 training pearson: 0.7395311840861415
[batch 5] cost: 0.6526666 training pearson: 0.8014124000258014
[batch 6] cost: 0.6067906 training pearson: 0.8112907808156565
[batch 7] cost: 0.6148384 training pearson: 0.8130202934058477
[batch 8] cost: 0.5913516 training pearson: 0.715055452451684
[batch 9] cost: 0.6105578 training pearson: 0.8120734134129962
[batch 10] cost: 0.96498704 training pearson: 0.7309215900431164
[batch 11] cost: 0.49445832 training pearson: 0.8102585292048079
[batch 12] cost: 0.62514424 training pearson: 0.6826561857097779
[batch 13] cost: 0.67169815 training pearson: 0.6924743890289844
[batch 14] cost: 0.5236135 training pearson: 0.7980214574786935
[batch 15] cost: 0.6437781 training pearson: 0.7291278925558488
epoch:  199 pearson: test_pearson:  0.722398842872396
============gbrt============
epoch:  199 pearson: ml_test_pearson:  0.6945606216336647
============xgb============
epoch:  199 pearson: ml_test_pearson:  0.6897375105777158
============rfr============
epoch:  199 pearson: ml_test_pearson:  0.6685096996261282
===============模型average结果==================
epoch:  199 pearson: ml_test_pearson:  0.6931150797068945
[Epoch 200]
[batch 1] cost: 0.68603045 training pearson: 0.7091361176074789
[batch 2] cost: 1.0612537 training pearson: 0.6251601512969991
[batch 3] cost: 0.5705992 training pearson: 0.7655126547246005
[batch 4] cost: 0.6676516 training pearson: 0.8448654628066266
[batch 5] cost: 0.6927492 training pearson: 0.7427119129887217
[batch 6] cost: 0.77353686 training pearson: 0.7369101672503925
[batch 7] cost: 0.52887976 training pearson: 0.80972899598727
[batch 8] cost: 0.7203167 training pearson: 0.734732792189564
[batch 9] cost: 0.9525207 training pearson: 0.7873695140902591
[batch 10] cost: 0.74376607 training pearson: 0.7889875119078295
[batch 11] cost: 0.81522864 training pearson: 0.7165153808823813
[batch 12] cost: 0.3637873 training pearson: 0.7558151208656175
[batch 13] cost: 0.67744493 training pearson: 0.827829294221413
[batch 14] cost: 0.41523892 training pearson: 0.6364586287374198
[batch 15] cost: 0.53641224 training pearson: 0.6863862479564962
epoch:  200 pearson: test_pearson:  0.7246779603907677
============gbrt============
epoch:  200 pearson: ml_test_pearson:  0.7090606857205957
============xgb============
epoch:  200 pearson: ml_test_pearson:  0.6904285961451101
============rfr============
epoch:  200 pearson: ml_test_pearson:  0.6660544919058202
===============模型average结果==================
epoch:  200 pearson: ml_test_pearson:  0.7028079040886709
[Epoch 201]
[batch 1] cost: 0.88768655 training pearson: 0.7070232857889782
[batch 2] cost: 0.8007214 training pearson: 0.8002085539608174
[batch 3] cost: 0.7178891 training pearson: 0.742965735378754
[batch 4] cost: 0.79729444 training pearson: 0.639055782677859
[batch 5] cost: 0.55754924 training pearson: 0.8001598801977037
[batch 6] cost: 0.82292604 training pearson: 0.6321495163949142
[batch 7] cost: 0.59073514 training pearson: 0.6436585629589471
[batch 8] cost: 0.77830374 training pearson: 0.7810496903809189
[batch 9] cost: 0.69337565 training pearson: 0.7755465637715783
[batch 10] cost: 0.43758267 training pearson: 0.8376691154220922
[batch 11] cost: 0.54427075 training pearson: 0.8257010071025762
[batch 12] cost: 0.50518167 training pearson: 0.7391702384408958
[batch 13] cost: 0.82918566 training pearson: 0.7393200131752005
[batch 14] cost: 0.65081316 training pearson: 0.8496294803731687
[batch 15] cost: 0.42661798 training pearson: 0.63360389526774
epoch:  201 pearson: test_pearson:  0.7246217552491666
============gbrt============
epoch:  201 pearson: ml_test_pearson:  0.6980507867315543
============xgb============
epoch:  201 pearson: ml_test_pearson:  0.7118073349012581
============rfr============
epoch:  201 pearson: ml_test_pearson:  0.6637080130018983
===============模型average结果==================
epoch:  201 pearson: ml_test_pearson:  0.699256284713434
[Epoch 202]
[batch 1] cost: 0.78240526 training pearson: 0.7218185989479147
[batch 2] cost: 0.7691132 training pearson: 0.7673156088774059
[batch 3] cost: 0.65035546 training pearson: 0.8240331906170449
[batch 4] cost: 0.73313636 training pearson: 0.6258484988863569
[batch 5] cost: 0.9666576 training pearson: 0.7811023043864396
[batch 6] cost: 0.5328424 training pearson: 0.6625896587485418
[batch 7] cost: 0.66844934 training pearson: 0.7720342859418979
[batch 8] cost: 0.57599056 training pearson: 0.7282417969115347
[batch 9] cost: 0.5476496 training pearson: 0.7552291642304992
[batch 10] cost: 0.4848565 training pearson: 0.8778979355080847
[batch 11] cost: 0.62585795 training pearson: 0.7149221603149586
[batch 12] cost: 0.80659604 training pearson: 0.77186413140439
[batch 13] cost: 0.4067466 training pearson: 0.810946927842869
[batch 14] cost: 0.66080475 training pearson: 0.6618550982340268
[batch 15] cost: 0.77316207 training pearson: 0.8126117159075991
epoch:  202 pearson: test_pearson:  0.7243560602196285
============gbrt============
epoch:  202 pearson: ml_test_pearson:  0.7044267013074562
============xgb============
epoch:  202 pearson: ml_test_pearson:  0.7068554776957136
============rfr============
epoch:  202 pearson: ml_test_pearson:  0.6709255827112024
===============模型average结果==================
epoch:  202 pearson: ml_test_pearson:  0.7071744795358392
[Epoch 203]
[batch 1] cost: 0.7310663 training pearson: 0.7738434159606161
[batch 2] cost: 0.50863594 training pearson: 0.8495561868803956
[batch 3] cost: 0.5991611 training pearson: 0.7081947256237896
[batch 4] cost: 0.7922423 training pearson: 0.7710736357215774
[batch 5] cost: 0.82219833 training pearson: 0.8039020780726173
[batch 6] cost: 0.8942186 training pearson: 0.7547926155493851
[batch 7] cost: 0.7506871 training pearson: 0.7796827323096444
[batch 8] cost: 0.62641656 training pearson: 0.678898546338036
[batch 9] cost: 0.48072845 training pearson: 0.6912679122261278
[batch 10] cost: 0.33515635 training pearson: 0.769583515328469
[batch 11] cost: 0.76678663 training pearson: 0.8557938990339036
[batch 12] cost: 0.7695563 training pearson: 0.7596450183951797
[batch 13] cost: 0.73552984 training pearson: 0.7285914949775862
[batch 14] cost: 0.3701506 training pearson: 0.611097520488051
[batch 15] cost: 0.8368927 training pearson: 0.7351492756599546
epoch:  203 pearson: test_pearson:  0.7234949933195199
============gbrt============
epoch:  203 pearson: ml_test_pearson:  0.6645768986862292
============xgb============
epoch:  203 pearson: ml_test_pearson:  0.7045495878481826
============rfr============
epoch:  203 pearson: ml_test_pearson:  0.6437615484149916
===============模型average结果==================
epoch:  203 pearson: ml_test_pearson:  0.6752572340974732
[Epoch 204]
[batch 1] cost: 0.74046004 training pearson: 0.8106735002081703
[batch 2] cost: 0.30301943 training pearson: 0.7959652046901761
[batch 3] cost: 0.49407333 training pearson: 0.5395641979776689
[batch 4] cost: 0.96474326 training pearson: 0.8175487395812983
[batch 5] cost: 0.6357534 training pearson: 0.7883817956354017
[batch 6] cost: 0.52930933 training pearson: 0.7090053030809181
[batch 7] cost: 0.5731356 training pearson: 0.5711213819990316
[batch 8] cost: 0.7972134 training pearson: 0.8316817002397825
[batch 9] cost: 0.64966154 training pearson: 0.777097828814814
[batch 10] cost: 0.9444534 training pearson: 0.7390816297696177
[batch 11] cost: 0.5470443 training pearson: 0.6299806753744793
[batch 12] cost: 0.5660991 training pearson: 0.819972049366217
[batch 13] cost: 0.56801224 training pearson: 0.7936673210269478
[batch 14] cost: 0.81118715 training pearson: 0.7738485060110869
[batch 15] cost: 0.8592848 training pearson: 0.6054270987612537
epoch:  204 pearson: test_pearson:  0.724747259607717
============gbrt============
epoch:  204 pearson: ml_test_pearson:  0.6980978540536895
============xgb============
epoch:  204 pearson: ml_test_pearson:  0.7114896873621421
============rfr============
epoch:  204 pearson: ml_test_pearson:  0.6594630142576544
===============模型average结果==================
epoch:  204 pearson: ml_test_pearson:  0.6997408042438312
[Epoch 205]
[batch 1] cost: 0.6921995 training pearson: 0.6590281927933577
[batch 2] cost: 0.6114842 training pearson: 0.854517721650995
[batch 3] cost: 0.81764376 training pearson: 0.7958029655361287
[batch 4] cost: 0.5698995 training pearson: 0.7258050480708108
[batch 5] cost: 0.7244919 training pearson: 0.8040870030121087
[batch 6] cost: 0.5779432 training pearson: 0.7993945108182944
[batch 7] cost: 0.51708066 training pearson: 0.4557268623220785
[batch 8] cost: 0.80709654 training pearson: 0.8233548553596967
[batch 9] cost: 0.90615344 training pearson: 0.6402089517507557
[batch 10] cost: 0.595669 training pearson: 0.6990677276093111
[batch 11] cost: 0.84217256 training pearson: 0.7845635800353096
[batch 12] cost: 0.43943012 training pearson: 0.7157478798113557
[batch 13] cost: 0.8770844 training pearson: 0.7495288198224735
[batch 14] cost: 0.44143692 training pearson: 0.8373394137035367
[batch 15] cost: 0.526146 training pearson: 0.7650071384421159
epoch:  205 pearson: test_pearson:  0.7251430751972532
============gbrt============
epoch:  205 pearson: ml_test_pearson:  0.7106913720619458
============xgb============
epoch:  205 pearson: ml_test_pearson:  0.7138193301338016
============rfr============
epoch:  205 pearson: ml_test_pearson:  0.6755630768105758
===============模型average结果==================
epoch:  205 pearson: ml_test_pearson:  0.7145850741400045
[Epoch 206]
[batch 1] cost: 0.75402814 training pearson: 0.5556033471062594
[batch 2] cost: 0.7160092 training pearson: 0.6092008990414649
[batch 3] cost: 0.7349448 training pearson: 0.8035800338675596
[batch 4] cost: 0.7996704 training pearson: 0.6659858672934077
[batch 5] cost: 0.6234339 training pearson: 0.7513271900866857
[batch 6] cost: 0.6400753 training pearson: 0.8444471383728896
[batch 7] cost: 0.70930403 training pearson: 0.7799536136173308
[batch 8] cost: 0.5160797 training pearson: 0.7537172050354175
[batch 9] cost: 0.6695273 training pearson: 0.7847535911622215
[batch 10] cost: 0.44359887 training pearson: 0.7968070272491294
[batch 11] cost: 0.597121 training pearson: 0.8590416647571574
[batch 12] cost: 0.78333783 training pearson: 0.7346618371360519
[batch 13] cost: 0.5606032 training pearson: 0.786300303574722
[batch 14] cost: 0.75815094 training pearson: 0.7786312358258499
[batch 15] cost: 0.5781206 training pearson: 0.7359853967576923
epoch:  206 pearson: test_pearson:  0.72798261556881
============gbrt============
epoch:  206 pearson: ml_test_pearson:  0.724926355686458
============xgb============
epoch:  206 pearson: ml_test_pearson:  0.7235560386104972
============rfr============
epoch:  206 pearson: ml_test_pearson:  0.6935391957364917
===============模型average结果==================
epoch:  206 pearson: ml_test_pearson:  0.7247927652844232
[Epoch 207]
[batch 1] cost: 0.7447229 training pearson: 0.7631743934859284
[batch 2] cost: 0.6411287 training pearson: 0.7788166196789706
[batch 3] cost: 0.7529328 training pearson: 0.7583224927302247
[batch 4] cost: 0.9147693 training pearson: 0.8577401359292294
[batch 5] cost: 0.64456224 training pearson: 0.8097291149141881
[batch 6] cost: 1.0286267 training pearson: 0.7734545398553399
[batch 7] cost: 0.62499213 training pearson: 0.7717394430026134
[batch 8] cost: 0.3973341 training pearson: 0.7569118887180319
[batch 9] cost: 0.54960257 training pearson: 0.7556363297951031
[batch 10] cost: 0.46042523 training pearson: 0.7436267677605372
[batch 11] cost: 0.83691823 training pearson: 0.7369439270821124
[batch 12] cost: 0.6092722 training pearson: 0.7585347773504958
[batch 13] cost: 0.50825644 training pearson: 0.6840945754124782
[batch 14] cost: 0.3425833 training pearson: 0.6952795518773813
[batch 15] cost: 0.7781111 training pearson: 0.6539030021187016
epoch:  207 pearson: test_pearson:  0.7269419068818516
============gbrt============
epoch:  207 pearson: ml_test_pearson:  0.7002799716352325
============xgb============
epoch:  207 pearson: ml_test_pearson:  0.7102396287822771
============rfr============
epoch:  207 pearson: ml_test_pearson:  0.6862885801316615
===============模型average结果==================
epoch:  207 pearson: ml_test_pearson:  0.7078674757724481
[Epoch 208]
[batch 1] cost: 0.87599474 training pearson: 0.7378295962071925
[batch 2] cost: 0.6492102 training pearson: 0.7932185011538107
[batch 3] cost: 0.73919463 training pearson: 0.8070991561101312
[batch 4] cost: 0.71567947 training pearson: 0.7836061800501622
[batch 5] cost: 0.6160196 training pearson: 0.7705200538873396
[batch 6] cost: 0.59238017 training pearson: 0.6482191244495165
[batch 7] cost: 0.6470772 training pearson: 0.7140308123106428
[batch 8] cost: 0.75000113 training pearson: 0.7324579499149371
[batch 9] cost: 0.75141716 training pearson: 0.7710950231432511
[batch 10] cost: 0.4745858 training pearson: 0.8559821565648434
[batch 11] cost: 0.5230677 training pearson: 0.6709471057897498
[batch 12] cost: 0.59267837 training pearson: 0.6390575708410968
[batch 13] cost: 0.7519133 training pearson: 0.7979726183841985
[batch 14] cost: 0.634173 training pearson: 0.8184195352085777
[batch 15] cost: 0.55066776 training pearson: 0.7283381495157576
epoch:  208 pearson: test_pearson:  0.7301733153798152
============gbrt============
epoch:  208 pearson: ml_test_pearson:  0.7150709795758533
============xgb============
epoch:  208 pearson: ml_test_pearson:  0.7460757049337208
============rfr============
epoch:  208 pearson: ml_test_pearson:  0.657082646176447
===============模型average结果==================
epoch:  208 pearson: ml_test_pearson:  0.7105578518366059
[Epoch 209]
[batch 1] cost: 0.58880967 training pearson: 0.7597185421205389
[batch 2] cost: 0.4453334 training pearson: 0.6863940737810704
[batch 3] cost: 0.62809664 training pearson: 0.6902852117870225
[batch 4] cost: 0.9762039 training pearson: 0.7804794781269205
[batch 5] cost: 0.7697931 training pearson: 0.745459099200882
[batch 6] cost: 0.45930886 training pearson: 0.7419842716035423
[batch 7] cost: 0.5385051 training pearson: 0.7925110404740964
[batch 8] cost: 0.5434758 training pearson: 0.7059056111284711
[batch 9] cost: 1.1231182 training pearson: 0.7006656968575282
[batch 10] cost: 0.3783632 training pearson: 0.8332995083657795
[batch 11] cost: 0.65589845 training pearson: 0.7192621341562752
[batch 12] cost: 0.79180527 training pearson: 0.8073351387354054
[batch 13] cost: 0.7618724 training pearson: 0.7593036483933927
[batch 14] cost: 0.48152742 training pearson: 0.7267918376335825
[batch 15] cost: 0.78850037 training pearson: 0.7178219417160768
epoch:  209 pearson: test_pearson:  0.7195008540941596
============gbrt============
epoch:  209 pearson: ml_test_pearson:  0.6909253741149292
============xgb============
epoch:  209 pearson: ml_test_pearson:  0.695231813611468
============rfr============
epoch:  209 pearson: ml_test_pearson:  0.6631948679235602
===============模型average结果==================
epoch:  209 pearson: ml_test_pearson:  0.6955810223211718
[Epoch 210]
[batch 1] cost: 0.52232283 training pearson: 0.7867032858494138
[batch 2] cost: 0.6748097 training pearson: 0.7808756803780903
[batch 3] cost: 0.8729347 training pearson: 0.6226533778110506
[batch 4] cost: 0.80983 training pearson: 0.7687846987290923
[batch 5] cost: 0.6514961 training pearson: 0.8354438412086077
[batch 6] cost: 0.52941597 training pearson: 0.6903377582419408
[batch 7] cost: 0.45779687 training pearson: 0.6541877351051222
[batch 8] cost: 0.8887213 training pearson: 0.7914908458775246
[batch 9] cost: 0.52161753 training pearson: 0.7610026509546518
[batch 10] cost: 0.607161 training pearson: 0.8157166339371588
[batch 11] cost: 0.71351355 training pearson: 0.5316780736419368
[batch 12] cost: 0.6303081 training pearson: 0.7446322154915507
[batch 13] cost: 0.79168683 training pearson: 0.7991017409392615
[batch 14] cost: 0.7466498 training pearson: 0.7117368488035108
[batch 15] cost: 0.5987124 training pearson: 0.8058891748562006
epoch:  210 pearson: test_pearson:  0.7197322394467657
============gbrt============
epoch:  210 pearson: ml_test_pearson:  0.664593041510435
============xgb============
epoch:  210 pearson: ml_test_pearson:  0.7002857921358067
============rfr============
epoch:  210 pearson: ml_test_pearson:  0.6502410996026394
===============模型average结果==================
epoch:  210 pearson: ml_test_pearson:  0.6816824438905124
[Epoch 211]
[batch 1] cost: 0.6783324 training pearson: 0.8475049299611511
[batch 2] cost: 0.7785084 training pearson: 0.6848525766295129
[batch 3] cost: 0.50858235 training pearson: 0.5887815642983968
[batch 4] cost: 0.7321732 training pearson: 0.787486792475738
[batch 5] cost: 0.57668996 training pearson: 0.6631130030175321
[batch 6] cost: 0.81360924 training pearson: 0.789993645104939
[batch 7] cost: 0.61806977 training pearson: 0.779862597560295
[batch 8] cost: 0.7089664 training pearson: 0.8241446092544622
[batch 9] cost: 0.9318534 training pearson: 0.5778475992465018
[batch 10] cost: 0.87395173 training pearson: 0.7074056873811096
[batch 11] cost: 0.5513348 training pearson: 0.8340792750983534
[batch 12] cost: 0.3441476 training pearson: 0.8423063526840008
[batch 13] cost: 0.40217525 training pearson: 0.7201288282401561
[batch 14] cost: 0.7484089 training pearson: 0.6976619775675861
[batch 15] cost: 0.80956876 training pearson: 0.7432422804101857
epoch:  211 pearson: test_pearson:  0.7198263871867667
============gbrt============
epoch:  211 pearson: ml_test_pearson:  0.6786620136444789
============xgb============
epoch:  211 pearson: ml_test_pearson:  0.6891312174446862
============rfr============
epoch:  211 pearson: ml_test_pearson:  0.643443198345327
===============模型average结果==================
epoch:  211 pearson: ml_test_pearson:  0.6826100693320104
[Epoch 212]
[batch 1] cost: 0.6794376 training pearson: 0.6897861445724336
[batch 2] cost: 0.7685599 training pearson: 0.7640615203743286
[batch 3] cost: 0.6658667 training pearson: 0.6622149319241233
[batch 4] cost: 0.71454024 training pearson: 0.7295326471417245
[batch 5] cost: 0.53745496 training pearson: 0.8065871675671026
[batch 6] cost: 0.85025144 training pearson: 0.7072295633908094
[batch 7] cost: 0.74414843 training pearson: 0.7083271570086913
[batch 8] cost: 0.6288169 training pearson: 0.7545185899785898
[batch 9] cost: 0.5525153 training pearson: 0.8147428483612041
[batch 10] cost: 0.5889734 training pearson: 0.7610997182250536
[batch 11] cost: 0.53286827 training pearson: 0.6669582793753476
[batch 12] cost: 0.68997955 training pearson: 0.8401664661151794
[batch 13] cost: 0.7870762 training pearson: 0.8215680626502252
[batch 14] cost: 0.63602847 training pearson: 0.6696092425753665
[batch 15] cost: 0.5835542 training pearson: 0.734966368431731
epoch:  212 pearson: test_pearson:  0.7229700334754885
============gbrt============
epoch:  212 pearson: ml_test_pearson:  0.6785510051816308
============xgb============
epoch:  212 pearson: ml_test_pearson:  0.7042802297908576
============rfr============
epoch:  212 pearson: ml_test_pearson:  0.6206775939885955
===============模型average结果==================
epoch:  212 pearson: ml_test_pearson:  0.6778574621634402
[Epoch 213]
[batch 1] cost: 0.57774633 training pearson: 0.7769115829313479
[batch 2] cost: 0.63843757 training pearson: 0.5565526712165046
[batch 3] cost: 0.74869555 training pearson: 0.7599738849014577
[batch 4] cost: 0.53088653 training pearson: 0.7690990303556695
[batch 5] cost: 0.78437376 training pearson: 0.4911785392273884
[batch 6] cost: 0.78216153 training pearson: 0.599191191637679
[batch 7] cost: 0.4496908 training pearson: 0.8294383220417177
[batch 8] cost: 0.91305816 training pearson: 0.758936486220316
[batch 9] cost: 0.58734965 training pearson: 0.7694842701407448
[batch 10] cost: 0.77042603 training pearson: 0.7654601072399768
[batch 11] cost: 0.39642006 training pearson: 0.7941758194935886
[batch 12] cost: 0.5267029 training pearson: 0.8384246544506189
[batch 13] cost: 0.79957 training pearson: 0.8168010157010436
[batch 14] cost: 0.7000136 training pearson: 0.7781813740834224
[batch 15] cost: 0.7765609 training pearson: 0.7371562916208563
epoch:  213 pearson: test_pearson:  0.72624374555731
============gbrt============
epoch:  213 pearson: ml_test_pearson:  0.724439578032256
============xgb============
epoch:  213 pearson: ml_test_pearson:  0.7317034130907208
============rfr============
epoch:  213 pearson: ml_test_pearson:  0.6843203509124283
===============模型average结果==================
epoch:  213 pearson: ml_test_pearson:  0.7240544878397466
[Epoch 214]
[batch 1] cost: 0.6136264 training pearson: 0.745658132528909
[batch 2] cost: 0.64614713 training pearson: 0.810623581209985
[batch 3] cost: 0.6177617 training pearson: 0.7297715546284855
[batch 4] cost: 0.7077185 training pearson: 0.8214893655366842
[batch 5] cost: 0.9463597 training pearson: 0.7359898841404512
[batch 6] cost: 0.6235563 training pearson: 0.8037038545423976
[batch 7] cost: 0.7283307 training pearson: 0.7590167726921376
[batch 8] cost: 0.46317402 training pearson: 0.8008736597331322
[batch 9] cost: 0.6565266 training pearson: 0.7615661353934449
[batch 10] cost: 0.578289 training pearson: 0.6195503945618075
[batch 11] cost: 0.6151914 training pearson: 0.7321823402527478
[batch 12] cost: 0.70139533 training pearson: 0.7698011472555591
[batch 13] cost: 0.42640308 training pearson: 0.8299793677414566
[batch 14] cost: 0.9795529 training pearson: 0.5776774164212684
[batch 15] cost: 0.5949091 training pearson: 0.7402673112595116
epoch:  214 pearson: test_pearson:  0.7251554820533104
============gbrt============
epoch:  214 pearson: ml_test_pearson:  0.6997641581368981
============xgb============
epoch:  214 pearson: ml_test_pearson:  0.7317952606488836
============rfr============
epoch:  214 pearson: ml_test_pearson:  0.6814647044099824
===============模型average结果==================
epoch:  214 pearson: ml_test_pearson:  0.7147504592288749
[Epoch 215]
[batch 1] cost: 0.4254009 training pearson: 0.7082934496757943
[batch 2] cost: 0.66338706 training pearson: 0.802622854898181
[batch 3] cost: 0.5177107 training pearson: 0.7791581764789245
[batch 4] cost: 0.6628377 training pearson: 0.8372056930996954
[batch 5] cost: 0.8236616 training pearson: 0.6543591527413586
[batch 6] cost: 0.40738574 training pearson: 0.7761118786835532
[batch 7] cost: 0.6132601 training pearson: 0.7997381173897099
[batch 8] cost: 0.77499753 training pearson: 0.7685738315940305
[batch 9] cost: 0.9219078 training pearson: 0.6986843009345768
[batch 10] cost: 0.65611285 training pearson: 0.7870192204469126
[batch 11] cost: 0.6203048 training pearson: 0.730808716616859
[batch 12] cost: 0.73162025 training pearson: 0.6226909877663204
[batch 13] cost: 0.7764764 training pearson: 0.7999482550740746
[batch 14] cost: 0.7429359 training pearson: 0.7113079763578124
[batch 15] cost: 0.657337 training pearson: 0.7725013855698458
epoch:  215 pearson: test_pearson:  0.7263143991620783
============gbrt============
epoch:  215 pearson: ml_test_pearson:  0.7121938483015989
============xgb============
epoch:  215 pearson: ml_test_pearson:  0.7267715768900118
============rfr============
epoch:  215 pearson: ml_test_pearson:  0.645496482037632
===============模型average结果==================
epoch:  215 pearson: ml_test_pearson:  0.7054843076314071
[Epoch 216]
[batch 1] cost: 0.49755353 training pearson: 0.6096760435975458
[batch 2] cost: 0.6778919 training pearson: 0.7177895987377173
[batch 3] cost: 0.615776 training pearson: 0.7156150138270316
[batch 4] cost: 0.6002388 training pearson: 0.7739792037813026
[batch 5] cost: 0.7049267 training pearson: 0.7606820453408508
[batch 6] cost: 0.8216687 training pearson: 0.7948869182984388
[batch 7] cost: 0.86945784 training pearson: 0.8142753103903374
[batch 8] cost: 0.66052186 training pearson: 0.8039140628089502
[batch 9] cost: 0.86660445 training pearson: 0.7715010516835471
[batch 10] cost: 0.66819334 training pearson: 0.44745892361859746
[batch 11] cost: 0.6062868 training pearson: 0.7995408837455802
[batch 12] cost: 0.6345078 training pearson: 0.8737882921523096
[batch 13] cost: 0.5461168 training pearson: 0.7912441635889093
[batch 14] cost: 0.6082032 training pearson: 0.4826293561040602
[batch 15] cost: 0.5619294 training pearson: 0.8149639993602319
epoch:  216 pearson: test_pearson:  0.7263151182848655
============gbrt============
epoch:  216 pearson: ml_test_pearson:  0.7259543213627173
============xgb============
epoch:  216 pearson: ml_test_pearson:  0.7383600865397395
============rfr============
epoch:  216 pearson: ml_test_pearson:  0.6773002852346389
===============模型average结果==================
epoch:  216 pearson: ml_test_pearson:  0.7238105479403457
[Epoch 217]
[batch 1] cost: 0.5351647 training pearson: 0.7476075230625457
[batch 2] cost: 0.54201883 training pearson: 0.6343852525502154
[batch 3] cost: 0.52665937 training pearson: 0.8062641072296942
[batch 4] cost: 0.8701289 training pearson: 0.6627110921935163
[batch 5] cost: 0.4204646 training pearson: 0.8048224659513896
[batch 6] cost: 0.49018094 training pearson: 0.6548106485981393
[batch 7] cost: 0.74077225 training pearson: 0.862594517031504
[batch 8] cost: 0.5877238 training pearson: 0.6810525287568765
[batch 9] cost: 0.5048754 training pearson: 0.8092090078116417
[batch 10] cost: 0.5908444 training pearson: 0.8348380494907994
[batch 11] cost: 0.6742695 training pearson: 0.7545624214119125
[batch 12] cost: 0.7080778 training pearson: 0.7607315074193732
[batch 13] cost: 0.7167399 training pearson: 0.7138345694808488
[batch 14] cost: 1.097755 training pearson: 0.7827493699738861
[batch 15] cost: 0.76239896 training pearson: 0.7842654593092441
epoch:  217 pearson: test_pearson:  0.7257737751753336
============gbrt============
epoch:  217 pearson: ml_test_pearson:  0.721708396652175
============xgb============
epoch:  217 pearson: ml_test_pearson:  0.729074867835902
============rfr============
epoch:  217 pearson: ml_test_pearson:  0.6780822761700361
===============模型average结果==================
epoch:  217 pearson: ml_test_pearson:  0.7216111154905371
[Epoch 218]
[batch 1] cost: 0.7316254 training pearson: 0.7990373907607595
[batch 2] cost: 0.73764366 training pearson: 0.7079929373813583
[batch 3] cost: 0.55444145 training pearson: 0.7738948872425012
[batch 4] cost: 0.6461601 training pearson: 0.7461459052816278
[batch 5] cost: 0.7017627 training pearson: 0.8152443777619005
[batch 6] cost: 0.6963208 training pearson: 0.8139368525813759
[batch 7] cost: 0.69905436 training pearson: 0.7457347808078771
[batch 8] cost: 0.5336128 training pearson: 0.7315612323978564
[batch 9] cost: 0.72603714 training pearson: 0.6579485373691202
[batch 10] cost: 0.7168901 training pearson: 0.7357191241797499
[batch 11] cost: 0.766913 training pearson: 0.7064071525001178
[batch 12] cost: 0.67763335 training pearson: 0.7383038367631745
[batch 13] cost: 0.5134214 training pearson: 0.7793065556310933
[batch 14] cost: 0.6409531 training pearson: 0.7876514714164177
[batch 15] cost: 0.43573198 training pearson: 0.746283351307674
epoch:  218 pearson: test_pearson:  0.7271668951488549
============gbrt============
epoch:  218 pearson: ml_test_pearson:  0.7449619770845616
============xgb============
epoch:  218 pearson: ml_test_pearson:  0.7440158673648378
============rfr============
epoch:  218 pearson: ml_test_pearson:  0.6982532467163522
===============模型average结果==================
epoch:  218 pearson: ml_test_pearson:  0.7405072989281151
[Epoch 219]
[batch 1] cost: 0.65499043 training pearson: 0.7152134236411763
[batch 2] cost: 0.6812084 training pearson: 0.7161603380669299
[batch 3] cost: 0.7321734 training pearson: 0.7093075766803215
[batch 4] cost: 0.5399854 training pearson: 0.7892365555008093
[batch 5] cost: 0.8897613 training pearson: 0.7431175246652907
[batch 6] cost: 0.7323662 training pearson: 0.7554053200140172
[batch 7] cost: 0.5218007 training pearson: 0.6798303975392934
[batch 8] cost: 0.49234864 training pearson: 0.783697140372175
[batch 9] cost: 0.88483566 training pearson: 0.7808050691243723
[batch 10] cost: 0.468335 training pearson: 0.7951275071276713
[batch 11] cost: 0.6639543 training pearson: 0.6935599607690425
[batch 12] cost: 0.65312195 training pearson: 0.859749254880716
[batch 13] cost: 0.4843706 training pearson: 0.8492742498436854
[batch 14] cost: 0.6437166 training pearson: 0.7915362275308951
[batch 15] cost: 0.7329319 training pearson: 0.6451477242665357
epoch:  219 pearson: test_pearson:  0.7264982208800271
============gbrt============
epoch:  219 pearson: ml_test_pearson:  0.7222268259579224
============xgb============
epoch:  219 pearson: ml_test_pearson:  0.7392678887601494
============rfr============
epoch:  219 pearson: ml_test_pearson:  0.7063143909109668
===============模型average结果==================
epoch:  219 pearson: ml_test_pearson:  0.7324417147437136
[Epoch 220]
[batch 1] cost: 0.67950594 training pearson: 0.7541819580981355
[batch 2] cost: 0.6307061 training pearson: 0.7235869543792695
[batch 3] cost: 0.48050174 training pearson: 0.8200796867667937
[batch 4] cost: 0.6032127 training pearson: 0.7730222952903171
[batch 5] cost: 0.8991399 training pearson: 0.625973774945695
[batch 6] cost: 0.5817463 training pearson: 0.8125449361659047
[batch 7] cost: 0.5266486 training pearson: 0.626174670476752
[batch 8] cost: 0.85941625 training pearson: 0.6897862313062539
[batch 9] cost: 0.5264731 training pearson: 0.6348005884958626
[batch 10] cost: 0.597642 training pearson: 0.7923275254356232
[batch 11] cost: 0.7502301 training pearson: 0.7940575776840306
[batch 12] cost: 0.9955288 training pearson: 0.7719257440606055
[batch 13] cost: 0.75808716 training pearson: 0.752267645045491
[batch 14] cost: 0.44489253 training pearson: 0.8095299247001183
[batch 15] cost: 0.43325433 training pearson: 0.8360685457722344
epoch:  220 pearson: test_pearson:  0.7261167811133822
============gbrt============
epoch:  220 pearson: ml_test_pearson:  0.7240550516283204
============xgb============
epoch:  220 pearson: ml_test_pearson:  0.7387074213678658
============rfr============
epoch:  220 pearson: ml_test_pearson:  0.6903302409281689
===============模型average结果==================
epoch:  220 pearson: ml_test_pearson:  0.7299697163520589
[Epoch 221]
[batch 1] cost: 0.77380145 training pearson: 0.7803557802021278
[batch 2] cost: 0.67688507 training pearson: 0.7780858730387039
[batch 3] cost: 0.59595156 training pearson: 0.6137788350159586
[batch 4] cost: 0.54797816 training pearson: 0.8433395966981028
[batch 5] cost: 0.49957398 training pearson: 0.8364010677581264
[batch 6] cost: 0.7217822 training pearson: 0.7610275971343926
[batch 7] cost: 0.83430743 training pearson: 0.7253634731646644
[batch 8] cost: 0.6252728 training pearson: 0.7546130023675197
[batch 9] cost: 0.7185324 training pearson: 0.7874927777030377
[batch 10] cost: 0.283936 training pearson: 0.7950573984190464
[batch 11] cost: 0.6085279 training pearson: 0.833366995241166
[batch 12] cost: 0.5496845 training pearson: 0.7100645896470511
[batch 13] cost: 0.8619442 training pearson: 0.48787284799916186
[batch 14] cost: 0.7348704 training pearson: 0.7562676813200366
[batch 15] cost: 0.81579065 training pearson: 0.7293754920173684
epoch:  221 pearson: test_pearson:  0.7247408819577335
============gbrt============
epoch:  221 pearson: ml_test_pearson:  0.7188167737283507
============xgb============
epoch:  221 pearson: ml_test_pearson:  0.7163763332578994
============rfr============
epoch:  221 pearson: ml_test_pearson:  0.68899561806024
===============模型average结果==================
epoch:  221 pearson: ml_test_pearson:  0.7195716989326649
[Epoch 222]
[batch 1] cost: 0.39892945 training pearson: 0.8475015385241521
[batch 2] cost: 0.5033342 training pearson: 0.6838718732657326
[batch 3] cost: 0.5708011 training pearson: 0.7845973870143854
[batch 4] cost: 0.5097131 training pearson: 0.8299120092609493
[batch 5] cost: 0.7166862 training pearson: 0.8388617149497304
[batch 6] cost: 0.8447223 training pearson: 0.8180038903124144
[batch 7] cost: 0.6002129 training pearson: 0.6044571831394123
[batch 8] cost: 1.1077408 training pearson: 0.6861991660923421
[batch 9] cost: 0.88352996 training pearson: 0.7026167384963095
[batch 10] cost: 0.8534497 training pearson: 0.7120480145790685
[batch 11] cost: 0.669329 training pearson: 0.7422467590900131
[batch 12] cost: 0.6152161 training pearson: 0.8077379212997743
[batch 13] cost: 0.5517448 training pearson: 0.5775413490695058
[batch 14] cost: 0.5927383 training pearson: 0.772068100085338
[batch 15] cost: 0.57535964 training pearson: 0.6585658190260835
epoch:  222 pearson: test_pearson:  0.722455801899005
============gbrt============
epoch:  222 pearson: ml_test_pearson:  0.6977063380659023
============xgb============
epoch:  222 pearson: ml_test_pearson:  0.7164865322667137
============rfr============
epoch:  222 pearson: ml_test_pearson:  0.660495228756841
===============模型average结果==================
epoch:  222 pearson: ml_test_pearson:  0.7017739630505423
[Epoch 223]
[batch 1] cost: 0.74744004 training pearson: 0.7892204399619829
[batch 2] cost: 0.63186216 training pearson: 0.7672134829097289
[batch 3] cost: 0.42199412 training pearson: 0.5567730162552129
[batch 4] cost: 0.7458456 training pearson: 0.6979584091025699
[batch 5] cost: 0.58065146 training pearson: 0.7458704008720208
[batch 6] cost: 0.6193374 training pearson: 0.7361830847631775
[batch 7] cost: 0.7500085 training pearson: 0.8373954463494937
[batch 8] cost: 0.6205646 training pearson: 0.7325928126981324
[batch 9] cost: 0.8133243 training pearson: 0.6466862511052338
[batch 10] cost: 0.71957475 training pearson: 0.6693757196085238
[batch 11] cost: 0.45170447 training pearson: 0.7558372280868916
[batch 12] cost: 0.6683056 training pearson: 0.7526135456191988
[batch 13] cost: 1.0113807 training pearson: 0.7588544885569315
[batch 14] cost: 0.4461367 training pearson: 0.8137083641505872
[batch 15] cost: 0.57638574 training pearson: 0.7289886875841424
epoch:  223 pearson: test_pearson:  0.7252790572302134
============gbrt============
epoch:  223 pearson: ml_test_pearson:  0.6889359516291899
============xgb============
epoch:  223 pearson: ml_test_pearson:  0.7274015239930276
============rfr============
epoch:  223 pearson: ml_test_pearson:  0.6788326631694042
===============模型average结果==================
epoch:  223 pearson: ml_test_pearson:  0.7113426441719113
[Epoch 224]
[batch 1] cost: 0.50640404 training pearson: 0.7460436296031009
[batch 2] cost: 0.9448795 training pearson: 0.7801356157842504
[batch 3] cost: 0.47721043 training pearson: 0.807996464553901
[batch 4] cost: 0.4894803 training pearson: 0.664843229378765
[batch 5] cost: 0.6504694 training pearson: 0.742886095113152
[batch 6] cost: 0.8252013 training pearson: 0.8545776336226406
[batch 7] cost: 0.6142342 training pearson: 0.7797751063754386
[batch 8] cost: 0.56942016 training pearson: 0.7689396561771781
[batch 9] cost: 0.56126636 training pearson: 0.4783525037565851
[batch 10] cost: 0.790309 training pearson: 0.800446296255935
[batch 11] cost: 0.66459304 training pearson: 0.616390033611628
[batch 12] cost: 0.78058225 training pearson: 0.6919872443101014
[batch 13] cost: 0.53114426 training pearson: 0.7154726893124831
[batch 14] cost: 0.54505014 training pearson: 0.8170682654002535
[batch 15] cost: 0.70150393 training pearson: 0.8146512582477767
epoch:  224 pearson: test_pearson:  0.7268834511453501
============gbrt============
epoch:  224 pearson: ml_test_pearson:  0.7187696129390696
============xgb============
epoch:  224 pearson: ml_test_pearson:  0.7183875420574364
============rfr============
epoch:  224 pearson: ml_test_pearson:  0.6899896302361854
===============模型average结果==================
epoch:  224 pearson: ml_test_pearson:  0.72219981273473
[Epoch 225]
[batch 1] cost: 0.818173 training pearson: 0.7540140462217273
[batch 2] cost: 0.84353286 training pearson: 0.6790638159615972
[batch 3] cost: 1.0319666 training pearson: 0.8476619574227938
[batch 4] cost: 0.5476137 training pearson: 0.6212718415031243
[batch 5] cost: 0.50208265 training pearson: 0.7719343691107917
[batch 6] cost: 0.7066391 training pearson: 0.6333743420279416
[batch 7] cost: 0.70093095 training pearson: 0.8225143816112327
[batch 8] cost: 0.5627587 training pearson: 0.7792049017222792
[batch 9] cost: 0.6299785 training pearson: 0.7273178571454346
[batch 10] cost: 0.6219573 training pearson: 0.8300547045979914
[batch 11] cost: 0.45944053 training pearson: 0.7025710776832813
[batch 12] cost: 0.44666654 training pearson: 0.7587480357342444
[batch 13] cost: 0.64807844 training pearson: 0.7093001197611389
[batch 14] cost: 0.6851766 training pearson: 0.5707276252909376
[batch 15] cost: 0.4491906 training pearson: 0.8724804284929958
epoch:  225 pearson: test_pearson:  0.7274344347101869
============gbrt============
epoch:  225 pearson: ml_test_pearson:  0.7391379819906885
============xgb============
epoch:  225 pearson: ml_test_pearson:  0.734495037012688
============rfr============
epoch:  225 pearson: ml_test_pearson:  0.6901090245571234
===============模型average结果==================
epoch:  225 pearson: ml_test_pearson:  0.7341050482084092
[Epoch 226]
[batch 1] cost: 0.28897622 training pearson: 0.7252390067120443
[batch 2] cost: 0.5045259 training pearson: 0.7953163513913313
[batch 3] cost: 0.8364734 training pearson: 0.7824398818989265
[batch 4] cost: 0.6306229 training pearson: 0.6621998341981473
[batch 5] cost: 0.5876783 training pearson: 0.7848034536863664
[batch 6] cost: 0.6449037 training pearson: 0.689000796175534
[batch 7] cost: 0.46831 training pearson: 0.7106580481396567
[batch 8] cost: 0.81688553 training pearson: 0.7954747640161047
[batch 9] cost: 0.8106027 training pearson: 0.7982705892818142
[batch 10] cost: 0.67117685 training pearson: 0.7567872732997933
[batch 11] cost: 0.9075195 training pearson: 0.7223263180069956
[batch 12] cost: 0.75845736 training pearson: 0.8513801039065501
[batch 13] cost: 0.41134247 training pearson: 0.7835801452881037
[batch 14] cost: 0.9077544 training pearson: 0.5101947603842122
[batch 15] cost: 0.60934997 training pearson: 0.8189981974907868
epoch:  226 pearson: test_pearson:  0.727786635498403
============gbrt============
epoch:  226 pearson: ml_test_pearson:  0.7082404343160155
============xgb============
epoch:  226 pearson: ml_test_pearson:  0.7354116469723824
============rfr============
epoch:  226 pearson: ml_test_pearson:  0.6820670911020691
===============模型average结果==================
epoch:  226 pearson: ml_test_pearson:  0.7194495924170405
[Epoch 227]
[batch 1] cost: 0.5080088 training pearson: 0.7268967877477844
[batch 2] cost: 0.7205927 training pearson: 0.7901259595063528
[batch 3] cost: 0.62111413 training pearson: 0.7879029945391945
[batch 4] cost: 0.67175764 training pearson: 0.8234674625067867
[batch 5] cost: 0.5056782 training pearson: 0.7705509284286849
[batch 6] cost: 0.80686295 training pearson: 0.7611971301767508
[batch 7] cost: 0.9830545 training pearson: 0.691311128569287
[batch 8] cost: 0.48686475 training pearson: 0.7716335094269676
[batch 9] cost: 0.6165778 training pearson: 0.7764849031765294
[batch 10] cost: 0.6558031 training pearson: 0.8315025550074784
[batch 11] cost: 0.6565393 training pearson: 0.5725643181860375
[batch 12] cost: 0.4727301 training pearson: 0.44518570528566687
[batch 13] cost: 0.7043223 training pearson: 0.8183334564175899
[batch 14] cost: 0.69800234 training pearson: 0.8202252829664161
[batch 15] cost: 0.54388475 training pearson: 0.7279348311373933
epoch:  227 pearson: test_pearson:  0.7278039719711464
============gbrt============
epoch:  227 pearson: ml_test_pearson:  0.722379552148189
============xgb============
epoch:  227 pearson: ml_test_pearson:  0.7232222216388613
============rfr============
epoch:  227 pearson: ml_test_pearson:  0.6882324975099459
===============模型average结果==================
epoch:  227 pearson: ml_test_pearson:  0.722922674657527
[Epoch 228]
[batch 1] cost: 0.58714837 training pearson: 0.7699685456710822
[batch 2] cost: 0.48671567 training pearson: 0.822960955314207
[batch 3] cost: 0.56442285 training pearson: 0.7675684214592368
[batch 4] cost: 0.51774234 training pearson: 0.7385759288521827
[batch 5] cost: 0.75373125 training pearson: 0.6241626474559128
[batch 6] cost: 0.7815419 training pearson: 0.8119810143114471
[batch 7] cost: 0.4553328 training pearson: 0.8398632188266861
[batch 8] cost: 0.9193804 training pearson: 0.7277891163513762
[batch 9] cost: 0.34491864 training pearson: 0.7387401477682795
[batch 10] cost: 0.70009154 training pearson: 0.6676133119428707
[batch 11] cost: 0.80252236 training pearson: 0.7621859253164703
[batch 12] cost: 0.77547896 training pearson: 0.7895678226597499
[batch 13] cost: 0.6837343 training pearson: 0.7150602113056929
[batch 14] cost: 0.53084934 training pearson: 0.8177349958698263
[batch 15] cost: 0.69372237 training pearson: 0.6887712816221833
epoch:  228 pearson: test_pearson:  0.7280607315297962
============gbrt============
epoch:  228 pearson: ml_test_pearson:  0.7313774349987104
============xgb============
epoch:  228 pearson: ml_test_pearson:  0.721841064212874
============rfr============
epoch:  228 pearson: ml_test_pearson:  0.6636292902789249
===============模型average结果==================
epoch:  228 pearson: ml_test_pearson:  0.7190522079928646
[Epoch 229]
[batch 1] cost: 0.5689348 training pearson: 0.7522142349699104
[batch 2] cost: 0.52556664 training pearson: 0.8234467984513356
[batch 3] cost: 0.6854962 training pearson: 0.8460219910434856
[batch 4] cost: 0.5731041 training pearson: 0.8528621194802118
[batch 5] cost: 1.0164567 training pearson: 0.66293172173467
[batch 6] cost: 0.7157058 training pearson: 0.7976638915208517
[batch 7] cost: 0.4903371 training pearson: 0.6132225768348538
[batch 8] cost: 0.67952013 training pearson: 0.7228475299163479
[batch 9] cost: 0.56336427 training pearson: 0.7311244391270555
[batch 10] cost: 0.6854613 training pearson: 0.40416637265728256
[batch 11] cost: 0.6701093 training pearson: 0.8071761810580914
[batch 12] cost: 0.553 training pearson: 0.7519292381201086
[batch 13] cost: 0.46160862 training pearson: 0.6435772449040412
[batch 14] cost: 0.7567003 training pearson: 0.8459731887779587
[batch 15] cost: 0.6998658 training pearson: 0.7961425865839585
epoch:  229 pearson: test_pearson:  0.7282865404436933
============gbrt============
epoch:  229 pearson: ml_test_pearson:  0.7280148201821174
============xgb============
epoch:  229 pearson: ml_test_pearson:  0.735758611968595
============rfr============
epoch:  229 pearson: ml_test_pearson:  0.7024447803527136
===============模型average结果==================
epoch:  229 pearson: ml_test_pearson:  0.7331080622992985
[Epoch 230]
[batch 1] cost: 0.63936985 training pearson: 0.8027341332785592
[batch 2] cost: 0.6808915 training pearson: 0.8122175455020056
[batch 3] cost: 0.5961374 training pearson: 0.6967097663143187
[batch 4] cost: 0.5681825 training pearson: 0.8325415211373719
[batch 5] cost: 0.672192 training pearson: 0.7502569956150025
[batch 6] cost: 0.7905201 training pearson: 0.7485042375422029
[batch 7] cost: 0.78803986 training pearson: 0.5499865792790728
[batch 8] cost: 0.47188428 training pearson: 0.8705308634303242
[batch 9] cost: 0.6987814 training pearson: 0.756409941681325
[batch 10] cost: 0.71750677 training pearson: 0.5980858248211804
[batch 11] cost: 0.5162166 training pearson: 0.8554221985089373
[batch 12] cost: 0.63635725 training pearson: 0.7633152902162476
[batch 13] cost: 0.790927 training pearson: 0.5543262424449223
[batch 14] cost: 0.39046258 training pearson: 0.6594487706205071
[batch 15] cost: 0.76479447 training pearson: 0.801010358049001
epoch:  230 pearson: test_pearson:  0.7186380133719005
============gbrt============
epoch:  230 pearson: ml_test_pearson:  0.6878915458225904
============xgb============
epoch:  230 pearson: ml_test_pearson:  0.6964680158078626
============rfr============
epoch:  230 pearson: ml_test_pearson:  0.6496586778913361
===============模型average结果==================
epoch:  230 pearson: ml_test_pearson:  0.691701709491587
[Epoch 231]
[batch 1] cost: 0.6245211 training pearson: 0.7437042455338593
[batch 2] cost: 0.71435255 training pearson: 0.6734725365717754
[batch 3] cost: 0.5977049 training pearson: 0.7843607168767507
[batch 4] cost: 0.94540817 training pearson: 0.6805706244819917
[batch 5] cost: 0.5178885 training pearson: 0.7403764991042265
[batch 6] cost: 0.69967484 training pearson: 0.737909535089353
[batch 7] cost: 0.7452377 training pearson: 0.7255068915321103
[batch 8] cost: 0.51257306 training pearson: 0.8596913868343855
[batch 9] cost: 0.68142533 training pearson: 0.7776061085009803
[batch 10] cost: 0.61476827 training pearson: 0.7052304603148284
[batch 11] cost: 0.7006838 training pearson: 0.8590793050034746
[batch 12] cost: 0.45632824 training pearson: 0.7379277511085445
[batch 13] cost: 0.5780389 training pearson: 0.7080415309606314
[batch 14] cost: 0.6700642 training pearson: 0.7568485047820006
[batch 15] cost: 0.78794754 training pearson: 0.7396131184475442
epoch:  231 pearson: test_pearson:  0.7187378339574542
============gbrt============
epoch:  231 pearson: ml_test_pearson:  0.6706096037799059
============xgb============
epoch:  231 pearson: ml_test_pearson:  0.6939315230282865
============rfr============
epoch:  231 pearson: ml_test_pearson:  0.647024029607995
===============模型average结果==================
epoch:  231 pearson: ml_test_pearson:  0.6838720100361632
[Epoch 232]
[batch 1] cost: 0.47620025 training pearson: 0.7333329851220374
[batch 2] cost: 0.7013597 training pearson: 0.7258588693676662
[batch 3] cost: 0.686723 training pearson: 0.6356342242938737
[batch 4] cost: 0.69614756 training pearson: 0.8110461739405194
[batch 5] cost: 0.52781224 training pearson: 0.8161669897552686
[batch 6] cost: 0.73621404 training pearson: 0.5444895940812473
[batch 7] cost: 0.8192687 training pearson: 0.6865851377800077
[batch 8] cost: 0.4841847 training pearson: 0.8321574793897026
[batch 9] cost: 0.9293204 training pearson: 0.7767272794450754
[batch 10] cost: 0.708688 training pearson: 0.6867522390270309
[batch 11] cost: 0.5331332 training pearson: 0.7529299673475485
[batch 12] cost: 0.61821544 training pearson: 0.7449444208646655
[batch 13] cost: 0.74492073 training pearson: 0.7624315439338621
[batch 14] cost: 0.5419014 training pearson: 0.8580738176403789
[batch 15] cost: 0.54593205 training pearson: 0.7502356487599303
epoch:  232 pearson: test_pearson:  0.7187138255842084
============gbrt============
epoch:  232 pearson: ml_test_pearson:  0.6695188206142568
============xgb============
epoch:  232 pearson: ml_test_pearson:  0.6982584788820579
============rfr============
epoch:  232 pearson: ml_test_pearson:  0.6339534025534258
===============模型average结果==================
epoch:  232 pearson: ml_test_pearson:  0.6777950209749577
[Epoch 233]
[batch 1] cost: 0.5895234 training pearson: 0.7402902110626111
[batch 2] cost: 0.796364 training pearson: 0.6516957379405183
[batch 3] cost: 1.0057906 training pearson: 0.718831903935022
[batch 4] cost: 0.6730014 training pearson: 0.7106557482645217
[batch 5] cost: 0.67443496 training pearson: 0.7831432228751976
[batch 6] cost: 0.48139182 training pearson: 0.7246796915119117
[batch 7] cost: 0.4815519 training pearson: 0.7906575407380397
[batch 8] cost: 0.58626205 training pearson: 0.7207969629907632
[batch 9] cost: 0.6172026 training pearson: 0.7994913580164613
[batch 10] cost: 0.43985125 training pearson: 0.7674150461075208
[batch 11] cost: 0.62187654 training pearson: 0.7984882291759793
[batch 12] cost: 0.87430406 training pearson: 0.6663714409300121
[batch 13] cost: 0.6838129 training pearson: 0.7667177757706257
[batch 14] cost: 0.5064877 training pearson: 0.814594057576841
[batch 15] cost: 0.7709876 training pearson: 0.8029977382334437
epoch:  233 pearson: test_pearson:  0.7186976289447231
============gbrt============
epoch:  233 pearson: ml_test_pearson:  0.6579665450805524
============xgb============
epoch:  233 pearson: ml_test_pearson:  0.6975721087726432
============rfr============
epoch:  233 pearson: ml_test_pearson:  0.6482248622484752
===============模型average结果==================
epoch:  233 pearson: ml_test_pearson:  0.6785353263350404
[Epoch 234]
[batch 1] cost: 0.5638683 training pearson: 0.6860081762439509
[batch 2] cost: 0.48362687 training pearson: 0.7719278442914956
[batch 3] cost: 0.84311175 training pearson: 0.7979807616508523
[batch 4] cost: 0.8814879 training pearson: 0.7774799062522026
[batch 5] cost: 0.49466872 training pearson: 0.7477563043509783
[batch 6] cost: 0.8209566 training pearson: 0.7905750270407919
[batch 7] cost: 0.53577644 training pearson: 0.8105303541221794
[batch 8] cost: 0.6405492 training pearson: 0.6802953237498217
[batch 9] cost: 0.8106594 training pearson: 0.6336258721325129
[batch 10] cost: 0.5903904 training pearson: 0.6750808591706987
[batch 11] cost: 0.77672607 training pearson: 0.7401987101959434
[batch 12] cost: 0.6929063 training pearson: 0.7803393349213628
[batch 13] cost: 0.47103444 training pearson: 0.7521288645012064
[batch 14] cost: 0.44158027 training pearson: 0.8206237081445164
[batch 15] cost: 0.695182 training pearson: 0.6895325331308245
epoch:  234 pearson: test_pearson:  0.7188066154442814
============gbrt============
epoch:  234 pearson: ml_test_pearson:  0.6634422245858411
============xgb============
epoch:  234 pearson: ml_test_pearson:  0.6922955802931292
============rfr============
epoch:  234 pearson: ml_test_pearson:  0.652844114244
===============模型average结果==================
epoch:  234 pearson: ml_test_pearson:  0.6812164572678828
[Epoch 235]
[batch 1] cost: 0.7375407 training pearson: 0.7527524169960006
[batch 2] cost: 0.60064733 training pearson: 0.726272709182671
[batch 3] cost: 0.540424 training pearson: 0.843024687500008
[batch 4] cost: 0.45204294 training pearson: 0.5890361374581278
[batch 5] cost: 0.6777919 training pearson: 0.5448990231545876
[batch 6] cost: 0.6818914 training pearson: 0.7715238828029972
[batch 7] cost: 0.7115297 training pearson: 0.5937487277040626
[batch 8] cost: 0.6056596 training pearson: 0.8290581018626152
[batch 9] cost: 0.48048282 training pearson: 0.7692923676320647
[batch 10] cost: 0.63854927 training pearson: 0.6792243813952453
[batch 11] cost: 0.68144226 training pearson: 0.7526020178714456
[batch 12] cost: 0.6297111 training pearson: 0.8173018751144481
[batch 13] cost: 0.89772636 training pearson: 0.7400486854280991
[batch 14] cost: 0.63612664 training pearson: 0.7977779188190524
[batch 15] cost: 0.78783226 training pearson: 0.846193628788482
epoch:  235 pearson: test_pearson:  0.7188316463663175
============gbrt============
epoch:  235 pearson: ml_test_pearson:  0.6663335779413361
============xgb============
epoch:  235 pearson: ml_test_pearson:  0.6925225078363755
============rfr============
epoch:  235 pearson: ml_test_pearson:  0.6486087748388605
===============模型average结果==================
epoch:  235 pearson: ml_test_pearson:  0.6826717769343258
[Epoch 236]
[batch 1] cost: 0.41192734 training pearson: 0.823892561503567
[batch 2] cost: 0.6094364 training pearson: 0.7670623215279834
[batch 3] cost: 0.4585209 training pearson: 0.7153831339110142
[batch 4] cost: 0.77447724 training pearson: 0.7652470670953829
[batch 5] cost: 0.6222437 training pearson: 0.7161588575465591
[batch 6] cost: 0.5911697 training pearson: 0.801058746233913
[batch 7] cost: 0.5944317 training pearson: 0.7735075481830522
[batch 8] cost: 0.4711721 training pearson: 0.8180236148074322
[batch 9] cost: 0.90858537 training pearson: 0.7914553676253193
[batch 10] cost: 0.88633835 training pearson: 0.6864047174092913
[batch 11] cost: 0.5642314 training pearson: 0.8385749462450884
[batch 12] cost: 0.63889915 training pearson: 0.7553170045937961
[batch 13] cost: 0.77669996 training pearson: 0.7045190974206469
[batch 14] cost: 0.82372427 training pearson: 0.5688616748914129
[batch 15] cost: 0.6451283 training pearson: 0.6517579491511144
epoch:  236 pearson: test_pearson:  0.7188569567374468
============gbrt============
epoch:  236 pearson: ml_test_pearson:  0.6652195914653994
============xgb============
epoch:  236 pearson: ml_test_pearson:  0.7070723338595123
============rfr============
epoch:  236 pearson: ml_test_pearson:  0.61157261092949
===============模型average结果==================
epoch:  236 pearson: ml_test_pearson:  0.6679681695585603
[Epoch 237]
[batch 1] cost: 0.8882321 training pearson: 0.7846040031140966
[batch 2] cost: 0.9856257 training pearson: 0.7775052531904928
[batch 3] cost: 0.76366365 training pearson: 0.7881766853119607
[batch 4] cost: 0.5379917 training pearson: 0.7599955299116236
[batch 5] cost: 0.6782072 training pearson: 0.7977862081166468
[batch 6] cost: 0.95213807 training pearson: 0.6818498881341888
[batch 7] cost: 0.40627533 training pearson: 0.5696059909659205
[batch 8] cost: 0.34276715 training pearson: 0.7962872221521503
[batch 9] cost: 0.53532004 training pearson: 0.6491843929526954
[batch 10] cost: 0.49362302 training pearson: 0.7919264897036917
[batch 11] cost: 0.7295301 training pearson: 0.5114178355440196
[batch 12] cost: 0.43242282 training pearson: 0.7983841945386394
[batch 13] cost: 0.68877393 training pearson: 0.7549191268750214
[batch 14] cost: 0.49656934 training pearson: 0.6771868897035603
[batch 15] cost: 0.79591924 training pearson: 0.8508364364540598
epoch:  237 pearson: test_pearson:  0.7189006594183053
============gbrt============
epoch:  237 pearson: ml_test_pearson:  0.6769101239735426
============xgb============
epoch:  237 pearson: ml_test_pearson:  0.6850073038727316
============rfr============
epoch:  237 pearson: ml_test_pearson:  0.6352752988496104
===============模型average结果==================
epoch:  237 pearson: ml_test_pearson:  0.6787811669067676
[Epoch 238]
[batch 1] cost: 0.5000753 training pearson: 0.7274152951629744
[batch 2] cost: 0.96375203 training pearson: 0.6425906510462465
[batch 3] cost: 0.4549814 training pearson: 0.7549428275121276
[batch 4] cost: 0.7080602 training pearson: 0.7906806896052977
[batch 5] cost: 0.61225635 training pearson: 0.814259474993392
[batch 6] cost: 0.5661401 training pearson: 0.606664681211984
[batch 7] cost: 0.5678602 training pearson: 0.7549337678215585
[batch 8] cost: 0.7681865 training pearson: 0.6635920121484057
[batch 9] cost: 0.6120088 training pearson: 0.6335402955041394
[batch 10] cost: 0.7556584 training pearson: 0.7383930842528743
[batch 11] cost: 0.5884282 training pearson: 0.7589801454031503
[batch 12] cost: 0.8326374 training pearson: 0.8384031250670931
[batch 13] cost: 0.5773399 training pearson: 0.7390199114665836
[batch 14] cost: 0.7168099 training pearson: 0.755796073360153
[batch 15] cost: 0.4994029 training pearson: 0.8202868135894088
epoch:  238 pearson: test_pearson:  0.7189753871758477
============gbrt============
epoch:  238 pearson: ml_test_pearson:  0.6866146571800512
============xgb============
epoch:  238 pearson: ml_test_pearson:  0.700668781317848
============rfr============
epoch:  238 pearson: ml_test_pearson:  0.6563544272570236
===============模型average结果==================
epoch:  238 pearson: ml_test_pearson:  0.6920730127719614
[Epoch 239]
[batch 1] cost: 0.48594254 training pearson: 0.8358905392510748
[batch 2] cost: 0.5096692 training pearson: 0.7947833267747466
[batch 3] cost: 0.38059783 training pearson: 0.7877578184998076
[batch 4] cost: 0.59032804 training pearson: 0.7751897855591608
[batch 5] cost: 0.78901654 training pearson: 0.8537748141188828
[batch 6] cost: 0.74324846 training pearson: 0.4731825309134594
[batch 7] cost: 0.8469028 training pearson: 0.683318781321057
[batch 8] cost: 0.6306229 training pearson: 0.8004617378113018
[batch 9] cost: 0.56408495 training pearson: 0.8048092478717165
[batch 10] cost: 0.57497686 training pearson: 0.7648985246259872
[batch 11] cost: 0.42787823 training pearson: 0.7744918876758534
[batch 12] cost: 0.7735084 training pearson: 0.7235605920084335
[batch 13] cost: 0.83907074 training pearson: 0.651433046194998
[batch 14] cost: 0.69654447 training pearson: 0.7690932166347216
[batch 15] cost: 0.83216774 training pearson: 0.7098197424756288
epoch:  239 pearson: test_pearson:  0.7189386379689252
============gbrt============
epoch:  239 pearson: ml_test_pearson:  0.6746837414200418
============xgb============
epoch:  239 pearson: ml_test_pearson:  0.7026337064139271
============rfr============
epoch:  239 pearson: ml_test_pearson:  0.6625365172809761
===============模型average结果==================
epoch:  239 pearson: ml_test_pearson:  0.6931269654817588
[Epoch 240]
[batch 1] cost: 0.7249107 training pearson: 0.8751116015900908
[batch 2] cost: 0.63508004 training pearson: 0.808646533679372
[batch 3] cost: 0.6626247 training pearson: 0.6695740429414513
[batch 4] cost: 0.6485498 training pearson: 0.759515460196113
[batch 5] cost: 0.70816386 training pearson: 0.7489852786568253
[batch 6] cost: 0.55057985 training pearson: 0.798490152057197
[batch 7] cost: 0.81171995 training pearson: 0.6668764770875506
[batch 8] cost: 0.55039716 training pearson: 0.7767720745743187
[batch 9] cost: 0.6483151 training pearson: 0.6946086895249359
[batch 10] cost: 0.575364 training pearson: 0.7818788988259273
[batch 11] cost: 0.4541403 training pearson: 0.721177907764128
[batch 12] cost: 0.87392104 training pearson: 0.7025429322494802
[batch 13] cost: 0.57395154 training pearson: 0.8031283213763911
[batch 14] cost: 0.79251665 training pearson: 0.6738218980596109
[batch 15] cost: 0.50260544 training pearson: 0.7290629618748101
epoch:  240 pearson: test_pearson:  0.7189968421538157
============gbrt============
epoch:  240 pearson: ml_test_pearson:  0.6889984032864739
============xgb============
epoch:  240 pearson: ml_test_pearson:  0.6924450446614125
============rfr============
epoch:  240 pearson: ml_test_pearson:  0.6432155458966669
===============模型average结果==================
epoch:  240 pearson: ml_test_pearson:  0.684687519807338
[Epoch 241]
[batch 1] cost: 0.87762284 training pearson: 0.7117228940883784
[batch 2] cost: 0.52047056 training pearson: 0.7466678863927629
[batch 3] cost: 0.51622105 training pearson: 0.75981200074665
[batch 4] cost: 0.41514352 training pearson: 0.8549877443722632
[batch 5] cost: 0.8077826 training pearson: 0.73686446682567
[batch 6] cost: 0.80685145 training pearson: 0.7043066224979857
[batch 7] cost: 0.5740657 training pearson: 0.7574710633103156
[batch 8] cost: 0.912668 training pearson: 0.6719851586761574
[batch 9] cost: 0.79864794 training pearson: 0.7320482518476348
[batch 10] cost: 0.69656837 training pearson: 0.6829211255866472
[batch 11] cost: 0.4790417 training pearson: 0.8526277586212052
[batch 12] cost: 0.58917034 training pearson: 0.7383977227365237
[batch 13] cost: 0.52835274 training pearson: 0.7715979465820753
[batch 14] cost: 0.47695827 training pearson: 0.765776420631421
[batch 15] cost: 0.66553843 training pearson: 0.644884918084628
epoch:  241 pearson: test_pearson:  0.7190252710341256
============gbrt============
epoch:  241 pearson: ml_test_pearson:  0.6739553986923829
============xgb============
epoch:  241 pearson: ml_test_pearson:  0.709652847735981
============rfr============
epoch:  241 pearson: ml_test_pearson:  0.6378628806838126
===============模型average结果==================
epoch:  241 pearson: ml_test_pearson:  0.681111021124828
[Epoch 242]
[batch 1] cost: 0.8040752 training pearson: 0.6371620092481338
[batch 2] cost: 0.76049554 training pearson: 0.5943002725648602
[batch 3] cost: 0.71413475 training pearson: 0.7136442786860185
[batch 4] cost: 0.3641037 training pearson: 0.4190420994207028
[batch 5] cost: 0.6643375 training pearson: 0.7508169817925969
[batch 6] cost: 0.79036224 training pearson: 0.6554710635202114
[batch 7] cost: 0.4199351 training pearson: 0.7814206160774738
[batch 8] cost: 0.72010314 training pearson: 0.7338737409235983
[batch 9] cost: 0.99710256 training pearson: 0.8382815491749754
[batch 10] cost: 0.6867766 training pearson: 0.7719034152661542
[batch 11] cost: 0.50220174 training pearson: 0.8389410029603707
[batch 12] cost: 0.5454872 training pearson: 0.8333525830656243
[batch 13] cost: 0.3920966 training pearson: 0.6186811986436355
[batch 14] cost: 0.6652248 training pearson: 0.8384685499183521
[batch 15] cost: 0.65379804 training pearson: 0.8145723016452774
epoch:  242 pearson: test_pearson:  0.7189884554308674
============gbrt============
epoch:  242 pearson: ml_test_pearson:  0.6809073673304348
============xgb============
epoch:  242 pearson: ml_test_pearson:  0.7046224597175625
============rfr============
epoch:  242 pearson: ml_test_pearson:  0.648814788343881
===============模型average结果==================
epoch:  242 pearson: ml_test_pearson:  0.6890831894892153
[Epoch 243]
[batch 1] cost: 0.6629059 training pearson: 0.7485227606868686
[batch 2] cost: 0.5884013 training pearson: 0.8491450621440706
[batch 3] cost: 0.86728776 training pearson: 0.7777519705646334
[batch 4] cost: 0.8155586 training pearson: 0.5234152862572924
[batch 5] cost: 0.3604168 training pearson: 0.8450662206838471
[batch 6] cost: 0.59499574 training pearson: 0.7762133351463684
[batch 7] cost: 0.76620847 training pearson: 0.7402974346684786
[batch 8] cost: 0.41462395 training pearson: 0.7846274618723228
[batch 9] cost: 0.5361965 training pearson: 0.5992910541760517
[batch 10] cost: 0.5187157 training pearson: 0.7923891359228133
[batch 11] cost: 0.786614 training pearson: 0.5692542855200413
[batch 12] cost: 0.6185531 training pearson: 0.7193309209959508
[batch 13] cost: 0.58491254 training pearson: 0.7181353476927096
[batch 14] cost: 0.8854199 training pearson: 0.8089969917667558
[batch 15] cost: 0.6774385 training pearson: 0.7527712170875047
epoch:  243 pearson: test_pearson:  0.7188759024987924
============gbrt============
epoch:  243 pearson: ml_test_pearson:  0.6792630975588767
============xgb============
epoch:  243 pearson: ml_test_pearson:  0.6998472569761395
============rfr============
epoch:  243 pearson: ml_test_pearson:  0.6378204199855381
===============模型average结果==================
epoch:  243 pearson: ml_test_pearson:  0.6840606428966566
[Epoch 244]
[batch 1] cost: 0.95094943 training pearson: 0.6113105841118962
[batch 2] cost: 0.68710226 training pearson: 0.6979298873478843
[batch 3] cost: 0.69878024 training pearson: 0.7558774306727909
[batch 4] cost: 0.6721991 training pearson: 0.7892246202330352
[batch 5] cost: 0.89940244 training pearson: 0.5808763804897171
[batch 6] cost: 0.7310391 training pearson: 0.8147238759002844
[batch 7] cost: 0.5456123 training pearson: 0.6802439132975056
[batch 8] cost: 0.5520313 training pearson: 0.784888974656403
[batch 9] cost: 0.45565736 training pearson: 0.814779981623222
[batch 10] cost: 0.56339 training pearson: 0.7767630492925559
[batch 11] cost: 0.5466431 training pearson: 0.7150092653322435
[batch 12] cost: 0.8101919 training pearson: 0.649085878116791
[batch 13] cost: 0.44308376 training pearson: 0.7843435794656323
[batch 14] cost: 0.5673386 training pearson: 0.8408552722101236
[batch 15] cost: 0.55883926 training pearson: 0.7601084917518113
epoch:  244 pearson: test_pearson:  0.7189388372179832
============gbrt============
epoch:  244 pearson: ml_test_pearson:  0.6770999111555293
============xgb============
epoch:  244 pearson: ml_test_pearson:  0.7131277076936192
============rfr============
epoch:  244 pearson: ml_test_pearson:  0.6470418917264594
===============模型average结果==================
epoch:  244 pearson: ml_test_pearson:  0.6899224305937791
[Epoch 245]
[batch 1] cost: 0.6818766 training pearson: 0.7322604932186917
[batch 2] cost: 0.7199582 training pearson: 0.6837941066134959
[batch 3] cost: 0.5290799 training pearson: 0.7312345627022808
[batch 4] cost: 0.7081963 training pearson: 0.6342786434447437
[batch 5] cost: 0.8001454 training pearson: 0.7226180254799812
[batch 6] cost: 0.6581381 training pearson: 0.8018455602207472
[batch 7] cost: 0.75703996 training pearson: 0.6777722700894054
[batch 8] cost: 0.40711638 training pearson: 0.6885684303354854
[batch 9] cost: 0.5191332 training pearson: 0.7214510820956852
[batch 10] cost: 0.49486673 training pearson: 0.8294851470620005
[batch 11] cost: 0.6734439 training pearson: 0.5728960850001488
[batch 12] cost: 0.682087 training pearson: 0.7673331078177199
[batch 13] cost: 0.7270676 training pearson: 0.8197851442208589
[batch 14] cost: 0.7472628 training pearson: 0.8393542394298945
[batch 15] cost: 0.594333 training pearson: 0.7779300349095545
epoch:  245 pearson: test_pearson:  0.7191476992940243
============gbrt============
epoch:  245 pearson: ml_test_pearson:  0.6935110621568491
============xgb============
epoch:  245 pearson: ml_test_pearson:  0.7182583021927618
============rfr============
epoch:  245 pearson: ml_test_pearson:  0.659516427477344
===============模型average结果==================
epoch:  245 pearson: ml_test_pearson:  0.7022215759316025
[Epoch 246]
[batch 1] cost: 0.5578276 training pearson: 0.7861926058701937
[batch 2] cost: 0.5997675 training pearson: 0.8102389415834664
[batch 3] cost: 0.84135836 training pearson: 0.7118624224589664
[batch 4] cost: 0.8820761 training pearson: 0.7315721269891182
[batch 5] cost: 0.59386545 training pearson: 0.7797002112808887
[batch 6] cost: 0.43622345 training pearson: 0.7859653711213421
[batch 7] cost: 0.5671349 training pearson: 0.773700345443659
[batch 8] cost: 0.64014757 training pearson: 0.7506256492241644
[batch 9] cost: 0.5453213 training pearson: 0.6815268534354864
[batch 10] cost: 0.72361785 training pearson: 0.8474031065761007
[batch 11] cost: 0.65648323 training pearson: 0.7973097384718294
[batch 12] cost: 0.5620791 training pearson: 0.6784815100409368
[batch 13] cost: 0.645838 training pearson: 0.6197292405816567
[batch 14] cost: 0.7537067 training pearson: 0.3247225115779195
[batch 15] cost: 0.6603366 training pearson: 0.8582997179858749
epoch:  246 pearson: test_pearson:  0.7190401110116434
============gbrt============
epoch:  246 pearson: ml_test_pearson:  0.6893136855527973
============xgb============
epoch:  246 pearson: ml_test_pearson:  0.7102831219254979
============rfr============
epoch:  246 pearson: ml_test_pearson:  0.6483990580907236
===============模型average结果==================
epoch:  246 pearson: ml_test_pearson:  0.6937445579602551
[Epoch 247]
[batch 1] cost: 0.99760664 training pearson: 0.6115952750761895
[batch 2] cost: 0.5862141 training pearson: 0.8720248298355479
[batch 3] cost: 0.7595261 training pearson: 0.7720091963630081
[batch 4] cost: 0.86300874 training pearson: 0.7197824374033757
[batch 5] cost: 0.68401396 training pearson: 0.7904941481159853
[batch 6] cost: 0.75208646 training pearson: 0.5940093370997518
[batch 7] cost: 0.9375713 training pearson: 0.7728774807417141
[batch 8] cost: 0.4464249 training pearson: 0.833279440536242
[batch 9] cost: 0.6304288 training pearson: 0.8263354824542501
[batch 10] cost: 0.7406764 training pearson: 0.7350361932745716
[batch 11] cost: 0.48881614 training pearson: 0.762819886680136
[batch 12] cost: 0.43055055 training pearson: 0.43823016111739355
[batch 13] cost: 0.36405388 training pearson: 0.7263350584367715
[batch 14] cost: 0.5484693 training pearson: 0.7823903241784076
[batch 15] cost: 0.4602575 training pearson: 0.7395812709873184
epoch:  247 pearson: test_pearson:  0.719094688114869
============gbrt============
epoch:  247 pearson: ml_test_pearson:  0.6838966720643236
============xgb============
epoch:  247 pearson: ml_test_pearson:  0.719690914595585
============rfr============
epoch:  247 pearson: ml_test_pearson:  0.665012923016916
===============模型average结果==================
epoch:  247 pearson: ml_test_pearson:  0.7014082853390211
[Epoch 248]
[batch 1] cost: 0.55566186 training pearson: 0.7430444820296027
[batch 2] cost: 0.6942834 training pearson: 0.7507335895918597
[batch 3] cost: 0.42132586 training pearson: 0.787602122694852
[batch 4] cost: 0.61436975 training pearson: 0.6986022627647287
[batch 5] cost: 0.72819686 training pearson: 0.6399343359187754
[batch 6] cost: 0.5236767 training pearson: 0.7550008014870508
[batch 7] cost: 0.3936505 training pearson: 0.6769453535803053
[batch 8] cost: 0.8358806 training pearson: 0.7487676923654571
[batch 9] cost: 1.1184354 training pearson: 0.7056462429850269
[batch 10] cost: 0.43527722 training pearson: 0.8518383117901014
[batch 11] cost: 0.78525496 training pearson: 0.5726100567275367
[batch 12] cost: 0.7170004 training pearson: 0.7577272968692523
[batch 13] cost: 0.6272041 training pearson: 0.7225592920171523
[batch 14] cost: 0.6490834 training pearson: 0.8381000204250642
[batch 15] cost: 0.60367006 training pearson: 0.7924522030583562
epoch:  248 pearson: test_pearson:  0.7191963223310961
============gbrt============
epoch:  248 pearson: ml_test_pearson:  0.6749572586008382
============xgb============
epoch:  248 pearson: ml_test_pearson:  0.7183561076055973
============rfr============
epoch:  248 pearson: ml_test_pearson:  0.6547349019834114
===============模型average结果==================
epoch:  248 pearson: ml_test_pearson:  0.6962362993262525
[Epoch 249]
[batch 1] cost: 0.507788 training pearson: 0.7977521622050705
[batch 2] cost: 0.61323655 training pearson: 0.7308716740606159
[batch 3] cost: 0.75101393 training pearson: 0.8387953271236308
[batch 4] cost: 0.5329066 training pearson: 0.7105912700844044
[batch 5] cost: 0.67996186 training pearson: 0.8295416890606262
[batch 6] cost: 0.7935746 training pearson: 0.49117498904883194
[batch 7] cost: 0.5878041 training pearson: 0.7905884043218806
[batch 8] cost: 0.6867316 training pearson: 0.7498868000347474
[batch 9] cost: 0.35657164 training pearson: 0.8435173474830425
[batch 10] cost: 0.9430229 training pearson: 0.6306217680974152
[batch 11] cost: 0.55907196 training pearson: 0.6760604205339995
[batch 12] cost: 0.61822283 training pearson: 0.7231191772437194
[batch 13] cost: 0.71185386 training pearson: 0.7595596629790197
[batch 14] cost: 0.56526893 training pearson: 0.8234448586397988
[batch 15] cost: 0.7813344 training pearson: 0.6606732054663901
epoch:  249 pearson: test_pearson:  0.7191227367938622
============gbrt============
epoch:  249 pearson: ml_test_pearson:  0.6696071463213706
============xgb============
epoch:  249 pearson: ml_test_pearson:  0.7033488496511882
============rfr============
epoch:  249 pearson: ml_test_pearson:  0.6488027789520867
===============模型average结果==================
epoch:  249 pearson: ml_test_pearson:  0.687483295040686
[Epoch 250]
[batch 1] cost: 0.68656045 training pearson: 0.7067718634241051
[batch 2] cost: 0.72924507 training pearson: 0.7000697363900767
[batch 3] cost: 0.6969591 training pearson: 0.6548298400211371
[batch 4] cost: 0.8490044 training pearson: 0.7341727644280539
[batch 5] cost: 0.74778414 training pearson: 0.631763113260047
[batch 6] cost: 0.360843 training pearson: 0.6924125380907639
[batch 7] cost: 0.6576667 training pearson: 0.8261912826039113
[batch 8] cost: 0.3828408 training pearson: 0.7900198347928292
[batch 9] cost: 0.9221098 training pearson: 0.6585299292614287
[batch 10] cost: 0.4662976 training pearson: 0.8413191213328008
[batch 11] cost: 0.55062604 training pearson: 0.7623496857893316
[batch 12] cost: 0.77774644 training pearson: 0.8039608809654638
[batch 13] cost: 0.53538346 training pearson: 0.819898962285095
[batch 14] cost: 0.7139331 training pearson: 0.7239952522853644
[batch 15] cost: 0.52855223 training pearson: 0.7784956017072853
epoch:  250 pearson: test_pearson:  0.719165820494652
============gbrt============
epoch:  250 pearson: ml_test_pearson:  0.689559619011378
============xgb============
epoch:  250 pearson: ml_test_pearson:  0.7065758890831642
============rfr============
epoch:  250 pearson: ml_test_pearson:  0.6523400654330137
===============模型average结果==================
epoch:  250 pearson: ml_test_pearson:  0.6961344615264582
[Epoch 251]
[batch 1] cost: 0.5562508 training pearson: 0.7895195607497189
[batch 2] cost: 0.48342952 training pearson: 0.7422394416290397
[batch 3] cost: 0.8232027 training pearson: 0.7818411301189319
[batch 4] cost: 0.6418598 training pearson: 0.7299615161444966
[batch 5] cost: 0.5107728 training pearson: 0.7874971161151555
[batch 6] cost: 0.6731073 training pearson: 0.7760479398194899
[batch 7] cost: 0.6372444 training pearson: 0.7970119518408857
[batch 8] cost: 0.5303065 training pearson: 0.7937693075840995
[batch 9] cost: 0.6502621 training pearson: 0.835275685017188
[batch 10] cost: 0.90728813 training pearson: 0.6231325800503098
[batch 11] cost: 0.5766841 training pearson: 0.8189311395741089
[batch 12] cost: 0.5389875 training pearson: 0.7761587587509513
[batch 13] cost: 0.6940345 training pearson: 0.42754039078519174
[batch 14] cost: 0.8404356 training pearson: 0.6532892170911698
[batch 15] cost: 0.5379255 training pearson: 0.6818181762571589
epoch:  251 pearson: test_pearson:  0.7192300496231808
============gbrt============
epoch:  251 pearson: ml_test_pearson:  0.6745253160279684
============xgb============
epoch:  251 pearson: ml_test_pearson:  0.712366468221344
============rfr============
epoch:  251 pearson: ml_test_pearson:  0.6764365942038425
===============模型average结果==================
epoch:  251 pearson: ml_test_pearson:  0.7015813550705016
[Epoch 252]
[batch 1] cost: 0.6905217 training pearson: 0.8190478167267935
[batch 2] cost: 0.58490515 training pearson: 0.707343582198108
[batch 3] cost: 0.8471181 training pearson: 0.7888701923468641
[batch 4] cost: 0.6673973 training pearson: 0.43776195572136084
[batch 5] cost: 0.44104043 training pearson: 0.7186314676528028
[batch 6] cost: 0.7752527 training pearson: 0.7180944903958727
[batch 7] cost: 0.43974724 training pearson: 0.7839758203764109
[batch 8] cost: 0.43663773 training pearson: 0.8104498889046828
[batch 9] cost: 0.6321501 training pearson: 0.7387471287478389
[batch 10] cost: 0.7630583 training pearson: 0.6862183429752398
[batch 11] cost: 0.50501716 training pearson: 0.776659629367295
[batch 12] cost: 0.74459404 training pearson: 0.7960211650885402
[batch 13] cost: 0.75929034 training pearson: 0.7422576862825532
[batch 14] cost: 0.58580095 training pearson: 0.6657884687495116
[batch 15] cost: 0.79433167 training pearson: 0.8207204854914794
epoch:  252 pearson: test_pearson:  0.7191723260094115
============gbrt============
epoch:  252 pearson: ml_test_pearson:  0.6834984579538973
============xgb============
epoch:  252 pearson: ml_test_pearson:  0.7086418710808984
============rfr============
epoch:  252 pearson: ml_test_pearson:  0.6626573035513834
===============模型average结果==================
epoch:  252 pearson: ml_test_pearson:  0.7017368538824507
[Epoch 253]
[batch 1] cost: 0.7223249 training pearson: 0.8232677682786809
[batch 2] cost: 0.64087975 training pearson: 0.7227480260676825
[batch 3] cost: 0.64533496 training pearson: 0.8094368819886102
[batch 4] cost: 0.4984432 training pearson: 0.7998443047584453
[batch 5] cost: 0.7124898 training pearson: 0.5934492578231982
[batch 6] cost: 0.73273796 training pearson: 0.813978363507464
[batch 7] cost: 0.517331 training pearson: 0.6706818359578434
[batch 8] cost: 0.4995041 training pearson: 0.7728784761731716
[batch 9] cost: 0.42522195 training pearson: 0.7665281657981174
[batch 10] cost: 0.6538118 training pearson: 0.730798943985803
[batch 11] cost: 0.65472394 training pearson: 0.7199450336324843
[batch 12] cost: 0.6817024 training pearson: 0.788869744285323
[batch 13] cost: 0.66873384 training pearson: 0.7056408231114564
[batch 14] cost: 0.6442541 training pearson: 0.7299216178192569
[batch 15] cost: 0.87282026 training pearson: 0.6030131741944414
epoch:  253 pearson: test_pearson:  0.7191458495327837
============gbrt============
epoch:  253 pearson: ml_test_pearson:  0.6779555751501036
============xgb============
epoch:  253 pearson: ml_test_pearson:  0.7139020080084378
============rfr============
epoch:  253 pearson: ml_test_pearson:  0.652530304953005
===============模型average结果==================
epoch:  253 pearson: ml_test_pearson:  0.6938172682389108
[Epoch 254]
[batch 1] cost: 0.8591388 training pearson: 0.7232457529365541
[batch 2] cost: 0.5894524 training pearson: 0.810734060125931
[batch 3] cost: 0.8042682 training pearson: 0.7878735659161025
[batch 4] cost: 0.37072346 training pearson: 0.8005547065037556
[batch 5] cost: 0.81868523 training pearson: 0.6842378416835139
[batch 6] cost: 0.6908949 training pearson: 0.6951380211730787
[batch 7] cost: 0.5112715 training pearson: 0.7281329343135168
[batch 8] cost: 0.6180022 training pearson: 0.6629839242046268
[batch 9] cost: 0.6743978 training pearson: 0.7714731587882284
[batch 10] cost: 0.6434154 training pearson: 0.8621167887218837
[batch 11] cost: 0.59789497 training pearson: 0.7486431214855835
[batch 12] cost: 0.5185592 training pearson: 0.7743452887126622
[batch 13] cost: 0.7589661 training pearson: 0.6126326320209514
[batch 14] cost: 0.47702187 training pearson: 0.7364519202707484
[batch 15] cost: 0.7123602 training pearson: 0.7669529933083894
epoch:  254 pearson: test_pearson:  0.7186655723223945
============gbrt============
epoch:  254 pearson: ml_test_pearson:  0.6731305952222488
============xgb============
epoch:  254 pearson: ml_test_pearson:  0.7065077856161912
============rfr============
epoch:  254 pearson: ml_test_pearson:  0.6626018914076609
===============模型average结果==================
epoch:  254 pearson: ml_test_pearson:  0.6938589188427182
[Epoch 255]
[batch 1] cost: 0.6534824 training pearson: 0.7773879978076812
[batch 2] cost: 0.5474691 training pearson: 0.8385758535269502
[batch 3] cost: 0.73491615 training pearson: 0.7487372363113121
[batch 4] cost: 0.79836303 training pearson: 0.83035837559918
[batch 5] cost: 0.74797523 training pearson: 0.7873193146401077
[batch 6] cost: 0.7611484 training pearson: 0.6644351749192762
[batch 7] cost: 0.5192372 training pearson: 0.5912699948382556
[batch 8] cost: 0.656644 training pearson: 0.7556730355985876
[batch 9] cost: 0.5595062 training pearson: 0.7553511532583665
[batch 10] cost: 0.56268346 training pearson: 0.7129475650983829
[batch 11] cost: 0.666635 training pearson: 0.6322517551423132
[batch 12] cost: 0.5590024 training pearson: 0.8241757643184437
[batch 13] cost: 0.63720894 training pearson: 0.7535723257183619
[batch 14] cost: 0.51401734 training pearson: 0.6764551708857626
[batch 15] cost: 0.72239405 training pearson: 0.7577369439112303
epoch:  255 pearson: test_pearson:  0.7188713491448593
============gbrt============
epoch:  255 pearson: ml_test_pearson:  0.7069135123955371
============xgb============
epoch:  255 pearson: ml_test_pearson:  0.6940283247176209
============rfr============
epoch:  255 pearson: ml_test_pearson:  0.6601053646382056
===============模型average结果==================
epoch:  255 pearson: ml_test_pearson:  0.7031474059511107
[Epoch 256]
[batch 1] cost: 0.5118496 training pearson: 0.8666865195511421
[batch 2] cost: 0.6101338 training pearson: 0.8093420670528317
[batch 3] cost: 0.83060527 training pearson: 0.6665085847540227
[batch 4] cost: 0.58030385 training pearson: 0.6907468576320633
[batch 5] cost: 0.78293073 training pearson: 0.7066140079428884
[batch 6] cost: 0.6760391 training pearson: 0.7283342678179193
[batch 7] cost: 0.6469324 training pearson: 0.7820387928939885
[batch 8] cost: 0.6196699 training pearson: 0.6003885013400672
[batch 9] cost: 0.5270342 training pearson: 0.6681842837025935
[batch 10] cost: 0.55854386 training pearson: 0.6958408016736229
[batch 11] cost: 0.5943032 training pearson: 0.7824318820560474
[batch 12] cost: 0.86371446 training pearson: 0.7989454757834696
[batch 13] cost: 0.6498231 training pearson: 0.732545223374381
[batch 14] cost: 0.48953006 training pearson: 0.7874643807408053
[batch 15] cost: 0.7155857 training pearson: 0.8056947449184994
epoch:  256 pearson: test_pearson:  0.7190780054767004
============gbrt============
epoch:  256 pearson: ml_test_pearson:  0.6981408596474632
============xgb============
epoch:  256 pearson: ml_test_pearson:  0.7099934621463746
============rfr============
epoch:  256 pearson: ml_test_pearson:  0.6776969849153202
===============模型average结果==================
epoch:  256 pearson: ml_test_pearson:  0.7096311652865382
[Epoch 257]
[batch 1] cost: 0.69878775 training pearson: 0.7150212195324303
[batch 2] cost: 0.4744118 training pearson: 0.810011574344075
[batch 3] cost: 0.5739474 training pearson: 0.8338672539951522
[batch 4] cost: 0.62467766 training pearson: 0.7800548012070304
[batch 5] cost: 0.76161057 training pearson: 0.7428984797915251
[batch 6] cost: 0.64596665 training pearson: 0.4814987062655103
[batch 7] cost: 0.64520335 training pearson: 0.7147804877854873
[batch 8] cost: 0.56426984 training pearson: 0.8158352354905176
[batch 9] cost: 0.47022477 training pearson: 0.6804530898766762
[batch 10] cost: 0.5946947 training pearson: 0.7330430814781292
[batch 11] cost: 0.5868492 training pearson: 0.8654776220345475
[batch 12] cost: 0.69349563 training pearson: 0.6048798524620987
[batch 13] cost: 0.64380366 training pearson: 0.7942623378934623
[batch 14] cost: 0.8764555 training pearson: 0.7821628221062623
[batch 15] cost: 0.7341649 training pearson: 0.620448256606939
epoch:  257 pearson: test_pearson:  0.7191739264555683
============gbrt============
epoch:  257 pearson: ml_test_pearson:  0.6925815297131015
============xgb============
epoch:  257 pearson: ml_test_pearson:  0.7101053494184412
============rfr============
epoch:  257 pearson: ml_test_pearson:  0.6598092586953108
===============模型average结果==================
epoch:  257 pearson: ml_test_pearson:  0.6985510424873631
[Epoch 258]
[batch 1] cost: 0.80122113 training pearson: 0.7222459830140453
[batch 2] cost: 0.75367904 training pearson: 0.6344464694558084
[batch 3] cost: 0.62130713 training pearson: 0.8273508886542906
[batch 4] cost: 0.5210723 training pearson: 0.7842592215897908
[batch 5] cost: 0.5871927 training pearson: 0.8532473827907024
[batch 6] cost: 0.8005311 training pearson: 0.6988311631931898
[batch 7] cost: 0.68639314 training pearson: 0.6560662255106662
[batch 8] cost: 0.68776596 training pearson: 0.7685645969599296
[batch 9] cost: 0.7745306 training pearson: 0.7840812771525478
[batch 10] cost: 0.63783824 training pearson: 0.7826289076066119
[batch 11] cost: 0.44277132 training pearson: 0.8079610599776887
[batch 12] cost: 0.45025748 training pearson: 0.8032129176094652
[batch 13] cost: 0.5763804 training pearson: 0.7186009414956397
[batch 14] cost: 0.6586497 training pearson: 0.5602525265854517
[batch 15] cost: 0.6603998 training pearson: 0.7806549125293466
epoch:  258 pearson: test_pearson:  0.7191210599445526
============gbrt============
epoch:  258 pearson: ml_test_pearson:  0.6965044315245024
============xgb============
epoch:  258 pearson: ml_test_pearson:  0.7059896388996819
============rfr============
epoch:  258 pearson: ml_test_pearson:  0.6714380332790135
===============模型average结果==================
epoch:  258 pearson: ml_test_pearson:  0.7067048885830013
[Epoch 259]
[batch 1] cost: 0.53726697 training pearson: 0.7966235898341323
[batch 2] cost: 0.42345193 training pearson: 0.7632033077417335
[batch 3] cost: 0.5350334 training pearson: 0.7686760152821238
[batch 4] cost: 0.69140977 training pearson: 0.719064888608235
[batch 5] cost: 0.51813555 training pearson: 0.7469683946676249
[batch 6] cost: 0.66312486 training pearson: 0.8216278054771564
[batch 7] cost: 0.82627976 training pearson: 0.8025206000197186
[batch 8] cost: 0.652239 training pearson: 0.692445359759513
[batch 9] cost: 0.51810616 training pearson: 0.8108206957004204
[batch 10] cost: 0.46648788 training pearson: 0.828537576983997
[batch 11] cost: 0.5625175 training pearson: 0.7760830435304896
[batch 12] cost: 0.5421827 training pearson: 0.7939220259189581
[batch 13] cost: 0.6989589 training pearson: 0.7160546700086836
[batch 14] cost: 1.0006611 training pearson: 0.5127349877063457
[batch 15] cost: 0.9051309 training pearson: 0.6815937503577963
epoch:  259 pearson: test_pearson:  0.7192523938177751
============gbrt============
epoch:  259 pearson: ml_test_pearson:  0.7076743256154748
============xgb============
epoch:  259 pearson: ml_test_pearson:  0.7166733118202192
============rfr============
epoch:  259 pearson: ml_test_pearson:  0.6613768937822443
===============模型average结果==================
epoch:  259 pearson: ml_test_pearson:  0.7086391827661053
[Epoch 260]
[batch 1] cost: 0.44473374 training pearson: 0.8432806618575206
[batch 2] cost: 0.6035807 training pearson: 0.8059529926536639
[batch 3] cost: 0.47231513 training pearson: 0.7052310763062642
[batch 4] cost: 0.4669568 training pearson: 0.7273225894256236
[batch 5] cost: 0.5730589 training pearson: 0.7788493070682435
[batch 6] cost: 0.5571689 training pearson: 0.8117395693263908
[batch 7] cost: 0.61008006 training pearson: 0.8130548998312586
[batch 8] cost: 0.91281164 training pearson: 0.6933815699644148
[batch 9] cost: 0.7696486 training pearson: 0.7150804066426945
[batch 10] cost: 0.613775 training pearson: 0.8057241137957979
[batch 11] cost: 0.74023527 training pearson: 0.7430030725466158
[batch 12] cost: 0.5770272 training pearson: 0.7545796505082879
[batch 13] cost: 1.0611614 training pearson: 0.6180582015710423
[batch 14] cost: 0.5092104 training pearson: 0.42552824329745675
[batch 15] cost: 0.63228816 training pearson: 0.7782373748329874
epoch:  260 pearson: test_pearson:  0.7191679587276887
============gbrt============
epoch:  260 pearson: ml_test_pearson:  0.693523096737875
============xgb============
epoch:  260 pearson: ml_test_pearson:  0.7077689450134425
============rfr============
epoch:  260 pearson: ml_test_pearson:  0.6723699877571144
===============模型average结果==================
epoch:  260 pearson: ml_test_pearson:  0.7043063109099701
[Epoch 261]
[batch 1] cost: 0.6580027 training pearson: 0.7822751079494704
[batch 2] cost: 0.9583738 training pearson: 0.7044082793753564
[batch 3] cost: 0.59134626 training pearson: 0.6897665209635371
[batch 4] cost: 0.5049776 training pearson: 0.6771731222925529
[batch 5] cost: 0.5264591 training pearson: 0.7030620778420428
[batch 6] cost: 0.8780919 training pearson: 0.730139011535203
[batch 7] cost: 0.5114751 training pearson: 0.820960148327542
[batch 8] cost: 0.6992886 training pearson: 0.7564766793370139
[batch 9] cost: 0.7863437 training pearson: 0.7039809424780686
[batch 10] cost: 0.7361171 training pearson: 0.7474422637730521
[batch 11] cost: 0.500448 training pearson: 0.7757437830920839
[batch 12] cost: 0.80170023 training pearson: 0.7855270904171261
[batch 13] cost: 0.5490311 training pearson: 0.8194177173398908
[batch 14] cost: 0.5759417 training pearson: 0.7798509826965306
[batch 15] cost: 0.34427232 training pearson: 0.8109904210291128
epoch:  261 pearson: test_pearson:  0.7193621599629078
============gbrt============
epoch:  261 pearson: ml_test_pearson:  0.7150065804826398
============xgb============
epoch:  261 pearson: ml_test_pearson:  0.7145972065187549
============rfr============
epoch:  261 pearson: ml_test_pearson:  0.7040402659393761
===============模型average结果==================
epoch:  261 pearson: ml_test_pearson:  0.7276571406759695
[Epoch 262]
[batch 1] cost: 0.43967733 training pearson: 0.6222613133495554
[batch 2] cost: 0.39347556 training pearson: 0.7003569284300013
[batch 3] cost: 0.8450174 training pearson: 0.7140143112489294
[batch 4] cost: 0.62887114 training pearson: 0.8565853301693274
[batch 5] cost: 0.6867139 training pearson: 0.5684525862919588
[batch 6] cost: 1.01136 training pearson: 0.6888063121823466
[batch 7] cost: 0.7016455 training pearson: 0.7588778975107624
[batch 8] cost: 0.9702792 training pearson: 0.7672156836859467
[batch 9] cost: 0.44533825 training pearson: 0.37924339038946936
[batch 10] cost: 0.5821195 training pearson: 0.8038685429768394
[batch 11] cost: 0.45289814 training pearson: 0.7887968028010287
[batch 12] cost: 0.70115936 training pearson: 0.6523105163977817
[batch 13] cost: 0.6512448 training pearson: 0.6996283956355174
[batch 14] cost: 0.43081582 training pearson: 0.843164878976047
[batch 15] cost: 0.63364685 training pearson: 0.8138772408842335
epoch:  262 pearson: test_pearson:  0.7193697637821321
============gbrt============
epoch:  262 pearson: ml_test_pearson:  0.7045909539794086
============xgb============
epoch:  262 pearson: ml_test_pearson:  0.712017669585314
============rfr============
epoch:  262 pearson: ml_test_pearson:  0.6694347314057053
===============模型average结果==================
epoch:  262 pearson: ml_test_pearson:  0.7099154964499144
[Epoch 263]
[batch 1] cost: 0.6181687 training pearson: 0.7170282458386966
[batch 2] cost: 0.46105042 training pearson: 0.7749178942175718
[batch 3] cost: 0.6631565 training pearson: 0.8035728042947888
[batch 4] cost: 0.5654503 training pearson: 0.7431782465549288
[batch 5] cost: 0.82433593 training pearson: 0.6500836489531049
[batch 6] cost: 0.67728454 training pearson: 0.6869102898006562
[batch 7] cost: 0.53959346 training pearson: 0.8786778490026884
[batch 8] cost: 0.58176994 training pearson: 0.6415389081921448
[batch 9] cost: 0.5599018 training pearson: 0.7814040081362001
[batch 10] cost: 0.61815137 training pearson: 0.7195250693827192
[batch 11] cost: 0.727494 training pearson: 0.6363816219837392
[batch 12] cost: 0.690657 training pearson: 0.8458752704790826
[batch 13] cost: 0.74181944 training pearson: 0.7456458694457311
[batch 14] cost: 0.6120341 training pearson: 0.8620624394306177
[batch 15] cost: 0.64839774 training pearson: 0.7569611198513815
epoch:  263 pearson: test_pearson:  0.7191890235626108
============gbrt============
epoch:  263 pearson: ml_test_pearson:  0.6996333208640213
============xgb============
epoch:  263 pearson: ml_test_pearson:  0.7052283941422673
============rfr============
epoch:  263 pearson: ml_test_pearson:  0.6767661168843218
===============模型average结果==================
epoch:  263 pearson: ml_test_pearson:  0.7060234559166395
[Epoch 264]
[batch 1] cost: 1.0603702 training pearson: 0.7639122556947162
[batch 2] cost: 0.7893268 training pearson: 0.6984190971848966
[batch 3] cost: 0.7951336 training pearson: 0.770261176575033
[batch 4] cost: 0.39647725 training pearson: 0.6279059290322494
[batch 5] cost: 0.5223744 training pearson: 0.6382964130299921
[batch 6] cost: 0.5974585 training pearson: 0.7488774613937553
[batch 7] cost: 0.59358025 training pearson: 0.7682952300153584
[batch 8] cost: 0.47094575 training pearson: 0.7663661051438537
[batch 9] cost: 0.59927034 training pearson: 0.7900931665875297
[batch 10] cost: 0.4672376 training pearson: 0.7368618620271302
[batch 11] cost: 0.46840754 training pearson: 0.4414728645331442
[batch 12] cost: 0.5041195 training pearson: 0.841484348533347
[batch 13] cost: 0.9099896 training pearson: 0.7480136338426351
[batch 14] cost: 0.6958436 training pearson: 0.7191721844132533
[batch 15] cost: 0.7395874 training pearson: 0.7681173290593204
epoch:  264 pearson: test_pearson:  0.7193387820089836
============gbrt============
epoch:  264 pearson: ml_test_pearson:  0.7059944851560691
============xgb============
epoch:  264 pearson: ml_test_pearson:  0.7169320257369379
============rfr============
epoch:  264 pearson: ml_test_pearson:  0.6830554149065425
===============模型average结果==================
epoch:  264 pearson: ml_test_pearson:  0.7170075536304134
[Epoch 265]
[batch 1] cost: 0.690763 training pearson: 0.8165897524962727
[batch 2] cost: 0.6514978 training pearson: 0.7400388313326022
[batch 3] cost: 0.7498661 training pearson: 0.800245057415624
[batch 4] cost: 0.43168873 training pearson: 0.634690558808437
[batch 5] cost: 0.9250653 training pearson: 0.791135624787101
[batch 6] cost: 0.46314847 training pearson: 0.8561522313172689
[batch 7] cost: 0.68074095 training pearson: 0.6197434624446857
[batch 8] cost: 0.5402202 training pearson: 0.8131749090993156
[batch 9] cost: 0.5358273 training pearson: 0.5885667096887756
[batch 10] cost: 0.47582287 training pearson: 0.8076818212676278
[batch 11] cost: 0.51018065 training pearson: 0.75949918455903
[batch 12] cost: 0.7387973 training pearson: 0.7704433836342466
[batch 13] cost: 0.6304014 training pearson: 0.6423364309392123
[batch 14] cost: 0.6228881 training pearson: 0.718580255351529
[batch 15] cost: 0.92392373 training pearson: 0.5654528407774249
epoch:  265 pearson: test_pearson:  0.7193934727991042
============gbrt============
epoch:  265 pearson: ml_test_pearson:  0.7087393216211774
============xgb============
epoch:  265 pearson: ml_test_pearson:  0.7121495397975093
============rfr============
epoch:  265 pearson: ml_test_pearson:  0.6940843509899031
===============模型average结果==================
epoch:  265 pearson: ml_test_pearson:  0.7206006866858026
[Epoch 266]
[batch 1] cost: 0.7035507 training pearson: 0.7047554676054736
[batch 2] cost: 0.6978897 training pearson: 0.7339848685895285
[batch 3] cost: 0.51987463 training pearson: 0.8443599648617258
[batch 4] cost: 0.6725902 training pearson: 0.7710054468608006
[batch 5] cost: 0.5610859 training pearson: 0.6295325360734724
[batch 6] cost: 0.5672185 training pearson: 0.7547523485726614
[batch 7] cost: 0.41489285 training pearson: 0.6979710978788164
[batch 8] cost: 0.8163957 training pearson: 0.7510731859261786
[batch 9] cost: 0.5953215 training pearson: 0.792318966109279
[batch 10] cost: 0.7874685 training pearson: 0.7395275453303136
[batch 11] cost: 0.7762449 training pearson: 0.7414405598684674
[batch 12] cost: 0.7044547 training pearson: 0.7603197048028609
[batch 13] cost: 0.59819245 training pearson: 0.7856381317827972
[batch 14] cost: 0.5658114 training pearson: 0.7367722924309021
[batch 15] cost: 0.5618817 training pearson: 0.688460290423101
epoch:  266 pearson: test_pearson:  0.7194363773477882
============gbrt============
epoch:  266 pearson: ml_test_pearson:  0.6976055201338308
============xgb============
epoch:  266 pearson: ml_test_pearson:  0.71753259651204
============rfr============
epoch:  266 pearson: ml_test_pearson:  0.6615729653104567
===============模型average结果==================
epoch:  266 pearson: ml_test_pearson:  0.7056630473752636
[Epoch 267]
[batch 1] cost: 0.4737835 training pearson: 0.5204002407925629
[batch 2] cost: 0.567701 training pearson: 0.8289547238170798
[batch 3] cost: 0.85991114 training pearson: 0.8157693167355061
[batch 4] cost: 0.5338461 training pearson: 0.6837863574605778
[batch 5] cost: 0.601435 training pearson: 0.8064489983345526
[batch 6] cost: 0.53763723 training pearson: 0.6730288958167032
[batch 7] cost: 0.5006028 training pearson: 0.8177067042006829
[batch 8] cost: 0.5146887 training pearson: 0.8789267667689964
[batch 9] cost: 0.46138802 training pearson: 0.8243752249820222
[batch 10] cost: 0.7986342 training pearson: 0.7630876544701767
[batch 11] cost: 0.8811248 training pearson: 0.6570543041887
[batch 12] cost: 0.75967246 training pearson: 0.6872835151550957
[batch 13] cost: 0.7691209 training pearson: 0.6416023991406153
[batch 14] cost: 0.58924985 training pearson: 0.5675112567871022
[batch 15] cost: 0.6484509 training pearson: 0.774580055280871
epoch:  267 pearson: test_pearson:  0.7194239056516172
============gbrt============
epoch:  267 pearson: ml_test_pearson:  0.6948176475280897
============xgb============
epoch:  267 pearson: ml_test_pearson:  0.7165150509560066
============rfr============
epoch:  267 pearson: ml_test_pearson:  0.6539781670552426
===============模型average结果==================
epoch:  267 pearson: ml_test_pearson:  0.7018177367617451
[Epoch 268]
[batch 1] cost: 0.6750801 training pearson: 0.7727426214611446
[batch 2] cost: 0.5556316 training pearson: 0.583708132665896
[batch 3] cost: 0.68493575 training pearson: 0.7211835618929252
[batch 4] cost: 0.37266907 training pearson: 0.7759977677601652
[batch 5] cost: 0.53033125 training pearson: 0.7929674774528307
[batch 6] cost: 0.6261844 training pearson: 0.8133201184714032
[batch 7] cost: 1.0731423 training pearson: 0.6829722873160976
[batch 8] cost: 0.50750214 training pearson: 0.7727583464625476
[batch 9] cost: 0.5108964 training pearson: 0.7885137063403965
[batch 10] cost: 0.6796132 training pearson: 0.7359781856199227
[batch 11] cost: 0.46892557 training pearson: 0.7068029875635566
[batch 12] cost: 0.777425 training pearson: 0.7793702982842396
[batch 13] cost: 0.7442619 training pearson: 0.6770815092639495
[batch 14] cost: 0.7386587 training pearson: 0.7488960104598074
[batch 15] cost: 0.54471797 training pearson: 0.7894711318093345
epoch:  268 pearson: test_pearson:  0.7194619699975082
============gbrt============
epoch:  268 pearson: ml_test_pearson:  0.7018474421631192
============xgb============
epoch:  268 pearson: ml_test_pearson:  0.7179552878476664
============rfr============
epoch:  268 pearson: ml_test_pearson:  0.6750386441035899
===============模型average结果==================
epoch:  268 pearson: ml_test_pearson:  0.7112477835057831
[Epoch 269]
[batch 1] cost: 0.6004343 training pearson: 0.7047698120901854
[batch 2] cost: 0.92545867 training pearson: 0.5101838906057019
[batch 3] cost: 0.6060602 training pearson: 0.7491298570450059
[batch 4] cost: 0.64915544 training pearson: 0.791944591137154
[batch 5] cost: 0.58425677 training pearson: 0.8107440966002042
[batch 6] cost: 0.5103154 training pearson: 0.7548336330239813
[batch 7] cost: 0.44460663 training pearson: 0.7649963955240071
[batch 8] cost: 0.51649386 training pearson: 0.6863500455428322
[batch 9] cost: 0.8430257 training pearson: 0.6993603572139365
[batch 10] cost: 0.77385545 training pearson: 0.8080125426192749
[batch 11] cost: 0.45996895 training pearson: 0.7464642723192682
[batch 12] cost: 0.6153401 training pearson: 0.7130084281020367
[batch 13] cost: 0.7797509 training pearson: 0.8152324210964585
[batch 14] cost: 0.63671 training pearson: 0.7795568716731254
[batch 15] cost: 0.55244505 training pearson: 0.7504075858065855
epoch:  269 pearson: test_pearson:  0.7194963489553164
============gbrt============
epoch:  269 pearson: ml_test_pearson:  0.6959481568060821
============xgb============
epoch:  269 pearson: ml_test_pearson:  0.7245217729545766
============rfr============
epoch:  269 pearson: ml_test_pearson:  0.6400062378860399
===============模型average结果==================
epoch:  269 pearson: ml_test_pearson:  0.6959303672704821
[Epoch 270]
[batch 1] cost: 0.4452778 training pearson: 0.8504522171436046
[batch 2] cost: 0.59435564 training pearson: 0.7904165680213014
[batch 3] cost: 0.82616925 training pearson: 0.6492402010432354
[batch 4] cost: 0.5795496 training pearson: 0.7886378156810543
[batch 5] cost: 0.56172734 training pearson: 0.7357142878841724
[batch 6] cost: 0.42623535 training pearson: 0.8040846952240746
[batch 7] cost: 0.73707306 training pearson: 0.7792297520863252
[batch 8] cost: 0.85369563 training pearson: 0.6076069021885372
[batch 9] cost: 0.41755754 training pearson: 0.7387647755793194
[batch 10] cost: 0.9553226 training pearson: 0.7215353827536327
[batch 11] cost: 0.7269034 training pearson: 0.6271851368388859
[batch 12] cost: 0.5752733 training pearson: 0.8611124627795286
[batch 13] cost: 0.53444135 training pearson: 0.7388533342180776
[batch 14] cost: 0.72390616 training pearson: 0.6350187570319368
[batch 15] cost: 0.5647304 training pearson: 0.778485774659984
epoch:  270 pearson: test_pearson:  0.7194519244379399
============gbrt============
epoch:  270 pearson: ml_test_pearson:  0.6974165202509057
============xgb============
epoch:  270 pearson: ml_test_pearson:  0.7163636643071195
============rfr============
epoch:  270 pearson: ml_test_pearson:  0.6295786344949104
===============模型average结果==================
epoch:  270 pearson: ml_test_pearson:  0.6898347960625332
[Epoch 271]
[batch 1] cost: 0.75813985 training pearson: 0.8214981684690607
[batch 2] cost: 1.0111989 training pearson: 0.4308364873161716
[batch 3] cost: 0.4467765 training pearson: 0.7449051813413158
[batch 4] cost: 0.5665591 training pearson: 0.7044572634218738
[batch 5] cost: 0.5596298 training pearson: 0.8031699815950508
[batch 6] cost: 0.63124746 training pearson: 0.7950769788036183
[batch 7] cost: 0.73561186 training pearson: 0.6831878098995205
[batch 8] cost: 0.6524476 training pearson: 0.7781423747734928
[batch 9] cost: 0.75243616 training pearson: 0.7251434455803965
[batch 10] cost: 0.40906465 training pearson: 0.8806001980200951
[batch 11] cost: 0.5612181 training pearson: 0.7326924287735073
[batch 12] cost: 0.6219713 training pearson: 0.7826763391838075
[batch 13] cost: 0.49935386 training pearson: 0.7568065226509915
[batch 14] cost: 0.51647943 training pearson: 0.7454242210890304
[batch 15] cost: 0.76691896 training pearson: 0.7811261022315485
epoch:  271 pearson: test_pearson:  0.7194150051589666
============gbrt============
epoch:  271 pearson: ml_test_pearson:  0.7049705092827114
============xgb============
epoch:  271 pearson: ml_test_pearson:  0.7202149682041437
============rfr============
epoch:  271 pearson: ml_test_pearson:  0.6614861309675485
===============模型average结果==================
epoch:  271 pearson: ml_test_pearson:  0.7075767011463485
[Epoch 272]
[batch 1] cost: 0.44652835 training pearson: 0.8874168867016442
[batch 2] cost: 0.6772839 training pearson: 0.7019188167514091
[batch 3] cost: 0.62783563 training pearson: 0.7416614577552774
[batch 4] cost: 0.64469445 training pearson: 0.848321747744351
[batch 5] cost: 0.784514 training pearson: 0.7367777636336279
[batch 6] cost: 0.531427 training pearson: 0.672933526315021
[batch 7] cost: 0.64711034 training pearson: 0.43735350672000756
[batch 8] cost: 0.5599919 training pearson: 0.7344222625813881
[batch 9] cost: 0.79343027 training pearson: 0.7702661668529056
[batch 10] cost: 0.69482785 training pearson: 0.8415955637006386
[batch 11] cost: 0.7772076 training pearson: 0.5910909884869006
[batch 12] cost: 0.6237912 training pearson: 0.8284736994996249
[batch 13] cost: 0.35393023 training pearson: 0.7689701665338685
[batch 14] cost: 0.73423105 training pearson: 0.6769977613358016
[batch 15] cost: 0.6377147 training pearson: 0.8343515632102572
epoch:  272 pearson: test_pearson:  0.7194999678464262
============gbrt============
epoch:  272 pearson: ml_test_pearson:  0.7014443896577243
============xgb============
epoch:  272 pearson: ml_test_pearson:  0.7258028454716912
============rfr============
epoch:  272 pearson: ml_test_pearson:  0.6526429563517399
===============模型average结果==================
epoch:  272 pearson: ml_test_pearson:  0.7053075289623711
[Epoch 273]
[batch 1] cost: 0.7535245 training pearson: 0.8056250902763739
[batch 2] cost: 0.73018765 training pearson: 0.5757410080451469
[batch 3] cost: 0.66480726 training pearson: 0.7380206981053151
[batch 4] cost: 0.56695515 training pearson: 0.7661684676744254
[batch 5] cost: 0.7157263 training pearson: 0.7897722991541023
[batch 6] cost: 0.6485188 training pearson: 0.7232713890011472
[batch 7] cost: 0.42932433 training pearson: 0.5958883358817121
[batch 8] cost: 0.4764669 training pearson: 0.8172732590625805
[batch 9] cost: 0.9689241 training pearson: 0.688111947923009
[batch 10] cost: 0.5967503 training pearson: 0.7413086550714677
[batch 11] cost: 0.49568152 training pearson: 0.8419373662730975
[batch 12] cost: 0.5608973 training pearson: 0.7047833854883616
[batch 13] cost: 0.5028916 training pearson: 0.5842049812803161
[batch 14] cost: 0.5906133 training pearson: 0.8403851370496217
[batch 15] cost: 0.7708443 training pearson: 0.7476147154059078
epoch:  273 pearson: test_pearson:  0.7191730842048446
============gbrt============
epoch:  273 pearson: ml_test_pearson:  0.6951481876965071
============xgb============
epoch:  273 pearson: ml_test_pearson:  0.7233533993001084
============rfr============
epoch:  273 pearson: ml_test_pearson:  0.6676071136124746
===============模型average结果==================
epoch:  273 pearson: ml_test_pearson:  0.7058174967446011
[Epoch 274]
[batch 1] cost: 0.9250862 training pearson: 0.7698004826746344
[batch 2] cost: 0.44251555 training pearson: 0.8480210463799159
[batch 3] cost: 0.6325964 training pearson: 0.799430608195897
[batch 4] cost: 0.51886255 training pearson: 0.7239039897325066
[batch 5] cost: 0.4698664 training pearson: 0.6858910615995695
[batch 6] cost: 0.65966254 training pearson: 0.7508326723214228
[batch 7] cost: 0.6480298 training pearson: 0.7345038343901025
[batch 8] cost: 0.66743314 training pearson: 0.8042998454372408
[batch 9] cost: 0.4760759 training pearson: 0.7693917118097022
[batch 10] cost: 0.80642515 training pearson: 0.663491337641661
[batch 11] cost: 0.69976157 training pearson: 0.6229707058925676
[batch 12] cost: 0.59048086 training pearson: 0.8196096144423017
[batch 13] cost: 0.5835128 training pearson: 0.7749988458712962
[batch 14] cost: 0.56734717 training pearson: 0.7237444724241969
[batch 15] cost: 0.81486875 training pearson: 0.4805307068685584
epoch:  274 pearson: test_pearson:  0.7194679937150389
============gbrt============
epoch:  274 pearson: ml_test_pearson:  0.7008359850281771
============xgb============
epoch:  274 pearson: ml_test_pearson:  0.709026577928475
============rfr============
epoch:  274 pearson: ml_test_pearson:  0.6609676682315092
===============模型average结果==================
epoch:  274 pearson: ml_test_pearson:  0.7065039276054879
[Epoch 275]
[batch 1] cost: 0.5453869 training pearson: 0.8324375877354385
[batch 2] cost: 0.8705198 training pearson: 0.6729626306233254
[batch 3] cost: 0.4526351 training pearson: 0.8283043926750262
[batch 4] cost: 0.57692087 training pearson: 0.7503856836437087
[batch 5] cost: 0.43675262 training pearson: 0.7242580026744555
[batch 6] cost: 0.88122255 training pearson: 0.8026053154208864
[batch 7] cost: 0.5712444 training pearson: 0.7699992313595488
[batch 8] cost: 0.64294356 training pearson: 0.7420381587014232
[batch 9] cost: 0.4864069 training pearson: 0.6923049436855915
[batch 10] cost: 0.65234345 training pearson: 0.7222064700856337
[batch 11] cost: 0.8931668 training pearson: 0.7773637709275096
[batch 12] cost: 0.8142694 training pearson: 0.4479015390133491
[batch 13] cost: 0.57608134 training pearson: 0.7533595064394512
[batch 14] cost: 0.65121704 training pearson: 0.728814520381133
[batch 15] cost: 0.45047534 training pearson: 0.8640568506511582
epoch:  275 pearson: test_pearson:  0.7195969079454394
============gbrt============
epoch:  275 pearson: ml_test_pearson:  0.7046116607806319
============xgb============
epoch:  275 pearson: ml_test_pearson:  0.7208897276011952
============rfr============
epoch:  275 pearson: ml_test_pearson:  0.6897513158417211
===============模型average结果==================
epoch:  275 pearson: ml_test_pearson:  0.7206801435381933
[Epoch 276]
[batch 1] cost: 0.5281777 training pearson: 0.7857311318299836
[batch 2] cost: 0.8067946 training pearson: 0.6955457799085744
[batch 3] cost: 0.7731755 training pearson: 0.7563070150020732
[batch 4] cost: 0.58816093 training pearson: 0.7155939376524373
[batch 5] cost: 0.65009004 training pearson: 0.7930415290565973
[batch 6] cost: 0.6084499 training pearson: 0.7358649716583654
[batch 7] cost: 0.56942964 training pearson: 0.7686098737565221
[batch 8] cost: 0.6423756 training pearson: 0.7636778524225852
[batch 9] cost: 0.5344791 training pearson: 0.7978134102404919
[batch 10] cost: 0.49721375 training pearson: 0.8736986044570706
[batch 11] cost: 0.6640086 training pearson: 0.5125780771134961
[batch 12] cost: 0.5097081 training pearson: 0.7459036781214313
[batch 13] cost: 0.75735945 training pearson: 0.7013555432952456
[batch 14] cost: 0.79195434 training pearson: 0.7499278451717198
[batch 15] cost: 0.5747528 training pearson: 0.7451783210478947
epoch:  276 pearson: test_pearson:  0.7196170867510104
============gbrt============
epoch:  276 pearson: ml_test_pearson:  0.704442499215835
============xgb============
epoch:  276 pearson: ml_test_pearson:  0.7272859625427082
============rfr============
epoch:  276 pearson: ml_test_pearson:  0.6745314204824965
===============模型average结果==================
epoch:  276 pearson: ml_test_pearson:  0.7159103982702502
[Epoch 277]
[batch 1] cost: 0.43074685 training pearson: 0.8302946060306574
[batch 2] cost: 0.5565755 training pearson: 0.7734475948605004
[batch 3] cost: 0.44794166 training pearson: 0.762508038932688
[batch 4] cost: 0.52447504 training pearson: 0.7036856862366427
[batch 5] cost: 0.6843524 training pearson: 0.7729028634384199
[batch 6] cost: 0.79570603 training pearson: 0.6402859026933297
[batch 7] cost: 0.44825476 training pearson: 0.7071115313484648
[batch 8] cost: 0.86353624 training pearson: 0.7947169246993181
[batch 9] cost: 0.5930131 training pearson: 0.7557499993823478
[batch 10] cost: 0.8536394 training pearson: 0.8179747555020186
[batch 11] cost: 0.7446099 training pearson: 0.6533278191179858
[batch 12] cost: 0.67886925 training pearson: 0.6862049674462543
[batch 13] cost: 0.6710142 training pearson: 0.6646999768282452
[batch 14] cost: 0.7264357 training pearson: 0.8097568676062014
[batch 15] cost: 0.57184905 training pearson: 0.8253825673602004
epoch:  277 pearson: test_pearson:  0.719588028187824
============gbrt============
epoch:  277 pearson: ml_test_pearson:  0.6992618236677576
============xgb============
epoch:  277 pearson: ml_test_pearson:  0.723184487624001
============rfr============
epoch:  277 pearson: ml_test_pearson:  0.6615449149444443
===============模型average结果==================
epoch:  277 pearson: ml_test_pearson:  0.7050488055357034
[Epoch 278]
[batch 1] cost: 0.8009765 training pearson: 0.675407247020387
[batch 2] cost: 0.5864247 training pearson: 0.7429736247879453
[batch 3] cost: 0.45798674 training pearson: 0.831796102432992
[batch 4] cost: 0.4524573 training pearson: 0.8411659999881794
[batch 5] cost: 0.50788736 training pearson: 0.7658748630733944
[batch 6] cost: 0.782916 training pearson: 0.7415969303238077
[batch 7] cost: 0.6691501 training pearson: 0.7783676789256216
[batch 8] cost: 0.68346894 training pearson: 0.8178018026180301
[batch 9] cost: 0.6409614 training pearson: 0.851867471335787
[batch 10] cost: 0.423773 training pearson: 0.7693894678143989
[batch 11] cost: 0.88482696 training pearson: 0.721044858564566
[batch 12] cost: 0.6574858 training pearson: 0.7577651141433009
[batch 13] cost: 0.95043284 training pearson: 0.25642267159976484
[batch 14] cost: 0.50771415 training pearson: 0.5503772827488806
[batch 15] cost: 0.4481194 training pearson: 0.8370235596866747
epoch:  278 pearson: test_pearson:  0.7196511345435421
============gbrt============
epoch:  278 pearson: ml_test_pearson:  0.7052257900897364
============xgb============
epoch:  278 pearson: ml_test_pearson:  0.7250106345848996
============rfr============
epoch:  278 pearson: ml_test_pearson:  0.6750364037235403
===============模型average结果==================
epoch:  278 pearson: ml_test_pearson:  0.7150348905450576
[Epoch 279]
[batch 1] cost: 0.76965314 training pearson: 0.3273651283192279
[batch 2] cost: 0.6239954 training pearson: 0.8072409670865895
[batch 3] cost: 0.53206426 training pearson: 0.8197203104293107
[batch 4] cost: 0.94270456 training pearson: 0.7709846160006443
[batch 5] cost: 0.5216031 training pearson: 0.8322800903986052
[batch 6] cost: 0.7815156 training pearson: 0.7051414383201702
[batch 7] cost: 0.49545303 training pearson: 0.7282598804273634
[batch 8] cost: 0.8144681 training pearson: 0.6133531420656944
[batch 9] cost: 0.6331078 training pearson: 0.7231164116247625
[batch 10] cost: 0.53150004 training pearson: 0.792183628683253
[batch 11] cost: 0.5934227 training pearson: 0.5529211417518836
[batch 12] cost: 0.6498117 training pearson: 0.859944827551432
[batch 13] cost: 0.66921586 training pearson: 0.6906466661462966
[batch 14] cost: 0.5629724 training pearson: 0.8135047738579847
[batch 15] cost: 0.41280738 training pearson: 0.8664936798430584
epoch:  279 pearson: test_pearson:  0.7195388420966834
============gbrt============
epoch:  279 pearson: ml_test_pearson:  0.6951926471571519
============xgb============
epoch:  279 pearson: ml_test_pearson:  0.7268633498341616
============rfr============
epoch:  279 pearson: ml_test_pearson:  0.6797278852602628
===============模型average结果==================
epoch:  279 pearson: ml_test_pearson:  0.7147207779858965
[Epoch 280]
[batch 1] cost: 0.85458493 training pearson: 0.6398259922936238
[batch 2] cost: 0.5198328 training pearson: 0.6527239176148238
[batch 3] cost: 0.87369776 training pearson: 0.7487018477685496
[batch 4] cost: 0.4688484 training pearson: 0.8145871170358112
[batch 5] cost: 0.42006278 training pearson: 0.8158931475510022
[batch 6] cost: 0.60093415 training pearson: 0.8136964409804454
[batch 7] cost: 0.6349366 training pearson: 0.7014377909169935
[batch 8] cost: 0.56307703 training pearson: 0.8054245504382915
[batch 9] cost: 0.65446335 training pearson: 0.7145941468536969
[batch 10] cost: 0.63080275 training pearson: 0.8254127601888221
[batch 11] cost: 0.47422227 training pearson: 0.7755301704376283
[batch 12] cost: 0.76652044 training pearson: 0.765792956683356
[batch 13] cost: 0.78385925 training pearson: 0.7069850975152289
[batch 14] cost: 0.6585576 training pearson: 0.7625827961014828
[batch 15] cost: 0.5569142 training pearson: 0.5913762396436537
epoch:  280 pearson: test_pearson:  0.7196699004420011
============gbrt============
epoch:  280 pearson: ml_test_pearson:  0.7004518833653133
============xgb============
epoch:  280 pearson: ml_test_pearson:  0.7225421694280699
============rfr============
epoch:  280 pearson: ml_test_pearson:  0.6673673946365103
===============模型average结果==================
epoch:  280 pearson: ml_test_pearson:  0.7088534524562783
[Epoch 281]
[batch 1] cost: 0.4926664 training pearson: 0.8510050030150337
[batch 2] cost: 0.6426588 training pearson: 0.5427232696418884
[batch 3] cost: 0.6397896 training pearson: 0.47069904009268965
[batch 4] cost: 0.58571875 training pearson: 0.6044121401530779
[batch 5] cost: 0.7298346 training pearson: 0.7325527725758774
[batch 6] cost: 0.61835474 training pearson: 0.7846143214806561
[batch 7] cost: 0.84064454 training pearson: 0.7089947604929144
[batch 8] cost: 0.5501309 training pearson: 0.7845415654952413
[batch 9] cost: 0.6186703 training pearson: 0.7846280617098875
[batch 10] cost: 0.63598603 training pearson: 0.7386443070954277
[batch 11] cost: 0.4277776 training pearson: 0.8363923842153325
[batch 12] cost: 0.5719362 training pearson: 0.8048620621562886
[batch 13] cost: 0.50301886 training pearson: 0.8067147198737832
[batch 14] cost: 0.65289503 training pearson: 0.7977832711489257
[batch 15] cost: 0.8943585 training pearson: 0.6926339556858383
epoch:  281 pearson: test_pearson:  0.7198443290314539
============gbrt============
epoch:  281 pearson: ml_test_pearson:  0.6979218666600849
============xgb============
epoch:  281 pearson: ml_test_pearson:  0.722725306020937
============rfr============
epoch:  281 pearson: ml_test_pearson:  0.6477973536319923
===============模型average结果==================
epoch:  281 pearson: ml_test_pearson:  0.7014932427523627
[Epoch 282]
[batch 1] cost: 0.7786064 training pearson: 0.5941416806641374
[batch 2] cost: 0.65458226 training pearson: 0.6551112682019118
[batch 3] cost: 0.5457124 training pearson: 0.7059287552964363
[batch 4] cost: 0.51151276 training pearson: 0.6811575835379844
[batch 5] cost: 0.73782355 training pearson: 0.7858593171892271
[batch 6] cost: 0.48256275 training pearson: 0.8118425899805701
[batch 7] cost: 0.42936242 training pearson: 0.7793344960168314
[batch 8] cost: 0.6722984 training pearson: 0.6604820632406693
[batch 9] cost: 0.4727757 training pearson: 0.7718571304786584
[batch 10] cost: 0.67210907 training pearson: 0.6801632221023525
[batch 11] cost: 0.95818955 training pearson: 0.7765043279610714
[batch 12] cost: 0.6841144 training pearson: 0.7974242447389374
[batch 13] cost: 0.48129588 training pearson: 0.8821300756971932
[batch 14] cost: 0.8328506 training pearson: 0.7068550661663271
[batch 15] cost: 0.5331467 training pearson: 0.7789194839054462
epoch:  282 pearson: test_pearson:  0.7194664818025133
============gbrt============
epoch:  282 pearson: ml_test_pearson:  0.6988215106692203
============xgb============
epoch:  282 pearson: ml_test_pearson:  0.7215680094533924
============rfr============
epoch:  282 pearson: ml_test_pearson:  0.6574692021989228
===============模型average结果==================
epoch:  282 pearson: ml_test_pearson:  0.7027296404954384
[Epoch 283]
[batch 1] cost: 0.57076335 training pearson: 0.8102730719724002
[batch 2] cost: 0.86178327 training pearson: 0.7415544830465643
[batch 3] cost: 0.5773439 training pearson: 0.7100412992885464
[batch 4] cost: 0.5162365 training pearson: 0.8504197669868453
[batch 5] cost: 0.72759354 training pearson: 0.5388921464606279
[batch 6] cost: 0.40038037 training pearson: 0.652357057009222
[batch 7] cost: 0.59989554 training pearson: 0.7767926477743032
[batch 8] cost: 0.75280786 training pearson: 0.6687948578518158
[batch 9] cost: 0.6043094 training pearson: 0.7830170027037617
[batch 10] cost: 0.59143865 training pearson: 0.7501087551050202
[batch 11] cost: 0.7608765 training pearson: 0.6688427543964446
[batch 12] cost: 0.8669281 training pearson: 0.8491813636324272
[batch 13] cost: 0.6243043 training pearson: 0.792449019204826
[batch 14] cost: 0.53780526 training pearson: 0.7468665671085983
[batch 15] cost: 0.5116256 training pearson: 0.7404226644344056
epoch:  283 pearson: test_pearson:  0.7196097051404413
============gbrt============
epoch:  283 pearson: ml_test_pearson:  0.7084379801332362
============xgb============
epoch:  283 pearson: ml_test_pearson:  0.7191587159635645
============rfr============
epoch:  283 pearson: ml_test_pearson:  0.6812479356393624
===============模型average结果==================
epoch:  283 pearson: ml_test_pearson:  0.7180486861648625
[Epoch 284]
[batch 1] cost: 0.63420266 training pearson: 0.687370377471946
[batch 2] cost: 0.6115796 training pearson: 0.6969200982048808
[batch 3] cost: 0.60338473 training pearson: 0.8000740678950236
[batch 4] cost: 0.67666644 training pearson: 0.7584573525670877
[batch 5] cost: 0.7688629 training pearson: 0.7588620251839602
[batch 6] cost: 0.70725477 training pearson: 0.6944080984472365
[batch 7] cost: 0.5873102 training pearson: 0.7627183927268081
[batch 8] cost: 0.6932224 training pearson: 0.7385941977803897
[batch 9] cost: 0.4779516 training pearson: 0.7656316329334638
[batch 10] cost: 0.7431448 training pearson: 0.7951758319682813
[batch 11] cost: 0.7321075 training pearson: 0.6232129079879059
[batch 12] cost: 0.68893874 training pearson: 0.7394060938491189
[batch 13] cost: 0.5037596 training pearson: 0.8810410172825356
[batch 14] cost: 0.5198816 training pearson: 0.808457722755383
[batch 15] cost: 0.5034035 training pearson: 0.7750094358124683
epoch:  284 pearson: test_pearson:  0.7196942938832666
============gbrt============
epoch:  284 pearson: ml_test_pearson:  0.6996840870925118
============xgb============
epoch:  284 pearson: ml_test_pearson:  0.710746743221585
============rfr============
epoch:  284 pearson: ml_test_pearson:  0.6663422696865553
===============模型average结果==================
epoch:  284 pearson: ml_test_pearson:  0.7043703083784316
[Epoch 285]
[batch 1] cost: 0.5353959 training pearson: 0.7147223582038768
[batch 2] cost: 0.860202 training pearson: 0.7048631671368316
[batch 3] cost: 0.73936236 training pearson: 0.7925897965396858
[batch 4] cost: 0.4687149 training pearson: 0.8776776604561614
[batch 5] cost: 0.39307362 training pearson: 0.6470503713502314
[batch 6] cost: 0.64520323 training pearson: 0.7889918628598613
[batch 7] cost: 0.42137155 training pearson: 0.8102740020561541
[batch 8] cost: 0.9073024 training pearson: 0.6871174345385054
[batch 9] cost: 0.54943144 training pearson: 0.6778742085181461
[batch 10] cost: 0.73638326 training pearson: 0.7948070420727676
[batch 11] cost: 0.8715217 training pearson: 0.6552349265901606
[batch 12] cost: 0.71180105 training pearson: 0.7305575724561562
[batch 13] cost: 0.50047475 training pearson: 0.811563071477123
[batch 14] cost: 0.71332544 training pearson: 0.7374936274258096
[batch 15] cost: 0.41648942 training pearson: 0.7992467146934848
epoch:  285 pearson: test_pearson:  0.7196167651456505
============gbrt============
epoch:  285 pearson: ml_test_pearson:  0.696390696638575
============xgb============
epoch:  285 pearson: ml_test_pearson:  0.7110985186794971
============rfr============
epoch:  285 pearson: ml_test_pearson:  0.6648032301836831
===============模型average结果==================
epoch:  285 pearson: ml_test_pearson:  0.7029128511829488
[Epoch 286]
[batch 1] cost: 0.63124514 training pearson: 0.7784020615609736
[batch 2] cost: 0.684252 training pearson: 0.7927300636581825
[batch 3] cost: 0.31988353 training pearson: 0.6897893272021617
[batch 4] cost: 0.8545625 training pearson: 0.797632317962679
[batch 5] cost: 0.9786951 training pearson: 0.6080245625968839
[batch 6] cost: 0.99117494 training pearson: 0.7056094189171424
[batch 7] cost: 0.6026142 training pearson: 0.7087485329340549
[batch 8] cost: 0.4982605 training pearson: 0.6731152609946568
[batch 9] cost: 0.78188 training pearson: 0.7555822972173108
[batch 10] cost: 0.59762 training pearson: 0.8046677796431262
[batch 11] cost: 0.5452186 training pearson: 0.7878242608671515
[batch 12] cost: 0.4432827 training pearson: 0.6960304585489807
[batch 13] cost: 0.52026445 training pearson: 0.8174514310784953
[batch 14] cost: 0.49882033 training pearson: 0.76441840812882
[batch 15] cost: 0.46330756 training pearson: 0.8415627573556013
epoch:  286 pearson: test_pearson:  0.7196301759317489
============gbrt============
epoch:  286 pearson: ml_test_pearson:  0.6934300164164346
============xgb============
epoch:  286 pearson: ml_test_pearson:  0.7041389472645242
============rfr============
epoch:  286 pearson: ml_test_pearson:  0.6668588454229789
===============模型average结果==================
epoch:  286 pearson: ml_test_pearson:  0.7017599565100044
[Epoch 287]
[batch 1] cost: 1.0217615 training pearson: 0.7060620084948098
[batch 2] cost: 0.49141392 training pearson: 0.77651237516141
[batch 3] cost: 0.7508342 training pearson: 0.7544509216864248
[batch 4] cost: 0.453293 training pearson: 0.4823126629566588
[batch 5] cost: 0.53448623 training pearson: 0.5657173974637889
[batch 6] cost: 0.57626444 training pearson: 0.724346436759691
[batch 7] cost: 0.68425214 training pearson: 0.6829691960211453
[batch 8] cost: 0.50771123 training pearson: 0.7909918619625184
[batch 9] cost: 0.6284104 training pearson: 0.826022330882501
[batch 10] cost: 0.62846774 training pearson: 0.8008098133324549
[batch 11] cost: 0.8718293 training pearson: 0.7775647173007141
[batch 12] cost: 0.6469264 training pearson: 0.7745367843977293
[batch 13] cost: 0.57016844 training pearson: 0.8201206688112861
[batch 14] cost: 0.58961904 training pearson: 0.7017738266982687
[batch 15] cost: 0.5030445 training pearson: 0.8221233897325051
epoch:  287 pearson: test_pearson:  0.7196063365045551
============gbrt============
epoch:  287 pearson: ml_test_pearson:  0.7044347966124517
============xgb============
epoch:  287 pearson: ml_test_pearson:  0.7122324337118272
============rfr============
epoch:  287 pearson: ml_test_pearson:  0.6668240600202392
===============模型average结果==================
epoch:  287 pearson: ml_test_pearson:  0.7061395444986165
[Epoch 288]
[batch 1] cost: 0.44308308 training pearson: 0.8554540471610792
[batch 2] cost: 0.7094105 training pearson: 0.7289052266201226
[batch 3] cost: 0.6263817 training pearson: 0.7765452642845712
[batch 4] cost: 0.5408221 training pearson: 0.7826490577792112
[batch 5] cost: 0.8646849 training pearson: 0.5223547034581064
[batch 6] cost: 0.57269037 training pearson: 0.7710670827084597
[batch 7] cost: 0.5065485 training pearson: 0.8306765821881684
[batch 8] cost: 0.9892779 training pearson: 0.6434745977594397
[batch 9] cost: 0.47931585 training pearson: 0.7517613869910468
[batch 10] cost: 0.5162928 training pearson: 0.695993978939138
[batch 11] cost: 0.75670075 training pearson: 0.8184011747291109
[batch 12] cost: 0.48995027 training pearson: 0.8250736108067642
[batch 13] cost: 0.60665804 training pearson: 0.7310257705991086
[batch 14] cost: 0.99760604 training pearson: 0.6611292323460626
[batch 15] cost: 0.47301704 training pearson: 0.8465564438064637
epoch:  288 pearson: test_pearson:  0.7197774180223336
============gbrt============
epoch:  288 pearson: ml_test_pearson:  0.7078009668876072
============xgb============
epoch:  288 pearson: ml_test_pearson:  0.7068138957598412
============rfr============
epoch:  288 pearson: ml_test_pearson:  0.662224074882135
===============模型average结果==================
epoch:  288 pearson: ml_test_pearson:  0.7023122060211886
[Epoch 289]
[batch 1] cost: 0.6705169 training pearson: 0.771923621080844
[batch 2] cost: 0.9346834 training pearson: 0.652901064964993
[batch 3] cost: 0.62389916 training pearson: 0.7843170545911078
[batch 4] cost: 0.5435966 training pearson: 0.7564924356718187
[batch 5] cost: 0.5099694 training pearson: 0.809137562504486
[batch 6] cost: 0.7312286 training pearson: 0.6633069930821344
[batch 7] cost: 0.5530659 training pearson: 0.8658985064352442
[batch 8] cost: 0.518915 training pearson: 0.7448205876851873
[batch 9] cost: 0.6004868 training pearson: 0.7335556090893964
[batch 10] cost: 0.8229517 training pearson: 0.6431975015365886
[batch 11] cost: 0.41933286 training pearson: 0.7438737719494508
[batch 12] cost: 0.6467869 training pearson: 0.6790083142227878
[batch 13] cost: 0.5187771 training pearson: 0.8124680903507343
[batch 14] cost: 0.5916322 training pearson: 0.7024925615238848
[batch 15] cost: 0.93145365 training pearson: 0.7899426891068818
epoch:  289 pearson: test_pearson:  0.7199200409276838
============gbrt============
epoch:  289 pearson: ml_test_pearson:  0.7032861829323955
============xgb============
epoch:  289 pearson: ml_test_pearson:  0.7170179609798719
============rfr============
epoch:  289 pearson: ml_test_pearson:  0.657196222096901
===============模型average结果==================
epoch:  289 pearson: ml_test_pearson:  0.7041589360649341
[Epoch 290]
[batch 1] cost: 0.5484437 training pearson: 0.7576476589633967
[batch 2] cost: 0.5975364 training pearson: 0.7823173108640925
[batch 3] cost: 0.65820915 training pearson: 0.8010928453426033
[batch 4] cost: 0.670445 training pearson: 0.5846545829006841
[batch 5] cost: 0.7820656 training pearson: 0.7687288967356383
[batch 6] cost: 0.68138456 training pearson: 0.7801322397658813
[batch 7] cost: 0.5709808 training pearson: 0.643042448441375
[batch 8] cost: 0.57041985 training pearson: 0.8724874085185923
[batch 9] cost: 0.68082887 training pearson: 0.8062643032472482
[batch 10] cost: 0.7068012 training pearson: 0.7367877609401824
[batch 11] cost: 0.7891657 training pearson: 0.7305489633574528
[batch 12] cost: 0.91467005 training pearson: 0.5858991263711454
[batch 13] cost: 0.38778985 training pearson: 0.7574087678755211
[batch 14] cost: 0.6326027 training pearson: 0.7842105382187956
[batch 15] cost: 0.5345022 training pearson: 0.5793762133158821
epoch:  290 pearson: test_pearson:  0.7201610223022313
============gbrt============
epoch:  290 pearson: ml_test_pearson:  0.6969784775409685
============xgb============
epoch:  290 pearson: ml_test_pearson:  0.7125568358218918
============rfr============
epoch:  290 pearson: ml_test_pearson:  0.6316101248260093
===============模型average结果==================
epoch:  290 pearson: ml_test_pearson:  0.6909509850899856
[Epoch 291]
[batch 1] cost: 0.49872345 training pearson: 0.8538205926261558
[batch 2] cost: 0.53053635 training pearson: 0.8348952115722178
[batch 3] cost: 0.5202019 training pearson: 0.727129391708653
[batch 4] cost: 0.7604346 training pearson: 0.7616913766728405
[batch 5] cost: 0.66114134 training pearson: 0.6322008616696432
[batch 6] cost: 0.67811686 training pearson: 0.7398194374803496
[batch 7] cost: 0.3971372 training pearson: 0.7817116971360847
[batch 8] cost: 0.922005 training pearson: 0.6967846208483546
[batch 9] cost: 0.58595717 training pearson: 0.7016513328584933
[batch 10] cost: 0.5781893 training pearson: 0.6763600036744135
[batch 11] cost: 0.53646505 training pearson: 0.8474292494273308
[batch 12] cost: 0.58759224 training pearson: 0.7267175172977502
[batch 13] cost: 0.720307 training pearson: 0.7694983785683832
[batch 14] cost: 0.7058972 training pearson: 0.755375713723033
[batch 15] cost: 0.77833945 training pearson: 0.6304277142417805
epoch:  291 pearson: test_pearson:  0.7203086261841124
============gbrt============
epoch:  291 pearson: ml_test_pearson:  0.7031801255067569
============xgb============
epoch:  291 pearson: ml_test_pearson:  0.7139549899027231
============rfr============
epoch:  291 pearson: ml_test_pearson:  0.6652067542605002
===============模型average结果==================
epoch:  291 pearson: ml_test_pearson:  0.7069268958234571
[Epoch 292]
[batch 1] cost: 0.54069316 training pearson: 0.7875183417776496
[batch 2] cost: 0.6032034 training pearson: 0.6819847447990752
[batch 3] cost: 0.5344601 training pearson: 0.8382655012141562
[batch 4] cost: 0.3281159 training pearson: 0.7823208099936161
[batch 5] cost: 0.648705 training pearson: 0.8035829451281888
[batch 6] cost: 0.65194654 training pearson: 0.7910614758317658
[batch 7] cost: 0.7947049 training pearson: 0.6531176507337625
[batch 8] cost: 0.5296791 training pearson: 0.7995444752062211
[batch 9] cost: 0.70107406 training pearson: 0.693210493002243
[batch 10] cost: 0.6969103 training pearson: 0.7284364713072905
[batch 11] cost: 0.6069417 training pearson: 0.7975148093322003
[batch 12] cost: 0.9374295 training pearson: 0.7580812466547637
[batch 13] cost: 0.5635755 training pearson: 0.5532340768362058
[batch 14] cost: 0.71266985 training pearson: 0.8226386328654652
[batch 15] cost: 0.598133 training pearson: 0.642200692472371
epoch:  292 pearson: test_pearson:  0.7203716437218132
============gbrt============
epoch:  292 pearson: ml_test_pearson:  0.7160102810189857
============xgb============
epoch:  292 pearson: ml_test_pearson:  0.7022445496389025
============rfr============
epoch:  292 pearson: ml_test_pearson:  0.6698086419915371
===============模型average结果==================
epoch:  292 pearson: ml_test_pearson:  0.7082052157097672
[Epoch 293]
[batch 1] cost: 0.7185465 training pearson: 0.744322890800123
[batch 2] cost: 0.584407 training pearson: 0.655881146686843
[batch 3] cost: 0.50339496 training pearson: 0.6851199012697865
[batch 4] cost: 0.47989845 training pearson: 0.80542542151426
[batch 5] cost: 0.63865656 training pearson: 0.8085654761270128
[batch 6] cost: 0.9253502 training pearson: 0.7356171199347683
[batch 7] cost: 0.78454816 training pearson: 0.6499687922782715
[batch 8] cost: 0.784621 training pearson: 0.7344310773078329
[batch 9] cost: 0.39272636 training pearson: 0.8751206843527988
[batch 10] cost: 0.6824461 training pearson: 0.79072372340068
[batch 11] cost: 0.67723876 training pearson: 0.7218277586059727
[batch 12] cost: 0.51464045 training pearson: 0.8088827945994977
[batch 13] cost: 0.5395014 training pearson: 0.76173374018674
[batch 14] cost: 0.6788213 training pearson: 0.6844792885081159
[batch 15] cost: 0.48813573 training pearson: 0.7148384805133573
epoch:  293 pearson: test_pearson:  0.7203657884495669
============gbrt============
epoch:  293 pearson: ml_test_pearson:  0.7002314543464306
============xgb============
epoch:  293 pearson: ml_test_pearson:  0.7177583346007438
============rfr============
epoch:  293 pearson: ml_test_pearson:  0.6687492876562999
===============模型average结果==================
epoch:  293 pearson: ml_test_pearson:  0.7050843268637332
[Epoch 294]
[batch 1] cost: 0.67482203 training pearson: 0.7273030189515713
[batch 2] cost: 0.6639792 training pearson: 0.7336828177259465
[batch 3] cost: 0.9898099 training pearson: 0.6885723675952161
[batch 4] cost: 0.5436404 training pearson: 0.7099490381093645
[batch 5] cost: 0.7361296 training pearson: 0.7899582550433528
[batch 6] cost: 0.7884298 training pearson: 0.6459705496428434
[batch 7] cost: 0.5670217 training pearson: 0.8621846899493467
[batch 8] cost: 0.46831536 training pearson: 0.6222519671301435
[batch 9] cost: 0.47813004 training pearson: 0.8138802814458049
[batch 10] cost: 0.8553424 training pearson: 0.7170427074041962
[batch 11] cost: 0.53974223 training pearson: 0.6729052302559835
[batch 12] cost: 0.41222912 training pearson: 0.8470652982993919
[batch 13] cost: 0.50338405 training pearson: 0.7274182833102882
[batch 14] cost: 0.49633095 training pearson: 0.7280253219312528
[batch 15] cost: 0.6147727 training pearson: 0.8081702452470201
epoch:  294 pearson: test_pearson:  0.7203680441607508
============gbrt============
epoch:  294 pearson: ml_test_pearson:  0.701593969864988
============xgb============
epoch:  294 pearson: ml_test_pearson:  0.7113976866726124
============rfr============
epoch:  294 pearson: ml_test_pearson:  0.6703595763870095
===============模型average结果==================
epoch:  294 pearson: ml_test_pearson:  0.707027439210261
[Epoch 295]
[batch 1] cost: 0.4617964 training pearson: 0.7362630819872303
[batch 2] cost: 0.7324118 training pearson: 0.7700615144167532
[batch 3] cost: 0.70425606 training pearson: 0.5947537710604223
[batch 4] cost: 0.74410325 training pearson: 0.8451639210968385
[batch 5] cost: 0.3680394 training pearson: 0.8438793037985164
[batch 6] cost: 0.69665635 training pearson: 0.7916440221212125
[batch 7] cost: 0.76421577 training pearson: 0.6884482864020068
[batch 8] cost: 0.5008476 training pearson: 0.7852984714848524
[batch 9] cost: 0.76289046 training pearson: 0.7653550565882706
[batch 10] cost: 0.7719133 training pearson: 0.711695337495192
[batch 11] cost: 0.82060456 training pearson: 0.6788124359396152
[batch 12] cost: 0.3723853 training pearson: 0.7817551481852539
[batch 13] cost: 0.42588723 training pearson: 0.8531318222827933
[batch 14] cost: 0.6127515 training pearson: 0.6877041570963524
[batch 15] cost: 0.6455376 training pearson: 0.6946627078093088
epoch:  295 pearson: test_pearson:  0.7204839905183891
============gbrt============
epoch:  295 pearson: ml_test_pearson:  0.7192226881386149
============xgb============
epoch:  295 pearson: ml_test_pearson:  0.7166883845847003
============rfr============
epoch:  295 pearson: ml_test_pearson:  0.6813179346320456
===============模型average结果==================
epoch:  295 pearson: ml_test_pearson:  0.7178218048032824
[Epoch 296]
[batch 1] cost: 0.47819367 training pearson: 0.8580720013788138
[batch 2] cost: 0.5460404 training pearson: 0.7508876667522598
[batch 3] cost: 0.7070255 training pearson: 0.7244419919241417
[batch 4] cost: 0.8132465 training pearson: 0.7875754069200476
[batch 5] cost: 0.44297302 training pearson: 0.7077798981105633
[batch 6] cost: 0.8756021 training pearson: 0.6733264335308787
[batch 7] cost: 0.48678333 training pearson: 0.7499734575234737
[batch 8] cost: 0.70878386 training pearson: 0.7695015150726492
[batch 9] cost: 0.6097033 training pearson: 0.7960878520358137
[batch 10] cost: 0.59621674 training pearson: 0.7586866005488007
[batch 11] cost: 0.500012 training pearson: 0.7982543742274005
[batch 12] cost: 0.7491071 training pearson: 0.7179403621605892
[batch 13] cost: 0.42543903 training pearson: 0.6146262828233054
[batch 14] cost: 0.8286541 training pearson: 0.5371945238021698
[batch 15] cost: 0.6204397 training pearson: 0.828456077278617
epoch:  296 pearson: test_pearson:  0.7206435507860314
============gbrt============
epoch:  296 pearson: ml_test_pearson:  0.7131316845456477
============xgb============
epoch:  296 pearson: ml_test_pearson:  0.6983573320770702
============rfr============
epoch:  296 pearson: ml_test_pearson:  0.6584400483047425
===============模型average结果==================
epoch:  296 pearson: ml_test_pearson:  0.7038834198529259
[Epoch 297]
[batch 1] cost: 0.7655536 training pearson: 0.6505124930781151
[batch 2] cost: 0.6954357 training pearson: 0.7283428399282371
[batch 3] cost: 0.6455871 training pearson: 0.8316751938782463
[batch 4] cost: 0.42178863 training pearson: 0.8485619734564309
[batch 5] cost: 0.8237449 training pearson: 0.7763551580500648
[batch 6] cost: 0.5637115 training pearson: 0.8341959918942574
[batch 7] cost: 0.48840207 training pearson: 0.8283437685879563
[batch 8] cost: 0.6103469 training pearson: 0.7614737340636252
[batch 9] cost: 0.44598618 training pearson: 0.8193167185915244
[batch 10] cost: 0.49540606 training pearson: 0.6902199731323059
[batch 11] cost: 0.46524924 training pearson: 0.8099797504350187
[batch 12] cost: 1.1326834 training pearson: 0.5630671058936546
[batch 13] cost: 0.88127226 training pearson: 0.6277126926629004
[batch 14] cost: 0.48101696 training pearson: 0.7986946111291948
[batch 15] cost: 0.38910502 training pearson: 0.6369970621123332
epoch:  297 pearson: test_pearson:  0.7205641730796587
============gbrt============
epoch:  297 pearson: ml_test_pearson:  0.7174597543578648
============xgb============
epoch:  297 pearson: ml_test_pearson:  0.709518692097116
============rfr============
epoch:  297 pearson: ml_test_pearson:  0.6600846735646485
===============模型average结果==================
epoch:  297 pearson: ml_test_pearson:  0.7062665232516232
[Epoch 298]
[batch 1] cost: 0.51642174 training pearson: 0.7163896064544862
[batch 2] cost: 0.4034098 training pearson: 0.8153269985910958
[batch 3] cost: 0.5380436 training pearson: 0.766209432263593
[batch 4] cost: 0.998611 training pearson: 0.7147561363278003
[batch 5] cost: 0.6735707 training pearson: 0.7950172274253584
[batch 6] cost: 0.46076158 training pearson: 0.8169919284055761
[batch 7] cost: 0.8904833 training pearson: 0.7431005635563893
[batch 8] cost: 0.5554734 training pearson: 0.8479579535288324
[batch 9] cost: 0.71618074 training pearson: 0.563784544203611
[batch 10] cost: 0.5057777 training pearson: 0.7342098156382789
[batch 11] cost: 0.49516118 training pearson: 0.8152925446755972
[batch 12] cost: 0.5275517 training pearson: 0.6859541649820962
[batch 13] cost: 0.6263802 training pearson: 0.6835959369403454
[batch 14] cost: 0.7116969 training pearson: 0.8259764873177229
[batch 15] cost: 0.7323985 training pearson: 0.7251239390322946
epoch:  298 pearson: test_pearson:  0.7207117203451672
============gbrt============
epoch:  298 pearson: ml_test_pearson:  0.7116817649293835
============xgb============
epoch:  298 pearson: ml_test_pearson:  0.7053001103371628
============rfr============
epoch:  298 pearson: ml_test_pearson:  0.648148706982367
===============模型average结果==================
epoch:  298 pearson: ml_test_pearson:  0.6987651949082749
[Epoch 299]
[batch 1] cost: 0.61989874 training pearson: 0.7788416856597759
[batch 2] cost: 0.5134365 training pearson: 0.8069548257448247
[batch 3] cost: 0.53978324 training pearson: 0.8122421766038431
[batch 4] cost: 0.5608576 training pearson: 0.7790043196386781
[batch 5] cost: 0.6350374 training pearson: 0.7384374225659442
[batch 6] cost: 0.5690744 training pearson: 0.7229083927940287
[batch 7] cost: 0.48065934 training pearson: 0.795730996739959
[batch 8] cost: 0.54808515 training pearson: 0.728811719514774
[batch 9] cost: 0.6256615 training pearson: 0.5288647366811098
[batch 10] cost: 0.72865367 training pearson: 0.7996510289286899
[batch 11] cost: 0.7326706 training pearson: 0.7824569307421294
[batch 12] cost: 0.88975614 training pearson: 0.7696517027877838
[batch 13] cost: 0.5111109 training pearson: 0.8739162593139309
[batch 14] cost: 0.56721777 training pearson: 0.6090989362645391
[batch 15] cost: 0.8960716 training pearson: 0.5850523961419325
epoch:  299 pearson: test_pearson:  0.719509392254903
============gbrt============
epoch:  299 pearson: ml_test_pearson:  0.7086651218946002
============xgb============
epoch:  299 pearson: ml_test_pearson:  0.7098521530402334
============rfr============
epoch:  299 pearson: ml_test_pearson:  0.6862217483005296
===============模型average结果==================
epoch:  299 pearson: ml_test_pearson:  0.7166617255754381
[Epoch 300]
[batch 1] cost: 0.61510795 training pearson: 0.706464890037324
[batch 2] cost: 0.6666811 training pearson: 0.7952616641769098
[batch 3] cost: 0.47918582 training pearson: 0.861541637088596
[batch 4] cost: 0.48949197 training pearson: 0.7545044297834975
[batch 5] cost: 0.49425292 training pearson: 0.7212572748533592
[batch 6] cost: 0.70214194 training pearson: 0.8062415581607485
[batch 7] cost: 0.67570627 training pearson: 0.8645665849866377
[batch 8] cost: 0.55676824 training pearson: 0.8173892055831611
[batch 9] cost: 1.0819747 training pearson: 0.6125010806531102
[batch 10] cost: 0.5075582 training pearson: 0.6635779434629457
[batch 11] cost: 0.7077037 training pearson: 0.5333722381688871
[batch 12] cost: 0.38207045 training pearson: 0.7784923432792011
[batch 13] cost: 0.59965533 training pearson: 0.846515017854449
[batch 14] cost: 0.85213697 training pearson: 0.7059242784913176
[batch 15] cost: 0.5758034 training pearson: 0.6549310164142381
epoch:  300 pearson: test_pearson:  0.7201466190912766
============gbrt============
epoch:  300 pearson: ml_test_pearson:  0.7041552818880727
============xgb============
epoch:  300 pearson: ml_test_pearson:  0.6920336807457137
============rfr============
epoch:  300 pearson: ml_test_pearson:  0.6527151837157853
===============模型average结果==================
epoch:  300 pearson: ml_test_pearson:  0.6972409952740005
[[3.6775503 ]
 [1.8438787 ]
 [3.4060707 ]
 [3.305994  ]
 [2.6628675 ]
 [3.9460363 ]
 [3.3018627 ]
 [3.500802  ]
 [2.991706  ]
 [3.9556313 ]
 [1.8204198 ]
 [3.3295403 ]
 [3.9026008 ]
 [3.8004436 ]
 [2.6018562 ]
 [3.7024288 ]
 [3.891261  ]
 [3.6369133 ]
 [3.1970768 ]
 [2.8208904 ]
 [3.0686235 ]
 [2.0292168 ]
 [3.732666  ]
 [3.5195045 ]
 [2.4639158 ]
 [3.5116405 ]
 [3.5204077 ]
 [1.4912739 ]
 [2.8688078 ]
 [3.1665487 ]
 [3.792241  ]
 [3.7733955 ]
 [3.9264088 ]
 [3.635786  ]
 [3.355595  ]
 [3.6355066 ]
 [1.8737698 ]
 [3.9202733 ]
 [3.6488304 ]
 [3.3282485 ]
 [3.6056852 ]
 [3.722128  ]
 [3.5036335 ]
 [3.8130808 ]
 [3.9630117 ]
 [3.751906  ]
 [0.7582655 ]
 [2.4164839 ]
 [3.8646946 ]
 [3.7560472 ]
 [3.4357371 ]
 [3.5908632 ]
 [3.3508186 ]
 [3.2679482 ]
 [3.9375043 ]
 [2.4633622 ]
 [3.8185863 ]
 [3.7898512 ]
 [0.35784912]
 [3.838818  ]
 [3.991499  ]
 [1.1977634 ]
 [3.6268158 ]
 [2.0312948 ]
 [3.4825535 ]
 [3.7868595 ]
 [3.1455784 ]
 [3.3594675 ]
 [3.6757708 ]
 [3.8183389 ]
 [2.4712915 ]
 [3.8696232 ]
 [3.3144603 ]
 [3.8887248 ]
 [3.8981113 ]
 [3.9131184 ]
 [3.8138094 ]
 [3.472106  ]
 [3.8039618 ]
 [3.9206057 ]
 [3.8951378 ]
 [2.8536777 ]
 [2.7111297 ]
 [3.3394556 ]
 [3.701517  ]
 [3.9960032 ]
 [3.5756416 ]
 [1.6646242 ]
 [3.285243  ]
 [3.3598757 ]
 [3.0483704 ]
 [3.2922778 ]
 [3.9283    ]
 [3.7475653 ]
 [3.7944117 ]
 [2.404355  ]
 [3.850895  ]
 [3.8332372 ]
 [2.9704762 ]
 [3.8192797 ]
 [3.5932922 ]
 [3.8914785 ]
 [3.184658  ]
 [3.6749535 ]
 [2.9363298 ]
 [3.3000827 ]
 [3.8377547 ]
 [3.8850718 ]
 [3.7296114 ]
 [3.8843045 ]
 [3.2613564 ]
 [3.8465605 ]
 [3.8234153 ]
 [3.1056976 ]
 [1.8977432 ]
 [2.8504992 ]
 [0.71610737]
 [3.8946838 ]
 [3.2836142 ]
 [2.8109374 ]
 [3.453795  ]
 [3.7756243 ]
 [1.9444046 ]
 [3.08391   ]
 [3.5763574 ]
 [3.5623589 ]
 [3.8452377 ]
 [2.392313  ]
 [3.1229582 ]
 [2.716527  ]
 [3.1838007 ]
 [3.5866003 ]
 [3.752698  ]
 [3.980474  ]
 [3.6627102 ]
 [2.280591  ]
 [3.3753662 ]
 [3.595601  ]
 [3.4961624 ]
 [3.5042706 ]
 [2.645422  ]
 [3.0311298 ]
 [3.205308  ]
 [3.936586  ]
 [3.4409552 ]
 [3.4783897 ]
 [1.9775534 ]
 [1.2835479 ]
 [2.4339514 ]
 [3.420844  ]
 [3.8860407 ]
 [3.9076786 ]
 [3.2885847 ]
 [3.9355278 ]
 [3.8492603 ]
 [3.9421902 ]
 [3.9153838 ]
 [3.814375  ]
 [3.232812  ]
 [3.3627062 ]
 [3.8531647 ]
 [2.5720034 ]
 [3.2053633 ]
 [3.5489378 ]
 [2.5144815 ]
 [3.7021694 ]
 [3.0720606 ]
 [2.487081  ]
 [3.4377756 ]
 [3.0751133 ]
 [3.8976536 ]
 [2.1166515 ]
 [0.87352014]
 [1.95543   ]
 [2.86127   ]
 [2.800393  ]
 [3.2716527 ]
 [2.2310743 ]
 [3.1885004 ]
 [1.058486  ]
 [3.1436167 ]
 [3.4730759 ]
 [3.6973763 ]
 [3.8231773 ]
 [2.8901997 ]
 [3.9362164 ]
 [3.4318619 ]
 [3.71005   ]
 [3.6482272 ]
 [3.6800508 ]
 [3.8663616 ]
 [3.7398567 ]
 [3.9059653 ]
 [3.8542624 ]
 [3.730441  ]
 [3.4701428 ]
 [3.9541311 ]
 [2.9852123 ]
 [3.47079   ]
 [2.8550148 ]
 [2.9687424 ]
 [1.7681146 ]
 [1.9720879 ]
 [3.519463  ]
 [2.829255  ]
 [2.3103046 ]
 [3.8431845 ]
 [3.9218755 ]
 [3.8856707 ]
 [3.854682  ]
 [1.5196152 ]
 [2.9281344 ]
 [3.753706  ]
 [1.0400198 ]
 [1.9926205 ]
 [3.925146  ]
 [3.4690123 ]
 [3.4908876 ]
 [3.6835608 ]
 [3.3357134 ]
 [3.423029  ]
 [3.8039446 ]
 [3.8012862 ]
 [3.6099129 ]
 [3.600727  ]
 [3.6159954 ]
 [2.3120246 ]
 [3.5254774 ]
 [2.7982311 ]
 [3.4446754 ]
 [3.283823  ]
 [3.7876062 ]
 [0.02925062]
 [3.2592845 ]
 [3.333767  ]
 [3.8588014 ]
 [3.312563  ]
 [3.6137738 ]
 [3.6038685 ]
 [3.5006647 ]
 [3.7964053 ]
 [3.8608303 ]
 [3.308979  ]
 [3.3812933 ]
 [3.3909974 ]
 [3.6274505 ]
 [3.128405  ]
 [3.9458728 ]
 [3.5249429 ]
 [3.9115586 ]
 [3.8937225 ]
 [3.498867  ]
 [3.4885335 ]
 [3.5803485 ]
 [3.509179  ]
 [3.860927  ]
 [2.8392735 ]
 [3.769011  ]
 [2.2884645 ]
 [3.6161323 ]
 [2.670011  ]
 [1.3337717 ]
 [3.8608198 ]
 [3.5784302 ]
 [2.473339  ]
 [3.7138405 ]
 [3.9085903 ]
 [3.725782  ]
 [3.587566  ]
 [3.8210611 ]
 [3.8842516 ]
 [3.8188057 ]
 [2.0314627 ]
 [3.6839504 ]
 [3.3013725 ]
 [0.9485998 ]
 [2.723178  ]
 [3.780736  ]
 [3.6537762 ]
 [3.6917515 ]
 [3.4247007 ]
 [3.3884654 ]
 [3.203899  ]
 [3.72398   ]
 [3.3084621 ]
 [3.9575443 ]
 [2.5907278 ]
 [3.8633442 ]
 [3.405613  ]
 [2.1915526 ]
 [3.0284157 ]
 [1.593195  ]
 [3.5081854 ]
 [3.70858   ]
 [2.4710774 ]
 [3.6844525 ]
 [3.8651323 ]
 [3.964365  ]
 [3.61419   ]
 [3.6318626 ]
 [3.3728275 ]
 [3.8802376 ]
 [2.571848  ]
 [3.3255768 ]
 [3.0303893 ]
 [3.4393253 ]
 [2.6160622 ]
 [3.8540587 ]
 [3.704154  ]
 [3.03471   ]
 [3.7647028 ]
 [3.7591553 ]
 [1.7693796 ]
 [3.8973017 ]
 [3.5560207 ]
 [3.0432796 ]
 [1.5320115 ]
 [3.380662  ]]/home/xy/Envs/cnn_lstm/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
/home/xy/Envs/cnn_lstm/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
/home/xy/Envs/cnn_lstm/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
/home/xy/Envs/cnn_lstm/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
/home/xy/Envs/cnn_lstm/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
/home/xy/Envs/cnn_lstm/lib/python3.5/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.
  from numpy.core.umath_tests import inner1d

training finished!
==================================================
